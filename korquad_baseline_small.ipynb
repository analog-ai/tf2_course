{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "korquad_baseline_small.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "140c4e20939d443aa2a9eb480bcc2244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05a43f1037be44be91ef4932de927bd1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_30d722d631eb4928a1dc0dfe8313ea45",
              "IPY_MODEL_64da43656f43476395ca9754b88ce1fc"
            ]
          }
        },
        "05a43f1037be44be91ef4932de927bd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30d722d631eb4928a1dc0dfe8313ea45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3694b19c632f4764898c530657c6e636",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f404231693cb4f7ca4c8eb911586c32a"
          }
        },
        "64da43656f43476395ca9754b88ce1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7332c9e54ba54e8cab7b97066dc9b6df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [1:04:54&lt;00:00, 973.65s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63a382e23d374080b826c1a1de85fc81"
          }
        },
        "3694b19c632f4764898c530657c6e636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f404231693cb4f7ca4c8eb911586c32a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7332c9e54ba54e8cab7b97066dc9b6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63a382e23d374080b826c1a1de85fc81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44ff86e536f8440a970ba95fd2740d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a048cb7b75c416692465e818ad22dfa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b694c8bc65a4fdd95de3203290f0029",
              "IPY_MODEL_14c35e772b4848479337508f2adf65d9"
            ]
          }
        },
        "5a048cb7b75c416692465e818ad22dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "1000px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "0b694c8bc65a4fdd95de3203290f0029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5da94d2b31c1475caf63f3251b522549",
            "_dom_classes": [],
            "description": "Train Step(4023 / 16088) (Mean loss=2.11209) (loss=1.74309): 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 4023,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4023,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2586a3fb0b3403ca2bda27aac3c4d9b"
          }
        },
        "14c35e772b4848479337508f2adf65d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c2731053d924e1d9b3d5248b408f09a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4023/4023 [16:07&lt;00:00,  4.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_430b975abe05466f80f24250078a5158"
          }
        },
        "5da94d2b31c1475caf63f3251b522549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2586a3fb0b3403ca2bda27aac3c4d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c2731053d924e1d9b3d5248b408f09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "430b975abe05466f80f24250078a5158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba9062a03b4047639b0b6456a83a4b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a98c967c27df4be08cfd2c8b817b21e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1f97c608941428ab408c0010a7aca72",
              "IPY_MODEL_9d2c674e501b47279c4bc35c9e29fff4"
            ]
          }
        },
        "a98c967c27df4be08cfd2c8b817b21e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "1000px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "c1f97c608941428ab408c0010a7aca72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21bcfbbe35ed41e4a916fdc3ae466341",
            "_dom_classes": [],
            "description": "Train Step(8046 / 16088) (Mean loss=0.75029) (loss=1.02030): 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 4023,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4023,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8879e8b511e4355b729381139860a87"
          }
        },
        "9d2c674e501b47279c4bc35c9e29fff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d5a1931cbb24dc4a9d0aa04777f9779",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4023/4023 [16:09&lt;00:00,  4.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0bfe6f5728e24c62b2ae817db2a296ca"
          }
        },
        "21bcfbbe35ed41e4a916fdc3ae466341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8879e8b511e4355b729381139860a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d5a1931cbb24dc4a9d0aa04777f9779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0bfe6f5728e24c62b2ae817db2a296ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6b5da14ff804cf0a041f91d7dd71ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2655decd73e4333804d3ffb4629f0bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_14276dd8994c46beb889ae51e8222301",
              "IPY_MODEL_7efe4178b8e54d86922524a18f9699ab"
            ]
          }
        },
        "b2655decd73e4333804d3ffb4629f0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "1000px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "14276dd8994c46beb889ae51e8222301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26ab7e201b7444bc852b1afdb5fbbc67",
            "_dom_classes": [],
            "description": "Train Step(12069 / 16088) (Mean loss=0.52097) (loss=0.72810): 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 4023,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4023,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64cbfb2ace974d6e9fe59dc98f21b92a"
          }
        },
        "7efe4178b8e54d86922524a18f9699ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b350ad0a7c884b4b9007fc39182445ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4023/4023 [16:09&lt;00:00,  4.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7322af938f4a49d4864a55e11b820740"
          }
        },
        "26ab7e201b7444bc852b1afdb5fbbc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64cbfb2ace974d6e9fe59dc98f21b92a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b350ad0a7c884b4b9007fc39182445ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7322af938f4a49d4864a55e11b820740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b15e4ed855c6466893ebb1c261b0b718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_643d5c4b26eb4ed9b465b05a2d861f37",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec77cd82dd754f5089fe49f11678c5b8",
              "IPY_MODEL_358ac6c1a160409fb32db2c29d27dc2f"
            ]
          }
        },
        "643d5c4b26eb4ed9b465b05a2d861f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "1000px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "ec77cd82dd754f5089fe49f11678c5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_227e408492ae4e949b71dd120dc4a94f",
            "_dom_classes": [],
            "description": "Train Step(16092 / 16088) (Mean loss=0.38386) (loss=0.13919): 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 4023,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4023,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_305a23f9e2004631bd314af17ff86ccc"
          }
        },
        "358ac6c1a160409fb32db2c29d27dc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b453ea309fc84dc39e8c28963358b208",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4023/4023 [16:10&lt;00:00,  4.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_986af53733cd483c8edc79f19225a105"
          }
        },
        "227e408492ae4e949b71dd120dc4a94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "305a23f9e2004631bd314af17ff86ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b453ea309fc84dc39e8c28963358b208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "986af53733cd483c8edc79f19225a105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e167b14cf0143769dd3bba96eebec75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9aa6ddbcf3f41bca8c61c3f9e662760",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cd12db3ff52940b985734a4ee0a42755",
              "IPY_MODEL_29c73eed32a54c778d58ad5b27b6ee46"
            ]
          }
        },
        "c9aa6ddbcf3f41bca8c61c3f9e662760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "1000px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "cd12db3ff52940b985734a4ee0a42755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d008966833f241c4b34d2c56a917ec2c",
            "_dom_classes": [],
            "description": "Evaluating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 412,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 412,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2991301f96e4492fb48bff7fd6b9f87d"
          }
        },
        "29c73eed32a54c778d58ad5b27b6ee46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ac42f967d354596a98a1a07b3664501",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412/412 [00:30&lt;00:00, 13.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64b8344aca2141a7a14f4a2008cd5116"
          }
        },
        "d008966833f241c4b34d2c56a917ec2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2991301f96e4492fb48bff7fd6b9f87d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ac42f967d354596a98a1a07b3664501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64b8344aca2141a7a14f4a2008cd5116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/may22es/tf2_course/blob/master/korquad_baseline_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlTCl7vtKr0R",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1-IhaaDuRI7EjogPsXsy4KHq_tWHHbqrl\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQq8VwrY-uky",
        "colab_type": "text"
      },
      "source": [
        "# 한국어 AI 언어모델 튜닝대회\n",
        "\n",
        "Model의 Capacity가 커질수록 성능면에서는 이점이 있을 수 있으나 그만큼 고사양의 Machine이 필요합니다.  \n",
        "그래서 Fine-tuning을 빠르게 수행할 수 있고 Google Colab 환경에서도 가능하도록 대회의 Pre-train Model은 Small Size로 진행하게 되었습니다.\n",
        "\n",
        "\n",
        "## Model Detail\n",
        "해당 언어모델은 [Google BERT](https://github.com/google-research/bert) 및 [Huggingface Transformers](https://github.com/huggingface/transformers)를 참고하였으며 이를 Baseline으로 학습되었습니다.  \n",
        "Baseline과 다른 점은 다음을 참고해주시면 감사하겠습니다.\n",
        "\n",
        "|                 | Baseline                         | 대회제공모델                    |\n",
        "|:----------------|:---------------------------------|:-------------------------------|\n",
        "| MLM Strategy    | 15% random or whole word masking | n-gram masking                 |\n",
        "| Additional Task | NSP(Next Sentence Prediction)     | SOP(Sentence Order Prediction) |\n",
        "| Sub-word Level  | Space-level                      | Morpheme-Level                 |\n",
        "\n",
        "* 또한 Google에서 공개한 BERT Small Size는 **Hidden:512, Layer:4, Attention-Head:8**로 세팅이 되어있지만 본 repository에서 제공하는 Small Size Model은 **Hidden:256, Layer:12, Attention-Head:8** 입니다.\n",
        "\n",
        "\n",
        "## Reference\n",
        "* [Google BERT](https://github.com/google-research/bert)\n",
        "* [Huggingface Transformers](https://github.com/huggingface/transformers)\n",
        "* [KorQuAD](https://korquad.github.io/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTq8PMxau_FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import sys\n",
        "import collections\n",
        "import os\n",
        "import unicodedata\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from io import open\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.nn import CrossEntropyLoss, Dropout, Embedding, Softmax\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
        "from tqdm.autonotebook import tqdm, trange\n",
        "\n",
        "SEED = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROsT4icysDZ7",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMjXQssqsKk3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title BERT Model (더블클릭하여 내용 확인 가능합니다.)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "LayerNorm = nn.LayerNorm\n",
        "\n",
        "\n",
        "def Linear(i_dim, o_dim, bias=True):\n",
        "    m = nn.Linear(i_dim, o_dim, bias)\n",
        "    nn.init.normal_(m.weight, std=0.02)\n",
        "    if bias:\n",
        "        nn.init.constant_(m.bias, 0.)\n",
        "    return m\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\" Implementation of the gelu activation function currently in Google Bert repo (identical to OpenAI GPT).\n",
        "        Also see https://arxiv.org/abs/1606.08415\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "\n",
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_attention_heads = config.num_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query =Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.o_proj = Linear(config.hidden_size, config.hidden_size)\n",
        "        self.dropout = Dropout(config.dropout_prob)\n",
        "\n",
        "        self.softmax = Softmax(dim=-1)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        attention_scores = attention_scores + attention_mask\n",
        "        attention_probs = self.softmax(attention_scores)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "        attention_output = self.o_proj(context_layer)\n",
        "\n",
        "        return attention_output\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = Linear(config.hidden_size, config.ff_dim)\n",
        "        self.fc2 = Linear(config.ff_dim, config.hidden_size)\n",
        "        self.act_fn = ACT2FN[config.act_fn]\n",
        "        self.dropout = Dropout(config.dropout_prob)\n",
        "\n",
        "    def forward(self, input):\n",
        "        intermediate = self.fc1(input)\n",
        "        ff_out = self.dropout(self.fc2(self.act_fn(intermediate)))\n",
        "        return ff_out\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Block, self).__init__()\n",
        "        self.attention_norm = LayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.ffn_norm = LayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.ffn = PositionWiseFeedForward(config)\n",
        "        self.attn = Attention(config)\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "        # Attention\n",
        "        h = x\n",
        "        x = self.attn(x, attention_mask)\n",
        "        x = h + x\n",
        "        x = self.attention_norm(x)\n",
        "\n",
        "        # FFN\n",
        "        h = x\n",
        "        x = self.ffn(x)\n",
        "        x = x + h\n",
        "        x = self.ffn_norm(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layer = nn.ModuleList()\n",
        "        for l in range(config.num_hidden_layers):\n",
        "            layer = Block(config)\n",
        "            self.layer.append(copy.deepcopy(layer))\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        all_encoder_layers = []\n",
        "        for layer_block in self.layer:\n",
        "            hidden_states = layer_block(hidden_states, attention_mask)\n",
        "            all_encoder_layers.append(hidden_states)\n",
        "\n",
        "        return all_encoder_layers\n",
        "\n",
        "\n",
        "class Config(object):\n",
        "    def __init__(self,\n",
        "                 vocab_size_or_config_json_file,\n",
        "                 act_fn=\"gelu\",\n",
        "                 hidden_size=768,\n",
        "                 num_hidden_layers=12,\n",
        "                 ff_dim=3072,\n",
        "                 num_heads=12,\n",
        "                 dropout_prob=0.1,\n",
        "                 max_position_embeddings=512,\n",
        "                 type_vocab_size=2,\n",
        "                 initializer_range=0.02\n",
        "                 ):\n",
        "        if isinstance(vocab_size_or_config_json_file, str):\n",
        "            with open(vocab_size_or_config_json_file, \"r\", encoding='utf-8') as reader:\n",
        "                json_config = json.loads(reader.read())\n",
        "            for key, value in json_config.items():\n",
        "                self.__dict__[key] = value\n",
        "        elif isinstance(vocab_size_or_config_json_file, int):\n",
        "            self.vocab_size = vocab_size_or_config_json_file\n",
        "            self.act_fn = act_fn\n",
        "            self.hidden_size = hidden_size\n",
        "            self.num_hidden_layers = num_hidden_layers\n",
        "            self.ff_dim = ff_dim\n",
        "            self.num_heads = num_heads\n",
        "            self.dropout_prob = dropout_prob\n",
        "            self.max_position_embeddings = max_position_embeddings\n",
        "            self.type_vocab_size = type_vocab_size\n",
        "            self.initializer_range = initializer_range\n",
        "        else:\n",
        "            raise ValueError(\"First argument must be either a vocabulary size (int)\"\n",
        "                             \"or the path to a pretrained model config file (str)\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, json_object):\n",
        "        config = Config(vocab_size_or_config_json_file=-1)\n",
        "        for key, value in json_object.items():\n",
        "            config.__dict__[key] = value\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_json_file(cls, json_file):\n",
        "        with open(json_file, \"r\", encoding='utf-8') as reader:\n",
        "            text = reader.read()\n",
        "        return cls.from_dict(json.loads(text))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.word_embeddings = Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n",
        "        self.position_embeddings = Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        self.LayerNorm = LayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = Dropout(config.dropout_prob)\n",
        "\n",
        "        self.init_weights(config)\n",
        "\n",
        "    def init_weights(self, config):\n",
        "        self.word_embeddings.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
        "        self.position_embeddings.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
        "        self.token_type_embeddings.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "\n",
        "        words_embeddings = self.word_embeddings(input_ids)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class PredictionHeadTransform(nn.Module):  #\n",
        "    def __init__(self, config):\n",
        "        super(PredictionHeadTransform, self).__init__()\n",
        "        self.dense = Linear(config.hidden_size, config.hidden_size)\n",
        "        self.act_fn = ACT2FN[config.act_fn]\n",
        "        self.LayerNorm = LayerNorm(config.hidden_size, eps=1e-12)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.act_fn(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class LMPredictionHead(nn.Module):  #\n",
        "    def __init__(self, config, embedding_weights):\n",
        "        super(LMPredictionHead, self).__init__()\n",
        "        self.transform = PredictionHeadTransform(config)\n",
        "        self.decoder = Linear(embedding_weights.size(1),\n",
        "                              embedding_weights.size(0),\n",
        "                              bias=False)\n",
        "        self.decoder.weight = embedding_weights\n",
        "        self.bias = nn.Parameter(torch.zeros(embedding_weights.size(0)))\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.transform(hidden_states)\n",
        "        hidden_states = self.decoder(hidden_states) + self.bias\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class PreTrainingHeads(nn.Module):  #\n",
        "    def __init__(self, config, embedding_weights):\n",
        "        super(PreTrainingHeads, self).__init__()\n",
        "        self.predictions = LMPredictionHead(config, embedding_weights)\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        prediction_scores = self.predictions(sequence_output)\n",
        "\n",
        "        return prediction_scores\n",
        "\n",
        "\n",
        "class Pooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Pooler, self).__init__()\n",
        "        self.dense = Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Model, self).__init__()\n",
        "        self.embeddings = Embeddings(config)\n",
        "        self.encoder = Encoder(config)\n",
        "        self.pooler = Pooler(config)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones_like(input_ids)\n",
        "\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
        "        #extended_attention_mask = extended_attention_mask.to(torch.float32)\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
        "        encoded_layers = self.encoder(embedding_output,\n",
        "                                      extended_attention_mask)\n",
        "\n",
        "        sequence_output = encoded_layers[-1]\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        return sequence_output , pooled_output\n",
        "\n",
        "\n",
        "class QuestionAnswering(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(QuestionAnswering, self).__init__()\n",
        "        self.bert = Model(config)\n",
        "        # TODO check with Google if it's normal there is no dropout on the token classifier of SQuAD in the TF version\n",
        "        # self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.qa_outputs = Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, start_positions=None, end_positions=None):\n",
        "        sequence_output, _ = self.bert(input_ids, token_type_ids, attention_mask)\n",
        "        logits = self.qa_outputs(sequence_output)\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "        start_logits = start_logits.squeeze(-1)\n",
        "        end_logits = end_logits.squeeze(-1)\n",
        "\n",
        "        if start_positions is not None and end_positions is not None:\n",
        "            # If we are on multi-GPU, split add a dimension\n",
        "            if len(start_positions.size()) > 1:\n",
        "                start_positions = start_positions.squeeze(-1)\n",
        "            if len(end_positions.size()) > 1:\n",
        "                end_positions = end_positions.squeeze(-1)\n",
        "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
        "            ignored_index = start_logits.size(1)\n",
        "            start_positions.clamp_(0, ignored_index)\n",
        "            end_positions.clamp_(0, ignored_index)\n",
        "\n",
        "            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n",
        "            start_loss = loss_fct(start_logits, start_positions)\n",
        "            end_loss = loss_fct(end_logits, end_positions)\n",
        "            total_loss = (start_loss + end_loss) / 2\n",
        "            return total_loss\n",
        "        else:\n",
        "            return start_logits, end_logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2kqqNFntYuZ",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ6kf68ptY5L",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title BertTokenizer (더블클릭하여 내용 확인 가능합니다.)\n",
        "# coding=utf-8\n",
        "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Tokenization classes.\"\"\"\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
        "    vocab = collections.OrderedDict()\n",
        "    index = 0\n",
        "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
        "        while True:\n",
        "            token = reader.readline()\n",
        "            if not token:\n",
        "                break\n",
        "            token = token.strip()\n",
        "            vocab[token] = index\n",
        "            index += 1\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def whitespace_tokenize(text):\n",
        "    \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n",
        "    text = text.strip()\n",
        "    if not text:\n",
        "        return []\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "\n",
        "class BertTokenizer(object):\n",
        "    \"\"\"Runs end-to-end tokenization: punctuation splitting + wordpiece\"\"\"\n",
        "\n",
        "    def __init__(self, vocab_file, do_lower_case=False, max_len=None, do_basic_tokenize=True,\n",
        "                 never_split=(\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\")):\n",
        "        \"\"\"Constructs a BertTokenizer.\n",
        "\n",
        "        Args:\n",
        "          vocab_file: Path to a one-wordpiece-per-line vocabulary file\n",
        "          do_lower_case: Whether to lower case the input\n",
        "                         Only has an effect when do_wordpiece_only=False\n",
        "          do_basic_tokenize: Whether to do basic tokenization before wordpiece.\n",
        "          max_len: An artificial maximum length to truncate tokenized sequences to;\n",
        "                         Effective maximum length is always the minimum of this\n",
        "                         value (if specified) and the underlying BERT model's\n",
        "                         sequence length.\n",
        "          never_split: List of tokens which will never be split during tokenization.\n",
        "                         Only has an effect when do_wordpiece_only=False\n",
        "        \"\"\"\n",
        "        if not os.path.isfile(vocab_file):\n",
        "            raise ValueError(\n",
        "                \"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"\n",
        "                \"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\".format(vocab_file))\n",
        "        self.vocab = load_vocab(vocab_file)\n",
        "        self.ids_to_tokens = collections.OrderedDict(\n",
        "            [(ids, tok) for tok, ids in self.vocab.items()])\n",
        "        self.do_basic_tokenize = do_basic_tokenize\n",
        "        if do_basic_tokenize:\n",
        "            self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case,\n",
        "                                                  never_split=never_split)\n",
        "        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
        "        self.max_len = max_len if max_len is not None else int(1e12)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        split_tokens = []\n",
        "        if self.do_basic_tokenize:\n",
        "            for token in self.basic_tokenizer.tokenize(text):\n",
        "                for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
        "                    split_tokens.append(sub_token)\n",
        "        else:\n",
        "            split_tokens = self.wordpiece_tokenizer.tokenize(text)\n",
        "        return split_tokens\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        \"\"\"Converts a sequence of tokens into ids using the vocab.\"\"\"\n",
        "        ids = []\n",
        "        for token in tokens:\n",
        "            ids.append(self.vocab[token])\n",
        "        if len(ids) > self.max_len:\n",
        "            logger.warning(\n",
        "                \"Token indices sequence length is longer than the specified maximum \"\n",
        "                \" sequence length for this BERT model ({} > {}). Running this\"\n",
        "                \" sequence through BERT will result in indexing errors\".format(len(ids), self.max_len)\n",
        "            )\n",
        "        return ids\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        \"\"\"Converts a sequence of ids in wordpiece tokens using the vocab.\"\"\"\n",
        "        tokens = []\n",
        "        for i in ids:\n",
        "            tokens.append(self.ids_to_tokens[i])\n",
        "        return tokens\n",
        "\n",
        "\n",
        "class BasicTokenizer(object):\n",
        "    \"\"\"Runs basic tokenization (punctuation splitting, lower casing, etc.).\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 do_lower_case=True,\n",
        "                 never_split=(\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\")):\n",
        "        \"\"\"Constructs a BasicTokenizer.\n",
        "\n",
        "        Args:\n",
        "          do_lower_case: Whether to lower case the input.\n",
        "        \"\"\"\n",
        "        self.do_lower_case = do_lower_case\n",
        "        self.never_split = never_split\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Tokenizes a piece of text.\"\"\"\n",
        "        text = self._clean_text(text)\n",
        "        # This was added on November 1st, 2018 for the multilingual and Chinese\n",
        "        # models. This is also applied to the English models now, but it doesn't\n",
        "        # matter since the English models were not trained on any Chinese data\n",
        "        # and generally don't have any Chinese data in them (there are Chinese\n",
        "        # characters in the vocabulary because Wikipedia does have some Chinese\n",
        "        # words in the English Wikipedia.).\n",
        "        text = self._tokenize_chinese_chars(text)\n",
        "        orig_tokens = whitespace_tokenize(text)\n",
        "        split_tokens = []\n",
        "        for token in orig_tokens:\n",
        "            if self.do_lower_case and token not in self.never_split:\n",
        "                token = self._run_strip_accents(token)\n",
        "            token = token.lower()\n",
        "            split_tokens.extend(self._run_split_on_punc(token))\n",
        "\n",
        "        output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n",
        "        return output_tokens\n",
        "\n",
        "    def _run_strip_accents(self, text):\n",
        "        \"\"\"Strips accents from a piece of text.\"\"\"\n",
        "        text = unicodedata.normalize(\"NFD\", text)\n",
        "        output = []\n",
        "        for char in text:\n",
        "            cat = unicodedata.category(char)\n",
        "            if cat == \"Mn\":\n",
        "                continue\n",
        "            output.append(char)\n",
        "        return \"\".join(output)\n",
        "\n",
        "    def _run_split_on_punc(self, text):\n",
        "        \"\"\"Splits punctuation on a piece of text.\"\"\"\n",
        "        if text in self.never_split:\n",
        "            return [text]\n",
        "        chars = list(text)\n",
        "        i = 0\n",
        "        start_new_word = True\n",
        "        output = []\n",
        "        while i < len(chars):\n",
        "            char = chars[i]\n",
        "            if _is_punctuation(char):\n",
        "                output.append([char])\n",
        "                start_new_word = True\n",
        "            else:\n",
        "                if start_new_word:\n",
        "                    output.append([])\n",
        "                start_new_word = False\n",
        "                output[-1].append(char)\n",
        "            i += 1\n",
        "\n",
        "        return [\"\".join(x) for x in output]\n",
        "\n",
        "    def _tokenize_chinese_chars(self, text):\n",
        "        \"\"\"Adds whitespace around any CJK character.\"\"\"\n",
        "        output = []\n",
        "        for char in text:\n",
        "            cp = ord(char)\n",
        "            if self._is_chinese_char(cp):\n",
        "                output.append(\" \")\n",
        "                output.append(char)\n",
        "                output.append(\" \")\n",
        "            else:\n",
        "                output.append(char)\n",
        "        return \"\".join(output)\n",
        "\n",
        "    def _is_chinese_char(self, cp):\n",
        "        \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n",
        "        # This defines a \"chinese character\" as anything in the CJK Unicode block:\n",
        "        #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n",
        "        #\n",
        "        # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n",
        "        # despite its name. The modern Korean Hangul alphabet is a different block,\n",
        "        # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n",
        "        # space-separated words, so they are not treated specially and handled\n",
        "        # like the all of the other languages.\n",
        "        if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n",
        "                (cp >= 0x3400 and cp <= 0x4DBF) or  #\n",
        "                (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n",
        "                (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n",
        "                (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n",
        "                (cp >= 0x2B820 and cp <= 0x2CEAF) or\n",
        "                (cp >= 0xF900 and cp <= 0xFAFF) or  #\n",
        "                (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _clean_text(self, text):\n",
        "        \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
        "        output = []\n",
        "        for char in text:\n",
        "            cp = ord(char)\n",
        "            if cp == 0 or cp == 0xfffd or _is_control(char):\n",
        "                continue\n",
        "            if _is_whitespace(char):\n",
        "                output.append(\" \")\n",
        "            else:\n",
        "                output.append(char)\n",
        "        return \"\".join(output)\n",
        "\n",
        "\n",
        "class WordpieceTokenizer(object):\n",
        "    \"\"\"Runs WordPiece tokenization.\"\"\"\n",
        "\n",
        "    def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=100):\n",
        "        self.vocab = vocab\n",
        "        self.unk_token = unk_token\n",
        "        self.max_input_chars_per_word = max_input_chars_per_word\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Tokenizes a piece of text into its word pieces.\n",
        "\n",
        "        This uses a greedy longest-match-first algorithm to perform tokenization\n",
        "        using the given vocabulary.\n",
        "\n",
        "        For example:\n",
        "          input = \"unaffable\"\n",
        "          output = [\"un\", \"##aff\", \"##able\"]\n",
        "\n",
        "        Args:\n",
        "          text: A single token or whitespace separated tokens. This should have\n",
        "            already been passed through `BasicTokenizer`.\n",
        "\n",
        "        Returns:\n",
        "          A list of wordpiece tokens.\n",
        "        \"\"\"\n",
        "\n",
        "        output_tokens = []\n",
        "        for token in whitespace_tokenize(text):\n",
        "            chars = list(token)\n",
        "            if len(chars) > self.max_input_chars_per_word:\n",
        "                output_tokens.append(self.unk_token)\n",
        "                continue\n",
        "\n",
        "            is_bad = False\n",
        "            start = 0\n",
        "            sub_tokens = []\n",
        "            while start < len(chars):\n",
        "                end = len(chars)\n",
        "                cur_substr = None\n",
        "                while start < end:\n",
        "                    substr = \"\".join(chars[start:end])\n",
        "                    if start > 0:\n",
        "                        substr = \"##\" + substr\n",
        "                    if substr in self.vocab:\n",
        "                        cur_substr = substr\n",
        "                        break\n",
        "                    end -= 1\n",
        "                if cur_substr is None:\n",
        "                    is_bad = True\n",
        "                    break\n",
        "                sub_tokens.append(cur_substr)\n",
        "                start = end\n",
        "\n",
        "            if is_bad:\n",
        "                output_tokens.append(self.unk_token)\n",
        "            else:\n",
        "                output_tokens.extend(sub_tokens)\n",
        "        return output_tokens\n",
        "\n",
        "\n",
        "def _is_whitespace(char):\n",
        "    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
        "    # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
        "    # as whitespace since they are generally considered as such.\n",
        "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
        "        return True\n",
        "    cat = unicodedata.category(char)\n",
        "    if cat == \"Zs\":\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def _is_control(char):\n",
        "    \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
        "    # These are technically control characters but we count them as whitespace\n",
        "    # characters.\n",
        "    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
        "        return False\n",
        "    cat = unicodedata.category(char)\n",
        "    if cat.startswith(\"C\"):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def _is_punctuation(char):\n",
        "    \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n",
        "    cp = ord(char)\n",
        "    # We treat all non-letter/number ASCII as punctuation.\n",
        "    # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
        "    # Punctuation class but we treat them as punctuation anyways, for\n",
        "    # consistency.\n",
        "    if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n",
        "            (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n",
        "        return True\n",
        "    cat = unicodedata.category(char)\n",
        "    if cat.startswith(\"P\"):\n",
        "        return True\n",
        "    return False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9NIohxdtgAF",
        "colab_type": "text"
      },
      "source": [
        "# Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwiZMddJsLsj",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title BERT Optimizer & Scheduler (더블클릭하여 내용 확인 가능합니다.)\n",
        "# coding=utf-8\n",
        "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"PyTorch optimization for BERT model.\"\"\"\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ConstantLRSchedule(LambdaLR):\n",
        "    \"\"\" Constant learning rate schedule.\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, last_epoch=-1):\n",
        "        super(ConstantLRSchedule, self).__init__(optimizer, lambda _: 1.0, last_epoch=last_epoch)\n",
        "\n",
        "\n",
        "class WarmupConstantSchedule(LambdaLR):\n",
        "    \"\"\" Linear warmup and then constant.\n",
        "        Linearly increases learning rate schedule from 0 to 1 over `warmup_steps` training steps.\n",
        "        Keeps learning rate schedule equal to 1. after warmup_steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, warmup_steps, last_epoch=-1):\n",
        "        self.warmup_steps = warmup_steps\n",
        "        super(WarmupConstantSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
        "\n",
        "    def lr_lambda(self, step):\n",
        "        if step < self.warmup_steps:\n",
        "            return float(step) / float(max(1.0, self.warmup_steps))\n",
        "        return 1.\n",
        "\n",
        "\n",
        "class WarmupLinearSchedule(LambdaLR):\n",
        "    \"\"\" Linear warmup and then linear decay.\n",
        "        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n",
        "        Linearly decreases learning rate from 1. to 0. over remaining `t_total - warmup_steps` steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, warmup_steps, t_total, last_epoch=-1):\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.t_total = t_total\n",
        "        super(WarmupLinearSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
        "\n",
        "    def lr_lambda(self, step):\n",
        "        if step < self.warmup_steps:\n",
        "            return float(step) / float(max(1, self.warmup_steps))\n",
        "        return max(0.0, float(self.t_total - step) / float(max(1.0, self.t_total - self.warmup_steps)))\n",
        "\n",
        "\n",
        "class WarmupCosineSchedule(LambdaLR):\n",
        "    \"\"\" Linear warmup and then cosine decay.\n",
        "        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n",
        "        Decreases learning rate from 1. to 0. over remaining `t_total - warmup_steps` steps following a cosine curve.\n",
        "        If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, warmup_steps, t_total, cycles=.5, last_epoch=-1):\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.t_total = t_total\n",
        "        self.cycles = cycles\n",
        "        super(WarmupCosineSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
        "\n",
        "    def lr_lambda(self, step):\n",
        "        if step < self.warmup_steps:\n",
        "            return float(step) / float(max(1.0, self.warmup_steps))\n",
        "        # progress after warmup\n",
        "        progress = float(step - self.warmup_steps) / float(max(1, self.t_total - self.warmup_steps))\n",
        "        return max(0.0, 0.5 * (1. + math.cos(math.pi * float(self.cycles) * 2.0 * progress)))\n",
        "\n",
        "\n",
        "class WarmupCosineWithHardRestartsSchedule(LambdaLR):\n",
        "    \"\"\" Linear warmup and then cosine cycles with hard restarts.\n",
        "        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n",
        "        If `cycles` (default=1.) is different from default, learning rate follows `cycles` times a cosine decaying\n",
        "        learning rate (with hard restarts).\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, warmup_steps, t_total, cycles=1., last_epoch=-1):\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.t_total = t_total\n",
        "        self.cycles = cycles\n",
        "        super(WarmupCosineWithHardRestartsSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
        "\n",
        "    def lr_lambda(self, step):\n",
        "        if step < self.warmup_steps:\n",
        "            return float(step) / float(max(1, self.warmup_steps))\n",
        "        # progress after warmup\n",
        "        progress = float(step - self.warmup_steps) / float(max(1, self.t_total - self.warmup_steps))\n",
        "        if progress >= 1.0:\n",
        "            return 0.0\n",
        "        return max(0.0, 0.5 * (1. + math.cos(math.pi * ((float(self.cycles) * progress) % 1.0))))\n",
        "\n",
        "\n",
        "\n",
        "class AdamW(Optimizer):\n",
        "    \"\"\" Implements Adam algorithm with weight decay fix.\n",
        "\n",
        "    Parameters:\n",
        "        lr (float): learning rate. Default 1e-3.\n",
        "        betas (tuple of 2 floats): Adams beta parameters (b1, b2). Default: (0.9, 0.999)\n",
        "        eps (float): Adams epsilon. Default: 1e-6\n",
        "        weight_decay (float): Weight decay. Default: 0.0\n",
        "        correct_bias (bool): can be set to False to avoid correcting bias in Adam (e.g. like in Bert TF repository). Default True.\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-6, weight_decay=0.0, correct_bias=True):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1]  < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[1]))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(eps))\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n",
        "                        correct_bias=correct_bias)\n",
        "        super(AdamW, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # In-place operations to update the averages at the same time\n",
        "                exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1.0 - beta2, grad, grad)\n",
        "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "                step_size = group['lr']\n",
        "                if group['correct_bias']:  # No bias correction for Bert\n",
        "                    bias_correction1 = 1.0 - beta1 ** state['step']\n",
        "                    bias_correction2 = 1.0 - beta2 ** state['step']\n",
        "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
        "\n",
        "                # Just adding the square of the weights to the loss function is *not*\n",
        "                # the correct way of using L2 regularization/weight decay with Adam,\n",
        "                # since that will interact with the m and v parameters in strange ways.\n",
        "                #\n",
        "                # Instead we want to decay the weights in a manner that doesn't interact\n",
        "                # with the m/v parameters. This is equivalent to adding the square\n",
        "                # of the weights to the loss with plain (non-momentum) SGD.\n",
        "                # Add weight decay at the end (fixed version)\n",
        "                if group['weight_decay'] > 0.0:\n",
        "                    p.data.add_(-group['lr'] * group['weight_decay'], p.data)\n",
        "\n",
        "        return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tfD5fKZsTKB",
        "colab_type": "text"
      },
      "source": [
        "# MRC Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdb-KQBys4fX",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title MRC 전처리 및 후처리 관련 소스코드 (더블클릭하여 내용 확인 가능합니다.)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class SquadExample(object):\n",
        "    \"\"\"\n",
        "    A single training/test example for the Squad dataset.\n",
        "    For examples without an answer, the start and end position are -1.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 qas_id,\n",
        "                 question_text,\n",
        "                 doc_tokens,\n",
        "                 orig_answer_text=None,\n",
        "                 start_position=None,\n",
        "                 end_position=None,\n",
        "                 is_impossible=None):\n",
        "        self.qas_id = qas_id\n",
        "        self.question_text = question_text\n",
        "        self.doc_tokens = doc_tokens\n",
        "        self.orig_answer_text = orig_answer_text\n",
        "        self.start_position = start_position\n",
        "        self.end_position = end_position\n",
        "        self.is_impossible = is_impossible\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__repr__()\n",
        "\n",
        "    def __repr__(self):\n",
        "        s = \"\"\n",
        "        s += \"qas_id: %s\" % (self.qas_id)\n",
        "        s += \", question_text: %s\" % (\n",
        "            self.question_text)\n",
        "        s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n",
        "        if self.start_position:\n",
        "            s += \", start_position: %d\" % (self.start_position)\n",
        "        if self.end_position:\n",
        "            s += \", end_position: %d\" % (self.end_position)\n",
        "        if self.is_impossible:\n",
        "            s += \", is_impossible: %r\" % (self.is_impossible)\n",
        "        return s\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 unique_id,\n",
        "                 example_index,\n",
        "                 doc_span_index,\n",
        "                 tokens,\n",
        "                 token_to_orig_map,\n",
        "                 token_is_max_context,\n",
        "                 input_ids,\n",
        "                 input_mask,\n",
        "                 segment_ids,\n",
        "                 start_position=None,\n",
        "                 end_position=None,\n",
        "                 is_impossible=None):\n",
        "        self.unique_id = unique_id\n",
        "        self.example_index = example_index\n",
        "        self.doc_span_index = doc_span_index\n",
        "        self.tokens = tokens\n",
        "        self.token_to_orig_map = token_to_orig_map\n",
        "        self.token_is_max_context = token_is_max_context\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.start_position = start_position\n",
        "        self.end_position = end_position\n",
        "        self.is_impossible = is_impossible\n",
        "\n",
        "\n",
        "def read_squad_examples(input_file, is_training, version_2_with_negative):\n",
        "    \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n",
        "    with open(input_file, \"r\", encoding='utf-8') as reader:\n",
        "        input_data = json.load(reader)[\"data\"]\n",
        "\n",
        "    def is_whitespace(c):\n",
        "        if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    examples = []\n",
        "    for entry in input_data:\n",
        "        for paragraph in entry[\"paragraphs\"]:\n",
        "            paragraph_text = paragraph[\"context\"]\n",
        "            doc_tokens = []\n",
        "            char_to_word_offset = []\n",
        "            prev_is_whitespace = True\n",
        "            for c in paragraph_text:\n",
        "                if is_whitespace(c):\n",
        "                    prev_is_whitespace = True\n",
        "                else:\n",
        "                    if prev_is_whitespace:\n",
        "                        doc_tokens.append(c)\n",
        "                    else:\n",
        "                        doc_tokens[-1] += c\n",
        "                    prev_is_whitespace = False\n",
        "                char_to_word_offset.append(len(doc_tokens) - 1)\n",
        "\n",
        "            for qa in paragraph[\"qas\"]:\n",
        "                qas_id = qa[\"id\"]\n",
        "                question_text = qa[\"question\"]\n",
        "                start_position = None\n",
        "                end_position = None\n",
        "                orig_answer_text = None\n",
        "                is_impossible = False\n",
        "                if is_training:\n",
        "                    if version_2_with_negative:\n",
        "                        is_impossible = qa[\"is_impossible\"]\n",
        "                    if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
        "                        raise ValueError(\n",
        "                            \"For training, each question should have exactly 1 answer.\")\n",
        "                    if not is_impossible:\n",
        "                        answer = qa[\"answers\"][0]\n",
        "                        orig_answer_text = answer[\"text\"]\n",
        "                        answer_offset = answer[\"answer_start\"]\n",
        "                        answer_length = len(orig_answer_text)\n",
        "                        start_position = char_to_word_offset[answer_offset]\n",
        "                        end_position = char_to_word_offset[answer_offset + answer_length - 1]\n",
        "                        # Only add answers where the text can be exactly recovered from the\n",
        "                        # document. If this CAN'T happen it's likely due to weird Unicode\n",
        "                        # stuff so we will just skip the example.\n",
        "                        #\n",
        "                        # Note that this means for training mode, every example is NOT\n",
        "                        # guaranteed to be preserved.\n",
        "                        actual_text = \" \".join(doc_tokens[start_position:(end_position + 1)])\n",
        "                        cleaned_answer_text = \" \".join(\n",
        "                            whitespace_tokenize(orig_answer_text))\n",
        "                        if actual_text.find(cleaned_answer_text) == -1:\n",
        "                            logger.warning(\"Could not find answer: '%s' vs. '%s'\",\n",
        "                                           actual_text, cleaned_answer_text)\n",
        "                            continue\n",
        "                    else:\n",
        "                        start_position = -1\n",
        "                        end_position = -1\n",
        "                        orig_answer_text = \"\"\n",
        "\n",
        "                example = SquadExample(\n",
        "                    qas_id=qas_id,\n",
        "                    question_text=question_text,\n",
        "                    doc_tokens=doc_tokens,\n",
        "                    orig_answer_text=orig_answer_text,\n",
        "                    start_position=start_position,\n",
        "                    end_position=end_position,\n",
        "                    is_impossible=is_impossible)\n",
        "                examples.append(example)\n",
        "    return examples\n",
        "\n",
        "\n",
        "def convert_examples_to_features(examples, tokenizer, max_seq_length,\n",
        "                                 doc_stride, max_query_length, is_training):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "    unique_id = 1000000000\n",
        "\n",
        "    features = []\n",
        "    for (example_index, example) in enumerate(examples):\n",
        "        query_tokens = tokenizer.tokenize(example.question_text)\n",
        "\n",
        "        if len(query_tokens) > max_query_length:\n",
        "            query_tokens = query_tokens[0:max_query_length]\n",
        "\n",
        "        tok_to_orig_index = []\n",
        "        orig_to_tok_index = []\n",
        "        all_doc_tokens = []\n",
        "        for (i, token) in enumerate(example.doc_tokens):\n",
        "            orig_to_tok_index.append(len(all_doc_tokens))\n",
        "            sub_tokens = tokenizer.tokenize(token)\n",
        "            for sub_token in sub_tokens:\n",
        "                tok_to_orig_index.append(i)\n",
        "                all_doc_tokens.append(sub_token)\n",
        "\n",
        "        tok_start_position = None\n",
        "        tok_end_position = None\n",
        "        if is_training and example.is_impossible:\n",
        "            tok_start_position = -1\n",
        "            tok_end_position = -1\n",
        "        if is_training and not example.is_impossible:\n",
        "            tok_start_position = orig_to_tok_index[example.start_position]\n",
        "            if example.end_position < len(example.doc_tokens) - 1:\n",
        "                tok_end_position = orig_to_tok_index[example.end_position + 1] - 1\n",
        "            else:\n",
        "                tok_end_position = len(all_doc_tokens) - 1\n",
        "            (tok_start_position, tok_end_position) = _improve_answer_span(\n",
        "                all_doc_tokens, tok_start_position, tok_end_position, tokenizer,\n",
        "                example.orig_answer_text)\n",
        "\n",
        "        # The -3 accounts for [CLS], [SEP] and [SEP]\n",
        "        max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
        "\n",
        "        # We can have documents that are longer than the maximum sequence length.\n",
        "        # To deal with this we do a sliding window approach, where we take chunks\n",
        "        # of the up to our max length with a stride of `doc_stride`.\n",
        "        _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "            \"DocSpan\", [\"start\", \"length\"])\n",
        "        doc_spans = []\n",
        "        start_offset = 0\n",
        "        while start_offset < len(all_doc_tokens):\n",
        "            length = len(all_doc_tokens) - start_offset\n",
        "            if length > max_tokens_for_doc:\n",
        "                length = max_tokens_for_doc\n",
        "            doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
        "            if start_offset + length == len(all_doc_tokens):\n",
        "                break\n",
        "            start_offset += min(length, doc_stride)\n",
        "\n",
        "        for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
        "            tokens = []\n",
        "            token_to_orig_map = {}\n",
        "            token_is_max_context = {}\n",
        "            segment_ids = []\n",
        "            tokens.append(\"[CLS]\")\n",
        "            segment_ids.append(0)\n",
        "            for token in query_tokens:\n",
        "                tokens.append(token)\n",
        "                segment_ids.append(0)\n",
        "            tokens.append(\"[SEP]\")\n",
        "            segment_ids.append(0)\n",
        "\n",
        "            for i in range(doc_span.length):\n",
        "                split_token_index = doc_span.start + i\n",
        "                token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
        "\n",
        "                is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
        "                                                       split_token_index)\n",
        "                token_is_max_context[len(tokens)] = is_max_context\n",
        "                tokens.append(all_doc_tokens[split_token_index])\n",
        "                segment_ids.append(1)\n",
        "            tokens.append(\"[SEP]\")\n",
        "            segment_ids.append(1)\n",
        "\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "            # tokens are attended to.\n",
        "            input_mask = [1] * len(input_ids)\n",
        "\n",
        "            # Zero-pad up to the sequence length.\n",
        "            while len(input_ids) < max_seq_length:\n",
        "                input_ids.append(0)\n",
        "                input_mask.append(0)\n",
        "                segment_ids.append(0)\n",
        "\n",
        "            assert len(input_ids) == max_seq_length\n",
        "            assert len(input_mask) == max_seq_length\n",
        "            assert len(segment_ids) == max_seq_length\n",
        "\n",
        "            start_position = None\n",
        "            end_position = None\n",
        "            if is_training and not example.is_impossible:\n",
        "                # For training, if our document chunk does not contain an annotation\n",
        "                # we throw it out, since there is nothing to predict.\n",
        "                doc_start = doc_span.start\n",
        "                doc_end = doc_span.start + doc_span.length - 1\n",
        "                out_of_span = False\n",
        "                if not (tok_start_position >= doc_start and\n",
        "                        tok_end_position <= doc_end):\n",
        "                    out_of_span = True\n",
        "                if out_of_span:\n",
        "                    start_position = 0\n",
        "                    end_position = 0\n",
        "                else:\n",
        "                    doc_offset = len(query_tokens) + 2\n",
        "                    start_position = tok_start_position - doc_start + doc_offset\n",
        "                    end_position = tok_end_position - doc_start + doc_offset\n",
        "            if is_training and example.is_impossible:\n",
        "                start_position = 0\n",
        "                end_position = 0\n",
        "            if example_index < 20:\n",
        "                logger.info(\"*** Example ***\")\n",
        "                logger.info(\"unique_id: %s\" % (unique_id))\n",
        "                logger.info(\"example_index: %s\" % (example_index))\n",
        "                logger.info(\"doc_span_index: %s\" % (doc_span_index))\n",
        "                logger.info(\"tokens: %s\" % \" \".join(tokens))\n",
        "                logger.info(\"token_to_orig_map: %s\" % \" \".join([\n",
        "                    \"%d:%d\" % (x, y) for (x, y) in token_to_orig_map.items()]))\n",
        "                logger.info(\"token_is_max_context: %s\" % \" \".join([\n",
        "                    \"%d:%s\" % (x, y) for (x, y) in token_is_max_context.items()\n",
        "                ]))\n",
        "                logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "                logger.info(\n",
        "                    \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "                logger.info(\n",
        "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "                if is_training and example.is_impossible:\n",
        "                    logger.info(\"impossible example\")\n",
        "                if is_training and not example.is_impossible:\n",
        "                    answer_text = \" \".join(tokens[start_position:(end_position + 1)])\n",
        "                    logger.info(\"start_position: %d\" % (start_position))\n",
        "                    logger.info(\"end_position: %d\" % (end_position))\n",
        "                    logger.info(\n",
        "                        \"answer: %s\" % (answer_text))\n",
        "\n",
        "            features.append(\n",
        "                InputFeatures(\n",
        "                    unique_id=unique_id,\n",
        "                    example_index=example_index,\n",
        "                    doc_span_index=doc_span_index,\n",
        "                    tokens=tokens,\n",
        "                    token_to_orig_map=token_to_orig_map,\n",
        "                    token_is_max_context=token_is_max_context,\n",
        "                    input_ids=input_ids,\n",
        "                    input_mask=input_mask,\n",
        "                    segment_ids=segment_ids,\n",
        "                    start_position=start_position,\n",
        "                    end_position=end_position,\n",
        "                    is_impossible=example.is_impossible))\n",
        "            unique_id += 1\n",
        "\n",
        "    return features\n",
        "\n",
        "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n",
        "                         orig_answer_text):\n",
        "    \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n",
        "\n",
        "    # The SQuAD annotations are character based. We first project them to\n",
        "    # whitespace-tokenized words. But then after WordPiece tokenization, we can\n",
        "    # often find a \"better match\". For example:\n",
        "    #\n",
        "    #   Question: What year was John Smith born?\n",
        "    #   Context: The leader was John Smith (1895-1943).\n",
        "    #   Answer: 1895\n",
        "    #\n",
        "    # The original whitespace-tokenized answer will be \"(1895-1943).\". However\n",
        "    # after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match\n",
        "    # the exact answer, 1895.\n",
        "    #\n",
        "    # However, this is not always possible. Consider the following:\n",
        "    #\n",
        "    #   Question: What country is the top exporter of electornics?\n",
        "    #   Context: The Japanese electronics industry is the lagest in the world.\n",
        "    #   Answer: Japan\n",
        "    #\n",
        "    # In this case, the annotator chose \"Japan\" as a character sub-span of\n",
        "    # the word \"Japanese\". Since our WordPiece tokenizer does not split\n",
        "    # \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare\n",
        "    # in SQuAD, but does happen.\n",
        "    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n",
        "\n",
        "    for new_start in range(input_start, input_end + 1):\n",
        "        for new_end in range(input_end, new_start - 1, -1):\n",
        "            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n",
        "            if text_span == tok_answer_text:\n",
        "                return (new_start, new_end)\n",
        "\n",
        "    return (input_start, input_end)\n",
        "\n",
        "\n",
        "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
        "    \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
        "\n",
        "    # Because of the sliding window approach taken to scoring documents, a single\n",
        "    # token can appear in multiple documents. E.g.\n",
        "    #  Doc: the man went to the store and bought a gallon of milk\n",
        "    #  Span A: the man went to the\n",
        "    #  Span B: to the store and bought\n",
        "    #  Span C: and bought a gallon of\n",
        "    #  ...\n",
        "    #\n",
        "    # Now the word 'bought' will have two scores from spans B and C. We only\n",
        "    # want to consider the score with \"maximum context\", which we define as\n",
        "    # the *minimum* of its left and right context (the *sum* of left and\n",
        "    # right context will always be the same, of course).\n",
        "    #\n",
        "    # In the example the maximum context for 'bought' would be span C since\n",
        "    # it has 1 left context and 3 right context, while span B has 4 left context\n",
        "    # and 0 right context.\n",
        "    best_score = None\n",
        "    best_span_index = None\n",
        "    for (span_index, doc_span) in enumerate(doc_spans):\n",
        "        end = doc_span.start + doc_span.length - 1\n",
        "        if position < doc_span.start:\n",
        "            continue\n",
        "        if position > end:\n",
        "            continue\n",
        "        num_left_context = position - doc_span.start\n",
        "        num_right_context = end - position\n",
        "        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score = score\n",
        "            best_span_index = span_index\n",
        "\n",
        "    return cur_span_index == best_span_index\n",
        "\n",
        "\n",
        "RawResult = collections.namedtuple(\"RawResult\",\n",
        "                                   [\"unique_id\", \"start_logits\", \"end_logits\"])\n",
        "\n",
        "\n",
        "def write_predictions(all_examples, all_features, all_results, n_best_size,\n",
        "                      max_answer_length, do_lower_case, output_prediction_file,\n",
        "                      output_nbest_file, output_null_log_odds_file, verbose_logging,\n",
        "                      version_2_with_negative, null_score_diff_threshold):\n",
        "    \"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"\n",
        "    logger.info(\"Writing predictions to: %s\" % (output_prediction_file))\n",
        "    logger.info(\"Writing nbest to: %s\" % (output_nbest_file))\n",
        "\n",
        "    example_index_to_features = collections.defaultdict(list)\n",
        "    for feature in all_features:\n",
        "        example_index_to_features[feature.example_index].append(feature)\n",
        "\n",
        "    unique_id_to_result = {}\n",
        "    for result in all_results:\n",
        "        unique_id_to_result[result.unique_id] = result\n",
        "\n",
        "    _PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "        \"PrelimPrediction\",\n",
        "        [\"feature_index\", \"start_index\", \"end_index\", \"start_logit\", \"end_logit\"])\n",
        "\n",
        "    all_predictions = collections.OrderedDict()\n",
        "    all_nbest_json = collections.OrderedDict()\n",
        "    scores_diff_json = collections.OrderedDict()\n",
        "\n",
        "    for (example_index, example) in enumerate(all_examples):\n",
        "        features = example_index_to_features[example_index]\n",
        "\n",
        "        prelim_predictions = []\n",
        "        # keep track of the minimum score of null start+end of position 0\n",
        "        score_null = 1000000  # large and positive\n",
        "        min_null_feature_index = 0  # the paragraph slice with min null score\n",
        "        null_start_logit = 0  # the start logit at the slice with min null score\n",
        "        null_end_logit = 0  # the end logit at the slice with min null score\n",
        "        for (feature_index, feature) in enumerate(features):\n",
        "            result = unique_id_to_result[feature.unique_id]\n",
        "            start_indexes = _get_best_indexes(result.start_logits, n_best_size)\n",
        "            end_indexes = _get_best_indexes(result.end_logits, n_best_size)\n",
        "            # if we could have irrelevant answers, get the min score of irrelevant\n",
        "            if version_2_with_negative:\n",
        "                feature_null_score = result.start_logits[0] + result.end_logits[0]\n",
        "                if feature_null_score < score_null:\n",
        "                    score_null = feature_null_score\n",
        "                    min_null_feature_index = feature_index\n",
        "                    null_start_logit = result.start_logits[0]\n",
        "                    null_end_logit = result.end_logits[0]\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # We could hypothetically create invalid predictions, e.g., predict\n",
        "                    # that the start of the span is in the question. We throw out all\n",
        "                    # invalid predictions.\n",
        "                    if start_index >= len(feature.tokens):\n",
        "                        continue\n",
        "                    if end_index >= len(feature.tokens):\n",
        "                        continue\n",
        "                    if start_index not in feature.token_to_orig_map:\n",
        "                        continue\n",
        "                    if end_index not in feature.token_to_orig_map:\n",
        "                        continue\n",
        "                    if not feature.token_is_max_context.get(start_index, False):\n",
        "                        continue\n",
        "                    if end_index < start_index:\n",
        "                        continue\n",
        "                    length = end_index - start_index + 1\n",
        "                    if length > max_answer_length:\n",
        "                        continue\n",
        "                    prelim_predictions.append(\n",
        "                        _PrelimPrediction(\n",
        "                            feature_index=feature_index,\n",
        "                            start_index=start_index,\n",
        "                            end_index=end_index,\n",
        "                            start_logit=result.start_logits[start_index],\n",
        "                            end_logit=result.end_logits[end_index]))\n",
        "        if version_2_with_negative:\n",
        "            prelim_predictions.append(\n",
        "                _PrelimPrediction(\n",
        "                    feature_index=min_null_feature_index,\n",
        "                    start_index=0,\n",
        "                    end_index=0,\n",
        "                    start_logit=null_start_logit,\n",
        "                    end_logit=null_end_logit))\n",
        "        prelim_predictions = sorted(\n",
        "            prelim_predictions,\n",
        "            key=lambda x: (x.start_logit + x.end_logit),\n",
        "            reverse=True)\n",
        "\n",
        "        _NbestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "            \"NbestPrediction\", [\"text\", \"start_logit\", \"end_logit\"])\n",
        "\n",
        "        seen_predictions = {}\n",
        "        nbest = []\n",
        "        for pred in prelim_predictions:\n",
        "            if len(nbest) >= n_best_size:\n",
        "                break\n",
        "            feature = features[pred.feature_index]\n",
        "            if pred.start_index > 0:  # this is a non-null prediction\n",
        "                tok_tokens = feature.tokens[pred.start_index:(pred.end_index + 1)]\n",
        "                orig_doc_start = feature.token_to_orig_map[pred.start_index]\n",
        "                orig_doc_end = feature.token_to_orig_map[pred.end_index]\n",
        "                orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + 1)]\n",
        "                tok_text = \" \".join(tok_tokens)\n",
        "\n",
        "                # De-tokenize WordPieces that have been split off.\n",
        "                tok_text = tok_text.replace(\" ##\", \"\")\n",
        "                tok_text = tok_text.replace(\"##\", \"\")\n",
        "\n",
        "                # Clean whitespace\n",
        "                tok_text = tok_text.strip()\n",
        "                tok_text = \" \".join(tok_text.split())\n",
        "                orig_text = \" \".join(orig_tokens)\n",
        "\n",
        "                final_text = get_final_text(tok_text, orig_text, do_lower_case, verbose_logging)\n",
        "                if final_text in seen_predictions:\n",
        "                    continue\n",
        "\n",
        "                seen_predictions[final_text] = True\n",
        "            else:\n",
        "                final_text = \"\"\n",
        "                seen_predictions[final_text] = True\n",
        "\n",
        "            nbest.append(\n",
        "                _NbestPrediction(\n",
        "                    text=final_text,\n",
        "                    start_logit=pred.start_logit,\n",
        "                    end_logit=pred.end_logit))\n",
        "        # if we didn't include the empty option in the n-best, include it\n",
        "        if version_2_with_negative:\n",
        "            if \"\" not in seen_predictions:\n",
        "                nbest.append(\n",
        "                    _NbestPrediction(\n",
        "                        text=\"\",\n",
        "                        start_logit=null_start_logit,\n",
        "                        end_logit=null_end_logit))\n",
        "\n",
        "            # In very rare edge cases we could only have single null prediction.\n",
        "            # So we just create a nonce prediction in this case to avoid failure.\n",
        "            if len(nbest)==1:\n",
        "                nbest.insert(0,\n",
        "                             _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n",
        "\n",
        "        # In very rare edge cases we could have no valid predictions. So we\n",
        "        # just create a nonce prediction in this case to avoid failure.\n",
        "        if not nbest:\n",
        "            nbest.append(\n",
        "                _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n",
        "\n",
        "        assert len(nbest) >= 1\n",
        "\n",
        "        total_scores = []\n",
        "        best_non_null_entry = None\n",
        "        for entry in nbest:\n",
        "            total_scores.append(entry.start_logit + entry.end_logit)\n",
        "            if not best_non_null_entry:\n",
        "                if entry.text:\n",
        "                    best_non_null_entry = entry\n",
        "\n",
        "        probs = _compute_softmax(total_scores)\n",
        "\n",
        "        nbest_json = []\n",
        "        for (i, entry) in enumerate(nbest):\n",
        "            output = collections.OrderedDict()\n",
        "            output[\"text\"] = entry.text\n",
        "            output[\"probability\"] = probs[i]\n",
        "            output[\"start_logit\"] = entry.start_logit\n",
        "            output[\"end_logit\"] = entry.end_logit\n",
        "            nbest_json.append(output)\n",
        "\n",
        "        assert len(nbest_json) >= 1\n",
        "\n",
        "        if not version_2_with_negative:\n",
        "            all_predictions[example.qas_id] = nbest_json[0][\"text\"]\n",
        "        else:\n",
        "            # predict \"\" iff the null score - the score of best non-null > threshold\n",
        "            score_diff = score_null - best_non_null_entry.start_logit - (\n",
        "                best_non_null_entry.end_logit)\n",
        "            scores_diff_json[example.qas_id] = score_diff\n",
        "            if score_diff > null_score_diff_threshold:\n",
        "                all_predictions[example.qas_id] = \"\"\n",
        "            else:\n",
        "                all_predictions[example.qas_id] = best_non_null_entry.text\n",
        "            all_nbest_json[example.qas_id] = nbest_json\n",
        "\n",
        "    with open(output_prediction_file, \"w\") as writer:\n",
        "        writer.write(json.dumps(all_predictions, indent=4) + \"\\n\")\n",
        "\n",
        "    with open(output_nbest_file, \"w\") as writer:\n",
        "        writer.write(json.dumps(all_nbest_json, indent=4) + \"\\n\")\n",
        "\n",
        "    if version_2_with_negative:\n",
        "        with open(output_null_log_odds_file, \"w\") as writer:\n",
        "            writer.write(json.dumps(scores_diff_json, indent=4) + \"\\n\")\n",
        "\n",
        "\n",
        "def get_final_text(pred_text, orig_text, do_lower_case, verbose_logging=False):\n",
        "    \"\"\"Project the tokenized prediction back to the original text.\"\"\"\n",
        "\n",
        "    # When we created the data, we kept track of the alignment between original\n",
        "    # (whitespace tokenized) tokens and our WordPiece tokenized tokens. So\n",
        "    # now `orig_text` contains the span of our original text corresponding to the\n",
        "    # span that we predicted.\n",
        "    #\n",
        "    # However, `orig_text` may contain extra characters that we don't want in\n",
        "    # our prediction.\n",
        "    #\n",
        "    # For example, let's say:\n",
        "    #   pred_text = steve smith\n",
        "    #   orig_text = Steve Smith's\n",
        "    #\n",
        "    # We don't want to return `orig_text` because it contains the extra \"'s\".\n",
        "    #\n",
        "    # We don't want to return `pred_text` because it's already been normalized\n",
        "    # (the SQuAD eval script also does punctuation stripping/lower casing but\n",
        "    # our tokenizer does additional normalization like stripping accent\n",
        "    # characters).\n",
        "    #\n",
        "    # What we really want to return is \"Steve Smith\".\n",
        "    #\n",
        "    # Therefore, we have to apply a semi-complicated alignment heuristic between\n",
        "    # `pred_text` and `orig_text` to get a character-to-character alignment. This\n",
        "    # can fail in certain cases in which case we just return `orig_text`.\n",
        "\n",
        "    def _strip_spaces(text):\n",
        "        ns_chars = []\n",
        "        ns_to_s_map = collections.OrderedDict()\n",
        "        for (i, c) in enumerate(text):\n",
        "            if c == \" \":\n",
        "                continue\n",
        "            ns_to_s_map[len(ns_chars)] = i\n",
        "            ns_chars.append(c)\n",
        "        ns_text = \"\".join(ns_chars)\n",
        "        return (ns_text, ns_to_s_map)\n",
        "\n",
        "    # We first tokenize `orig_text`, strip whitespace from the result\n",
        "    # and `pred_text`, and check if they are the same length. If they are\n",
        "    # NOT the same length, the heuristic has failed. If they are the same\n",
        "    # length, we assume the characters are one-to-one aligned.\n",
        "    tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n",
        "\n",
        "    tok_text = \" \".join(tokenizer.tokenize(orig_text))\n",
        "\n",
        "    start_position = tok_text.find(pred_text)\n",
        "    if start_position == -1:\n",
        "        if verbose_logging:\n",
        "            logger.info(\n",
        "                \"Unable to find text: '%s' in '%s'\" % (pred_text, orig_text))\n",
        "        return orig_text\n",
        "    end_position = start_position + len(pred_text) - 1\n",
        "\n",
        "    (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text)\n",
        "    (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text)\n",
        "\n",
        "    if len(orig_ns_text) != len(tok_ns_text):\n",
        "        if verbose_logging:\n",
        "            logger.info(\"Length not equal after stripping spaces: '%s' vs '%s'\",\n",
        "                        orig_ns_text, tok_ns_text)\n",
        "        return orig_text\n",
        "\n",
        "    # We then project the characters in `pred_text` back to `orig_text` using\n",
        "    # the character-to-character alignment.\n",
        "    tok_s_to_ns_map = {}\n",
        "    for (i, tok_index) in tok_ns_to_s_map.items():\n",
        "        tok_s_to_ns_map[tok_index] = i\n",
        "\n",
        "    orig_start_position = None\n",
        "    if start_position in tok_s_to_ns_map:\n",
        "        ns_start_position = tok_s_to_ns_map[start_position]\n",
        "        if ns_start_position in orig_ns_to_s_map:\n",
        "            orig_start_position = orig_ns_to_s_map[ns_start_position]\n",
        "\n",
        "    if orig_start_position is None:\n",
        "        if verbose_logging:\n",
        "            logger.info(\"Couldn't map start position\")\n",
        "        return orig_text\n",
        "\n",
        "    orig_end_position = None\n",
        "    if end_position in tok_s_to_ns_map:\n",
        "        ns_end_position = tok_s_to_ns_map[end_position]\n",
        "        if ns_end_position in orig_ns_to_s_map:\n",
        "            orig_end_position = orig_ns_to_s_map[ns_end_position]\n",
        "\n",
        "    if orig_end_position is None:\n",
        "        if verbose_logging:\n",
        "            logger.info(\"Couldn't map end position\")\n",
        "        return orig_text\n",
        "\n",
        "    output_text = orig_text[orig_start_position:(orig_end_position + 1)]\n",
        "    return output_text\n",
        "\n",
        "\n",
        "def _get_best_indexes(logits, n_best_size):\n",
        "    \"\"\"Get the n-best logits from a list.\"\"\"\n",
        "    index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    best_indexes = []\n",
        "    for i in range(len(index_and_score)):\n",
        "        if i >= n_best_size:\n",
        "            break\n",
        "        best_indexes.append(index_and_score[i][0])\n",
        "    return best_indexes\n",
        "\n",
        "\n",
        "def _compute_softmax(scores):\n",
        "    \"\"\"Compute softmax probability over raw logits.\"\"\"\n",
        "    if not scores:\n",
        "        return []\n",
        "\n",
        "    max_score = None\n",
        "    for score in scores:\n",
        "        if max_score is None or score > max_score:\n",
        "            max_score = score\n",
        "\n",
        "    exp_scores = []\n",
        "    total_sum = 0.0\n",
        "    for score in scores:\n",
        "        x = math.exp(score - max_score)\n",
        "        exp_scores.append(x)\n",
        "        total_sum += x\n",
        "\n",
        "    probs = []\n",
        "    for score in exp_scores:\n",
        "        probs.append(score / total_sum)\n",
        "    return probs\n",
        "\n",
        "\n",
        "'''KorQuAD v1.0에 대한 공식 평가 스크립트 '''\n",
        "'''본 스크립트는 SQuAD v1.1 평가 스크립트 https://rajpurkar.github.io/SQuAD-explorer/ 를 바탕으로 작성됨.'''\n",
        "\n",
        "def normalize_answer(s):    \n",
        "    def remove_(text):\n",
        "        ''' 불필요한 기호 제거 '''\n",
        "        text = re.sub(\"'\", \" \", text)\n",
        "        text = re.sub('\"', \" \", text)\n",
        "        text = re.sub('《', \" \", text)\n",
        "        text = re.sub('》', \" \", text)\n",
        "        text = re.sub('<', \" \", text)\n",
        "        text = re.sub('>', \" \", text) \n",
        "        text = re.sub('〈', \" \", text)\n",
        "        text = re.sub('〉', \" \", text)   \n",
        "        text = re.sub(\"\\(\", \" \", text)\n",
        "        text = re.sub(\"\\)\", \" \", text)\n",
        "        text = re.sub(\"‘\", \" \", text)\n",
        "        text = re.sub(\"’\", \" \", text)      \n",
        "        return text\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_punc(lower(remove_(s))))\n",
        "\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "   \n",
        "    #F1 by character\n",
        "    prediction_Char = []\n",
        "    for tok in prediction_tokens:\n",
        "        now = [a for a in tok]\n",
        "        prediction_Char.extend(now)\n",
        "        \n",
        "    ground_truth_Char = []\n",
        "    for tok in ground_truth_tokens:\n",
        "        now = [a for a in tok]\n",
        "        ground_truth_Char.extend(now)   \n",
        "        \n",
        "    common = Counter(prediction_Char) & Counter(ground_truth_Char)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    \n",
        "    precision = 1.0 * num_same / len(prediction_Char)\n",
        "    recall = 1.0 * num_same / len(ground_truth_Char)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    \n",
        "    return f1\n",
        "\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "\n",
        "def evaluate(dataset, predictions):\n",
        "    f1 = exact_match = total = 0\n",
        "    for article in dataset:\n",
        "        for paragraph in article['paragraphs']:\n",
        "            for qa in paragraph['qas']:\n",
        "                total += 1\n",
        "                if qa['id'] not in predictions:\n",
        "                    message = 'Unanswered question ' + qa['id'] + \\\n",
        "                              ' will receive score 0.'\n",
        "                    print(message, file=sys.stderr)\n",
        "                    continue\n",
        "                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n",
        "                prediction = predictions[qa['id']]\n",
        "                exact_match += metric_max_over_ground_truths(\n",
        "                    exact_match_score, prediction, ground_truths)\n",
        "                f1 += metric_max_over_ground_truths(\n",
        "                    f1_score, prediction, ground_truths)\n",
        "\n",
        "    exact_match = 100.0 * exact_match / total\n",
        "    f1 = 100.0 * f1 / total\n",
        "    return {'exact_match': exact_match, 'f1': f1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBW_G806pKlo",
        "colab_type": "text"
      },
      "source": [
        "# Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDsq5jlLvU-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmGyVptOvXY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VOjl7yKFsXW",
        "colab_type": "text"
      },
      "source": [
        "## 학습에 필요한 파일 및 Hyper-parameters 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXLjguWHvXWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdrive_path = \"/content/drive/My Drive/bert_small\"\n",
        "output_dir = gdrive_path\n",
        "checkpoint = os.path.join(gdrive_path, \"bert_small_ckpt.bin\")\n",
        "model_config = os.path.join(gdrive_path, \"bert_small.json\")\n",
        "train_file = os.path.join(gdrive_path, \"KorQuAD_v1.0_train.json\")\n",
        "vocab_file = os.path.join(gdrive_path, \"ko_vocab_32k.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKuVDtG1vXUg",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "max_seq_length = 512 #@param {type: \"integer\"}\n",
        "doc_stride = 128 #@param {type: \"integer\"}\n",
        "max_query_length = 96 #@param {type: \"integer\"}\n",
        "max_answer_length = 30 #@param {type: \"integer\"}\n",
        "n_best_size = 20 #@param {type: \"integer\"}\n",
        "\n",
        "train_batch_size = 16 #@param {type: \"integer\"}\n",
        "learning_rate = 5e-5 #@param {type:\"raw\"}\n",
        "warmup_proportion = 0.1 #@param {type:\"raw\"}\n",
        "num_train_epochs = 4.0 #@param {type:\"raw\"}\n",
        "\n",
        "max_grad_norm = 1.0 #@param {type:\"raw\"}\n",
        "adam_epsilon = 1e-6 #@param {type:\"raw\"}\n",
        "weight_decay = 0.01 #@param {type:\"raw\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHyX3s0Sy_HF",
        "colab_type": "code",
        "outputId": "2d5fb44c-7807-4c9a-8770-db82c405ce7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "logger.info(\"device: {} n_gpu: {}\".format(device, n_gpu))\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 01:31:34 - INFO - __main__ -   device: cuda n_gpu: 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs07JilPGCKf",
        "colab_type": "text"
      },
      "source": [
        "## Model 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lcs_rNB0ApJ",
        "colab_type": "code",
        "outputId": "0f9e0756-5404-42f8-ad22-2941e9e9c654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Prepare model\n",
        "config = Config.from_json_file(model_config)\n",
        "model = QuestionAnswering(config)\n",
        "model.bert.load_state_dict(torch.load(checkpoint))\n",
        "num_params = count_parameters(model)\n",
        "logger.info(\"Total Parameter: %d\" % num_params)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 01:31:54 - INFO - __main__ -   Total Parameter: 17867522\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionAnswering(\n",
              "  (bert): Model(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(32000, 256, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 256)\n",
              "      (token_type_embeddings): Embedding(2, 256)\n",
              "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (1): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (2): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (3): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (4): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (5): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (6): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (7): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (8): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (9): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (10): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (11): Block(\n",
              "          (attention_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): PositionWiseFeedForward(\n",
              "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (attn): Attention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Pooler(\n",
              "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DexoydS8GR5a",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizer 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktU_U8MY0AnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare Tokenizer\n",
        "tokenizer = BertTokenizer(vocab_file, max_len=max_seq_length, do_basic_tokenize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEvmf4VWGUmH",
        "colab_type": "text"
      },
      "source": [
        "## KorQuAD 학습데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i-wV4VE0Alc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# KorQuad Pre-processing\n",
        "train_examples = read_squad_examples(input_file=train_file, is_training=True, version_2_with_negative=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRSAxv0u0Aj-",
        "colab_type": "code",
        "outputId": "ea51f88f-2659-41f7-f89b-bf200fe3b25d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_features = convert_examples_to_features(examples=train_examples,\n",
        "                                              tokenizer=tokenizer,\n",
        "                                              max_seq_length=max_seq_length,\n",
        "                                              doc_stride=doc_stride,\n",
        "                                              max_query_length=max_query_length,\n",
        "                                              is_training=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000000\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 바그너 ##는 괴테 ##의 파우스트 ##를 읽 ##고 무엇 ##을 쓰 ##고 ##자 했 ##는 ##가 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나 ##의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는 ##다 . 이 시기 바그너 ##는 1838 ##년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전 ##을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했 ##으 ##며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심 ##경 ##에 공감 ##했 ##다고 한다 . 또한 파리 ##에 ##서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하 ##는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는 ##데 , 이것 ##이 이듬해 1 ##월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향 ##을 끼쳤 ##으 ##리 ##라는 것 ##은 의심 ##할 여지 ##가 없 ##다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에 ##도 그 ##의 전기 ##에 적혀 있 ##는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것 ##이 아니 ##라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향 ##을 받 ##은 것 ##을 볼 수 있 ##다 . 그렇 ##게 교향곡 작곡 ##을 1839 ##년 ##부터 40 ##년 ##에 걸쳐 파리 ##에 ##서 착수 ##했 ##으 ##나 1 ##악 ##장 ##을 쓴 뒤 ##에 중단 ##했 ##다 . 또한 작품 ##의 완성 ##과 동시 ##에 그 ##는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에 ##서 연주 ##할 파트 ##보 ##까 ##지 준비 ##하 ##였 ##으 ##나 , 실제로 ##는 이루 ##어지 ##지 ##는 않 ##았 ##다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후 ##에 드레스덴 ##에 ##서 연주 ##되 ##었 ##고 재 ##연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되 ##고 말 ##았 ##다 . 그 사이 ##에 그 ##는 리 ##엔 ##치 ##와 방황 ##하 ##는 네덜란드인 ##을 완성 ##하 ##고 탄 ##호 ##이 ##저 ##에 ##도 착수 ##하 ##는 등 분 ##주 ##한 시간 ##을 보냈 ##는 ##데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것 ##이 아닌가 하 ##는 의견 ##도 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 19:0 20:0 21:1 22:1 23:2 24:2 25:3 26:3 27:4 28:5 29:5 30:6 31:7 32:7 33:8 34:8 35:9 36:10 37:11 38:11 39:12 40:13 41:13 42:14 43:14 44:15 45:15 46:15 47:16 48:16 49:17 50:17 51:17 52:17 53:18 54:19 55:20 56:20 57:21 58:21 59:21 60:22 61:23 62:23 63:23 64:24 65:24 66:24 67:24 68:24 69:25 70:26 71:27 72:27 73:27 74:28 75:28 76:29 77:29 78:30 79:30 80:30 81:30 82:31 83:31 84:31 85:31 86:31 87:31 88:32 89:32 90:33 91:33 92:34 93:34 94:34 95:35 96:35 97:35 98:36 99:36 100:37 101:38 102:38 103:38 104:39 105:39 106:39 107:39 108:40 109:40 110:41 111:42 112:43 113:43 114:44 115:44 116:44 117:45 118:45 119:46 120:47 121:47 122:47 123:48 124:48 125:49 126:49 127:50 128:50 129:51 130:51 131:51 132:51 133:51 134:52 135:52 136:53 137:54 138:54 139:54 140:55 141:55 142:56 143:56 144:57 145:58 146:59 147:59 148:60 149:60 150:60 151:61 152:61 153:62 154:62 155:62 156:62 157:63 158:63 159:64 160:64 161:65 162:65 163:66 164:66 165:66 166:67 167:67 168:68 169:68 170:68 171:69 172:69 173:70 174:70 175:70 176:71 177:71 178:72 179:72 180:73 181:74 182:74 183:75 184:75 185:76 186:76 187:77 188:77 189:78 190:78 191:79 192:79 193:79 194:80 195:80 196:81 197:81 198:82 199:82 200:83 201:83 202:84 203:84 204:84 205:84 206:85 207:85 208:86 209:86 210:87 211:87 212:88 213:88 214:89 215:90 216:91 217:91 218:91 219:92 220:92 221:93 222:94 223:94 224:95 225:95 226:95 227:96 228:96 229:96 230:97 231:98 232:98 233:98 234:99 235:99 236:99 237:99 238:100 239:100 240:100 241:100 242:101 243:102 244:102 245:103 246:103 247:103 248:103 249:104 250:105 251:105 252:106 253:106 254:107 255:107 256:108 257:108 258:109 259:110 260:110 261:110 262:110 263:110 264:110 265:110 266:111 267:112 268:112 269:113 270:113 271:113 272:114 273:114 274:115 275:115 276:115 277:115 278:116 279:116 280:116 281:116 282:116 283:116 284:117 285:117 286:118 287:118 288:118 289:118 290:119 291:119 292:119 293:119 294:120 295:121 296:121 297:122 298:122 299:123 300:123 301:124 302:125 303:125 304:126 305:126 306:126 307:127 308:127 309:127 310:127 311:128 312:128 313:128 314:129 315:129 316:129 317:129 318:130 319:130 320:131 321:132 322:132 323:132 324:133 325:133 326:133 327:133 328:134 329:135 330:135 331:136 332:136 333:137 334:137 335:137 336:137 337:138 338:138 339:138 340:139 341:139 342:140 343:140 344:140 345:141 346:141 347:141 348:141 349:141 350:141 351:142 352:142 353:142 354:143 355:144 356:144 357:144 358:145 359:145 360:146 361:146 362:146 363:146 364:147 365:148 366:149 367:149 368:150 369:151 370:151 371:152 372:152 373:153 374:154 375:154 376:155 377:156 378:156 379:157 380:157 381:158 382:158 383:158\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 10404 28140 21474 28139 23793 28154 2038 28147 3081 28144 406 28147 28167 47 28140 28146 1132 3 13791 28165 10404 28140 21474 28139 23793 28144 456 2038 28147 36 726 28137 1192 28135 7173 6832 1880 28141 672 359 28139 5964 28144 406 28318 28140 667 28144 540 28140 28136 9 7 817 10404 28140 19804 28165 28137 1236 201 28784 17099 249 28178 28172 28178 28144 10 1 860 28135 28173 7490 28183 8370 28137 6316 28195 28153 28215 336 4159 28331 28901 800 28154 1485 28140 23793 28139 366 28221 28137 9404 28195 14548 77 9 255 1584 28137 28149 15434 28413 28299 28139 1036 28141 1584 15005 13266 28135 1403 28142 28140 10722 28139 5964 183 28365 28144 2023 28147 1433 28151 17925 28144 132 28354 28140 28270 13 586 28135 1541 17 28210 28137 23793 28139 25727 17099 11036 7 525 28137 2593 28135 1526 553 28144 8418 28153 28159 8338 64 28151 3710 28297 8297 28146 165 28136 9 783 28139 59 28273 28212 1900 28139 278 28137 28160 36 28139 1150 28137 8990 28 28140 64 14949 1729 28150 1351 28191 10929 28175 167 28139 28146 3431 28255 64 28135 373 28173 10722 28139 8118 28235 28414 28473 1900 28139 553 28144 132 28151 64 28144 535 46 28 28136 9 1361 28199 5964 1339 28144 13791 28165 342 1058 28165 28137 1341 1584 28137 28149 6058 28195 28153 28175 17 28448 28190 28144 1607 308 28137 1899 28195 28136 9 255 525 28139 1724 28183 852 28137 36 28140 7 25727 24 17 28448 28190 23 14 1584 15005 28139 13723 28137 28149 1403 28297 4016 28207 28348 28148 1489 28142 28201 28153 28175 13 1570 28140 455 12050 28148 28140 122 28354 28136 9 700 8792 28151 101 28165 161 28135 2062 103 28137 18694 28137 28149 1403 28177 28182 28147 184 28249 28160 455 19252 539 13 186 28137 1615 11181 28177 28147 172 28354 28136 9 36 319 28137 36 28140 189 28546 28247 28198 20222 28142 28140 23270 28144 1724 28142 28147 644 28302 28135 28400 28137 28160 6058 28142 28140 78 137 28186 28150 473 28144 1951 28140 28270 13 1514 23346 742 28135 7 595 28144 6294 28199 22 64 28135 12039 15 28140 1904 28160 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 42\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 42\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 교향곡\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000001\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 1\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 바그너 ##는 교향곡 작곡 ##을 어디 ##까 ##지 쓴 뒤 ##에 중단 ##했 ##는 ##가 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나 ##의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는 ##다 . 이 시기 바그너 ##는 1838 ##년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전 ##을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했 ##으 ##며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심 ##경 ##에 공감 ##했 ##다고 한다 . 또한 파리 ##에 ##서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하 ##는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는 ##데 , 이것 ##이 이듬해 1 ##월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향 ##을 끼쳤 ##으 ##리 ##라는 것 ##은 의심 ##할 여지 ##가 없 ##다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에 ##도 그 ##의 전기 ##에 적혀 있 ##는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것 ##이 아니 ##라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향 ##을 받 ##은 것 ##을 볼 수 있 ##다 . 그렇 ##게 교향곡 작곡 ##을 1839 ##년 ##부터 40 ##년 ##에 걸쳐 파리 ##에 ##서 착수 ##했 ##으 ##나 1 ##악 ##장 ##을 쓴 뒤 ##에 중단 ##했 ##다 . 또한 작품 ##의 완성 ##과 동시 ##에 그 ##는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에 ##서 연주 ##할 파트 ##보 ##까 ##지 준비 ##하 ##였 ##으 ##나 , 실제로 ##는 이루 ##어지 ##지 ##는 않 ##았 ##다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후 ##에 드레스덴 ##에 ##서 연주 ##되 ##었 ##고 재 ##연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되 ##고 말 ##았 ##다 . 그 사이 ##에 그 ##는 리 ##엔 ##치 ##와 방황 ##하 ##는 네덜란드인 ##을 완성 ##하 ##고 탄 ##호 ##이 ##저 ##에 ##도 착수 ##하 ##는 등 분 ##주 ##한 시간 ##을 보냈 ##는 ##데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것 ##이 아닌가 하 ##는 의견 ##도 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 18:0 19:0 20:1 21:1 22:2 23:2 24:3 25:3 26:4 27:5 28:5 29:6 30:7 31:7 32:8 33:8 34:9 35:10 36:11 37:11 38:12 39:13 40:13 41:14 42:14 43:15 44:15 45:15 46:16 47:16 48:17 49:17 50:17 51:17 52:18 53:19 54:20 55:20 56:21 57:21 58:21 59:22 60:23 61:23 62:23 63:24 64:24 65:24 66:24 67:24 68:25 69:26 70:27 71:27 72:27 73:28 74:28 75:29 76:29 77:30 78:30 79:30 80:30 81:31 82:31 83:31 84:31 85:31 86:31 87:32 88:32 89:33 90:33 91:34 92:34 93:34 94:35 95:35 96:35 97:36 98:36 99:37 100:38 101:38 102:38 103:39 104:39 105:39 106:39 107:40 108:40 109:41 110:42 111:43 112:43 113:44 114:44 115:44 116:45 117:45 118:46 119:47 120:47 121:47 122:48 123:48 124:49 125:49 126:50 127:50 128:51 129:51 130:51 131:51 132:51 133:52 134:52 135:53 136:54 137:54 138:54 139:55 140:55 141:56 142:56 143:57 144:58 145:59 146:59 147:60 148:60 149:60 150:61 151:61 152:62 153:62 154:62 155:62 156:63 157:63 158:64 159:64 160:65 161:65 162:66 163:66 164:66 165:67 166:67 167:68 168:68 169:68 170:69 171:69 172:70 173:70 174:70 175:71 176:71 177:72 178:72 179:73 180:74 181:74 182:75 183:75 184:76 185:76 186:77 187:77 188:78 189:78 190:79 191:79 192:79 193:80 194:80 195:81 196:81 197:82 198:82 199:83 200:83 201:84 202:84 203:84 204:84 205:85 206:85 207:86 208:86 209:87 210:87 211:88 212:88 213:89 214:90 215:91 216:91 217:91 218:92 219:92 220:93 221:94 222:94 223:95 224:95 225:95 226:96 227:96 228:96 229:97 230:98 231:98 232:98 233:99 234:99 235:99 236:99 237:100 238:100 239:100 240:100 241:101 242:102 243:102 244:103 245:103 246:103 247:103 248:104 249:105 250:105 251:106 252:106 253:107 254:107 255:108 256:108 257:109 258:110 259:110 260:110 261:110 262:110 263:110 264:110 265:111 266:112 267:112 268:113 269:113 270:113 271:114 272:114 273:115 274:115 275:115 276:115 277:116 278:116 279:116 280:116 281:116 282:116 283:117 284:117 285:118 286:118 287:118 288:118 289:119 290:119 291:119 292:119 293:120 294:121 295:121 296:122 297:122 298:123 299:123 300:124 301:125 302:125 303:126 304:126 305:126 306:127 307:127 308:127 309:127 310:128 311:128 312:128 313:129 314:129 315:129 316:129 317:130 318:130 319:131 320:132 321:132 322:132 323:133 324:133 325:133 326:133 327:134 328:135 329:135 330:136 331:136 332:137 333:137 334:137 335:137 336:138 337:138 338:138 339:139 340:139 341:140 342:140 343:140 344:141 345:141 346:141 347:141 348:141 349:141 350:142 351:142 352:142 353:143 354:144 355:144 356:144 357:145 358:145 359:146 360:146 361:146 362:146 363:147 364:148 365:149 366:149 367:150 368:151 369:151 370:152 371:152 372:153 373:154 374:154 375:155 376:156 377:156 378:157 379:157 380:158 381:158 382:158\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 10404 28140 5964 1339 28144 3990 28348 28148 1607 308 28137 1899 28195 28140 28146 1132 3 13791 28165 10404 28140 21474 28139 23793 28144 456 2038 28147 36 726 28137 1192 28135 7173 6832 1880 28141 672 359 28139 5964 28144 406 28318 28140 667 28144 540 28140 28136 9 7 817 10404 28140 19804 28165 28137 1236 201 28784 17099 249 28178 28172 28178 28144 10 1 860 28135 28173 7490 28183 8370 28137 6316 28195 28153 28215 336 4159 28331 28901 800 28154 1485 28140 23793 28139 366 28221 28137 9404 28195 14548 77 9 255 1584 28137 28149 15434 28413 28299 28139 1036 28141 1584 15005 13266 28135 1403 28142 28140 10722 28139 5964 183 28365 28144 2023 28147 1433 28151 17925 28144 132 28354 28140 28270 13 586 28135 1541 17 28210 28137 23793 28139 25727 17099 11036 7 525 28137 2593 28135 1526 553 28144 8418 28153 28159 8338 64 28151 3710 28297 8297 28146 165 28136 9 783 28139 59 28273 28212 1900 28139 278 28137 28160 36 28139 1150 28137 8990 28 28140 64 14949 1729 28150 1351 28191 10929 28175 167 28139 28146 3431 28255 64 28135 373 28173 10722 28139 8118 28235 28414 28473 1900 28139 553 28144 132 28151 64 28144 535 46 28 28136 9 1361 28199 5964 1339 28144 13791 28165 342 1058 28165 28137 1341 1584 28137 28149 6058 28195 28153 28175 17 28448 28190 28144 1607 308 28137 1899 28195 28136 9 255 525 28139 1724 28183 852 28137 36 28140 7 25727 24 17 28448 28190 23 14 1584 15005 28139 13723 28137 28149 1403 28297 4016 28207 28348 28148 1489 28142 28201 28153 28175 13 1570 28140 455 12050 28148 28140 122 28354 28136 9 700 8792 28151 101 28165 161 28135 2062 103 28137 18694 28137 28149 1403 28177 28182 28147 184 28249 28160 455 19252 539 13 186 28137 1615 11181 28177 28147 172 28354 28136 9 36 319 28137 36 28140 189 28546 28247 28198 20222 28142 28140 23270 28144 1724 28142 28147 644 28302 28135 28400 28137 28160 6058 28142 28140 78 137 28186 28150 473 28144 1951 28140 28270 13 1514 23346 742 28135 7 595 28144 6294 28199 22 64 28135 12039 15 28140 1904 28160 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 237\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 239\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 1 ##악 ##장\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000002\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 2\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 바그너 ##가 파우스트 서곡 ##을 쓸 때 어떤 곡 ##의 영향 ##을 받 ##았 ##는 ##가 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나 ##의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는 ##다 . 이 시기 바그너 ##는 1838 ##년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전 ##을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했 ##으 ##며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심 ##경 ##에 공감 ##했 ##다고 한다 . 또한 파리 ##에 ##서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하 ##는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는 ##데 , 이것 ##이 이듬해 1 ##월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향 ##을 끼쳤 ##으 ##리 ##라는 것 ##은 의심 ##할 여지 ##가 없 ##다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에 ##도 그 ##의 전기 ##에 적혀 있 ##는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것 ##이 아니 ##라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향 ##을 받 ##은 것 ##을 볼 수 있 ##다 . 그렇 ##게 교향곡 작곡 ##을 1839 ##년 ##부터 40 ##년 ##에 걸쳐 파리 ##에 ##서 착수 ##했 ##으 ##나 1 ##악 ##장 ##을 쓴 뒤 ##에 중단 ##했 ##다 . 또한 작품 ##의 완성 ##과 동시 ##에 그 ##는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에 ##서 연주 ##할 파트 ##보 ##까 ##지 준비 ##하 ##였 ##으 ##나 , 실제로 ##는 이루 ##어지 ##지 ##는 않 ##았 ##다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후 ##에 드레스덴 ##에 ##서 연주 ##되 ##었 ##고 재 ##연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되 ##고 말 ##았 ##다 . 그 사이 ##에 그 ##는 리 ##엔 ##치 ##와 방황 ##하 ##는 네덜란드인 ##을 완성 ##하 ##고 탄 ##호 ##이 ##저 ##에 ##도 착수 ##하 ##는 등 분 ##주 ##한 시간 ##을 보냈 ##는 ##데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것 ##이 아닌가 하 ##는 의견 ##도 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 19:0 20:0 21:1 22:1 23:2 24:2 25:3 26:3 27:4 28:5 29:5 30:6 31:7 32:7 33:8 34:8 35:9 36:10 37:11 38:11 39:12 40:13 41:13 42:14 43:14 44:15 45:15 46:15 47:16 48:16 49:17 50:17 51:17 52:17 53:18 54:19 55:20 56:20 57:21 58:21 59:21 60:22 61:23 62:23 63:23 64:24 65:24 66:24 67:24 68:24 69:25 70:26 71:27 72:27 73:27 74:28 75:28 76:29 77:29 78:30 79:30 80:30 81:30 82:31 83:31 84:31 85:31 86:31 87:31 88:32 89:32 90:33 91:33 92:34 93:34 94:34 95:35 96:35 97:35 98:36 99:36 100:37 101:38 102:38 103:38 104:39 105:39 106:39 107:39 108:40 109:40 110:41 111:42 112:43 113:43 114:44 115:44 116:44 117:45 118:45 119:46 120:47 121:47 122:47 123:48 124:48 125:49 126:49 127:50 128:50 129:51 130:51 131:51 132:51 133:51 134:52 135:52 136:53 137:54 138:54 139:54 140:55 141:55 142:56 143:56 144:57 145:58 146:59 147:59 148:60 149:60 150:60 151:61 152:61 153:62 154:62 155:62 156:62 157:63 158:63 159:64 160:64 161:65 162:65 163:66 164:66 165:66 166:67 167:67 168:68 169:68 170:68 171:69 172:69 173:70 174:70 175:70 176:71 177:71 178:72 179:72 180:73 181:74 182:74 183:75 184:75 185:76 186:76 187:77 188:77 189:78 190:78 191:79 192:79 193:79 194:80 195:80 196:81 197:81 198:82 199:82 200:83 201:83 202:84 203:84 204:84 205:84 206:85 207:85 208:86 209:86 210:87 211:87 212:88 213:88 214:89 215:90 216:91 217:91 218:91 219:92 220:92 221:93 222:94 223:94 224:95 225:95 226:95 227:96 228:96 229:96 230:97 231:98 232:98 233:98 234:99 235:99 236:99 237:99 238:100 239:100 240:100 241:100 242:101 243:102 244:102 245:103 246:103 247:103 248:103 249:104 250:105 251:105 252:106 253:106 254:107 255:107 256:108 257:108 258:109 259:110 260:110 261:110 262:110 263:110 264:110 265:110 266:111 267:112 268:112 269:113 270:113 271:113 272:114 273:114 274:115 275:115 276:115 277:115 278:116 279:116 280:116 281:116 282:116 283:116 284:117 285:117 286:118 287:118 288:118 289:118 290:119 291:119 292:119 293:119 294:120 295:121 296:121 297:122 298:122 299:123 300:123 301:124 302:125 303:125 304:126 305:126 306:126 307:127 308:127 309:127 310:127 311:128 312:128 313:128 314:129 315:129 316:129 317:129 318:130 319:130 320:131 321:132 322:132 323:132 324:133 325:133 326:133 327:133 328:134 329:135 330:135 331:136 332:136 333:137 334:137 335:137 336:137 337:138 338:138 339:138 340:139 341:139 342:140 343:140 344:140 345:141 346:141 347:141 348:141 349:141 350:141 351:142 352:142 353:142 354:143 355:144 356:144 357:144 358:145 359:145 360:146 361:146 362:146 363:146 364:147 365:148 366:149 367:149 368:150 369:151 370:151 371:152 372:152 373:153 374:154 375:154 376:155 377:156 378:156 379:157 380:157 381:158 382:158 383:158\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 10404 28146 23793 25727 28144 3436 90 995 595 28139 553 28144 132 28354 28140 28146 1132 3 13791 28165 10404 28140 21474 28139 23793 28144 456 2038 28147 36 726 28137 1192 28135 7173 6832 1880 28141 672 359 28139 5964 28144 406 28318 28140 667 28144 540 28140 28136 9 7 817 10404 28140 19804 28165 28137 1236 201 28784 17099 249 28178 28172 28178 28144 10 1 860 28135 28173 7490 28183 8370 28137 6316 28195 28153 28215 336 4159 28331 28901 800 28154 1485 28140 23793 28139 366 28221 28137 9404 28195 14548 77 9 255 1584 28137 28149 15434 28413 28299 28139 1036 28141 1584 15005 13266 28135 1403 28142 28140 10722 28139 5964 183 28365 28144 2023 28147 1433 28151 17925 28144 132 28354 28140 28270 13 586 28135 1541 17 28210 28137 23793 28139 25727 17099 11036 7 525 28137 2593 28135 1526 553 28144 8418 28153 28159 8338 64 28151 3710 28297 8297 28146 165 28136 9 783 28139 59 28273 28212 1900 28139 278 28137 28160 36 28139 1150 28137 8990 28 28140 64 14949 1729 28150 1351 28191 10929 28175 167 28139 28146 3431 28255 64 28135 373 28173 10722 28139 8118 28235 28414 28473 1900 28139 553 28144 132 28151 64 28144 535 46 28 28136 9 1361 28199 5964 1339 28144 13791 28165 342 1058 28165 28137 1341 1584 28137 28149 6058 28195 28153 28175 17 28448 28190 28144 1607 308 28137 1899 28195 28136 9 255 525 28139 1724 28183 852 28137 36 28140 7 25727 24 17 28448 28190 23 14 1584 15005 28139 13723 28137 28149 1403 28297 4016 28207 28348 28148 1489 28142 28201 28153 28175 13 1570 28140 455 12050 28148 28140 122 28354 28136 9 700 8792 28151 101 28165 161 28135 2062 103 28137 18694 28137 28149 1403 28177 28182 28147 184 28249 28160 455 19252 539 13 186 28137 1615 11181 28177 28147 172 28354 28136 9 36 319 28137 36 28140 189 28546 28247 28198 20222 28142 28140 23270 28144 1724 28142 28147 644 28302 28135 28400 28137 28160 6058 28142 28140 78 137 28186 28150 473 28144 1951 28140 28270 13 1514 23346 742 28135 7 595 28144 6294 28199 22 64 28135 12039 15 28140 1904 28160 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 117\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 121\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 베토벤 ##의 교향곡 9 ##번\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000003\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 3\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 1839 ##년 바그너 ##가 교향곡 ##의 소재 ##로 쓰 ##려고 했 ##던 책 ##은 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나 ##의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는 ##다 . 이 시기 바그너 ##는 1838 ##년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전 ##을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했 ##으 ##며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심 ##경 ##에 공감 ##했 ##다고 한다 . 또한 파리 ##에 ##서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하 ##는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는 ##데 , 이것 ##이 이듬해 1 ##월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향 ##을 끼쳤 ##으 ##리 ##라는 것 ##은 의심 ##할 여지 ##가 없 ##다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에 ##도 그 ##의 전기 ##에 적혀 있 ##는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것 ##이 아니 ##라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향 ##을 받 ##은 것 ##을 볼 수 있 ##다 . 그렇 ##게 교향곡 작곡 ##을 1839 ##년 ##부터 40 ##년 ##에 걸쳐 파리 ##에 ##서 착수 ##했 ##으 ##나 1 ##악 ##장 ##을 쓴 뒤 ##에 중단 ##했 ##다 . 또한 작품 ##의 완성 ##과 동시 ##에 그 ##는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에 ##서 연주 ##할 파트 ##보 ##까 ##지 준비 ##하 ##였 ##으 ##나 , 실제로 ##는 이루 ##어지 ##지 ##는 않 ##았 ##다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후 ##에 드레스덴 ##에 ##서 연주 ##되 ##었 ##고 재 ##연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되 ##고 말 ##았 ##다 . 그 사이 ##에 그 ##는 리 ##엔 ##치 ##와 방황 ##하 ##는 네덜란드인 ##을 완성 ##하 ##고 탄 ##호 ##이 ##저 ##에 ##도 착수 ##하 ##는 등 분 ##주 ##한 시간 ##을 보냈 ##는 ##데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것 ##이 아닌가 하 ##는 의견 ##도 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 17:0 18:0 19:1 20:1 21:2 22:2 23:3 24:3 25:4 26:5 27:5 28:6 29:7 30:7 31:8 32:8 33:9 34:10 35:11 36:11 37:12 38:13 39:13 40:14 41:14 42:15 43:15 44:15 45:16 46:16 47:17 48:17 49:17 50:17 51:18 52:19 53:20 54:20 55:21 56:21 57:21 58:22 59:23 60:23 61:23 62:24 63:24 64:24 65:24 66:24 67:25 68:26 69:27 70:27 71:27 72:28 73:28 74:29 75:29 76:30 77:30 78:30 79:30 80:31 81:31 82:31 83:31 84:31 85:31 86:32 87:32 88:33 89:33 90:34 91:34 92:34 93:35 94:35 95:35 96:36 97:36 98:37 99:38 100:38 101:38 102:39 103:39 104:39 105:39 106:40 107:40 108:41 109:42 110:43 111:43 112:44 113:44 114:44 115:45 116:45 117:46 118:47 119:47 120:47 121:48 122:48 123:49 124:49 125:50 126:50 127:51 128:51 129:51 130:51 131:51 132:52 133:52 134:53 135:54 136:54 137:54 138:55 139:55 140:56 141:56 142:57 143:58 144:59 145:59 146:60 147:60 148:60 149:61 150:61 151:62 152:62 153:62 154:62 155:63 156:63 157:64 158:64 159:65 160:65 161:66 162:66 163:66 164:67 165:67 166:68 167:68 168:68 169:69 170:69 171:70 172:70 173:70 174:71 175:71 176:72 177:72 178:73 179:74 180:74 181:75 182:75 183:76 184:76 185:77 186:77 187:78 188:78 189:79 190:79 191:79 192:80 193:80 194:81 195:81 196:82 197:82 198:83 199:83 200:84 201:84 202:84 203:84 204:85 205:85 206:86 207:86 208:87 209:87 210:88 211:88 212:89 213:90 214:91 215:91 216:91 217:92 218:92 219:93 220:94 221:94 222:95 223:95 224:95 225:96 226:96 227:96 228:97 229:98 230:98 231:98 232:99 233:99 234:99 235:99 236:100 237:100 238:100 239:100 240:101 241:102 242:102 243:103 244:103 245:103 246:103 247:104 248:105 249:105 250:106 251:106 252:107 253:107 254:108 255:108 256:109 257:110 258:110 259:110 260:110 261:110 262:110 263:110 264:111 265:112 266:112 267:113 268:113 269:113 270:114 271:114 272:115 273:115 274:115 275:115 276:116 277:116 278:116 279:116 280:116 281:116 282:117 283:117 284:118 285:118 286:118 287:118 288:119 289:119 290:119 291:119 292:120 293:121 294:121 295:122 296:122 297:123 298:123 299:124 300:125 301:125 302:126 303:126 304:126 305:127 306:127 307:127 308:127 309:128 310:128 311:128 312:129 313:129 314:129 315:129 316:130 317:130 318:131 319:132 320:132 321:132 322:133 323:133 324:133 325:133 326:134 327:135 328:135 329:136 330:136 331:137 332:137 333:137 334:137 335:138 336:138 337:138 338:139 339:139 340:140 341:140 342:140 343:141 344:141 345:141 346:141 347:141 348:141 349:142 350:142 351:142 352:143 353:144 354:144 355:144 356:145 357:145 358:146 359:146 360:146 361:146 362:147 363:148 364:149 365:149 366:150 367:151 368:151 369:152 370:152 371:153 372:154 373:154 374:155 375:156 376:156 377:157 378:157 379:158 380:158 381:158\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 13791 28165 10404 28146 5964 28139 1880 28141 406 25582 47 28317 558 28151 1132 3 13791 28165 10404 28140 21474 28139 23793 28144 456 2038 28147 36 726 28137 1192 28135 7173 6832 1880 28141 672 359 28139 5964 28144 406 28318 28140 667 28144 540 28140 28136 9 7 817 10404 28140 19804 28165 28137 1236 201 28784 17099 249 28178 28172 28178 28144 10 1 860 28135 28173 7490 28183 8370 28137 6316 28195 28153 28215 336 4159 28331 28901 800 28154 1485 28140 23793 28139 366 28221 28137 9404 28195 14548 77 9 255 1584 28137 28149 15434 28413 28299 28139 1036 28141 1584 15005 13266 28135 1403 28142 28140 10722 28139 5964 183 28365 28144 2023 28147 1433 28151 17925 28144 132 28354 28140 28270 13 586 28135 1541 17 28210 28137 23793 28139 25727 17099 11036 7 525 28137 2593 28135 1526 553 28144 8418 28153 28159 8338 64 28151 3710 28297 8297 28146 165 28136 9 783 28139 59 28273 28212 1900 28139 278 28137 28160 36 28139 1150 28137 8990 28 28140 64 14949 1729 28150 1351 28191 10929 28175 167 28139 28146 3431 28255 64 28135 373 28173 10722 28139 8118 28235 28414 28473 1900 28139 553 28144 132 28151 64 28144 535 46 28 28136 9 1361 28199 5964 1339 28144 13791 28165 342 1058 28165 28137 1341 1584 28137 28149 6058 28195 28153 28175 17 28448 28190 28144 1607 308 28137 1899 28195 28136 9 255 525 28139 1724 28183 852 28137 36 28140 7 25727 24 17 28448 28190 23 14 1584 15005 28139 13723 28137 28149 1403 28297 4016 28207 28348 28148 1489 28142 28201 28153 28175 13 1570 28140 455 12050 28148 28140 122 28354 28136 9 700 8792 28151 101 28165 161 28135 2062 103 28137 18694 28137 28149 1403 28177 28182 28147 184 28249 28160 455 19252 539 13 186 28137 1615 11181 28177 28147 172 28354 28136 9 36 319 28137 36 28140 189 28546 28247 28198 20222 28142 28140 23270 28144 1724 28142 28147 644 28302 28135 28400 28137 28160 6058 28142 28140 78 137 28186 28150 473 28144 1951 28140 28270 13 1514 23346 742 28135 7 595 28144 6294 28199 22 64 28135 12039 15 28140 1904 28160 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 23\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 23\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 파우스트\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000004\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 4\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 파우스트 서곡 ##의 라 ##단 ##조 조성 ##이 영향 ##을 받 ##은 베토벤 ##의 곡 ##은 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나 ##의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는 ##다 . 이 시기 바그너 ##는 1838 ##년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전 ##을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했 ##으 ##며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심 ##경 ##에 공감 ##했 ##다고 한다 . 또한 파리 ##에 ##서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하 ##는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는 ##데 , 이것 ##이 이듬해 1 ##월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향 ##을 끼쳤 ##으 ##리 ##라는 것 ##은 의심 ##할 여지 ##가 없 ##다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에 ##도 그 ##의 전기 ##에 적혀 있 ##는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것 ##이 아니 ##라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향 ##을 받 ##은 것 ##을 볼 수 있 ##다 . 그렇 ##게 교향곡 작곡 ##을 1839 ##년 ##부터 40 ##년 ##에 걸쳐 파리 ##에 ##서 착수 ##했 ##으 ##나 1 ##악 ##장 ##을 쓴 뒤 ##에 중단 ##했 ##다 . 또한 작품 ##의 완성 ##과 동시 ##에 그 ##는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에 ##서 연주 ##할 파트 ##보 ##까 ##지 준비 ##하 ##였 ##으 ##나 , 실제로 ##는 이루 ##어지 ##지 ##는 않 ##았 ##다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후 ##에 드레스덴 ##에 ##서 연주 ##되 ##었 ##고 재 ##연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되 ##고 말 ##았 ##다 . 그 사이 ##에 그 ##는 리 ##엔 ##치 ##와 방황 ##하 ##는 네덜란드인 ##을 완성 ##하 ##고 탄 ##호 ##이 ##저 ##에 ##도 착수 ##하 ##는 등 분 ##주 ##한 시간 ##을 보냈 ##는 ##데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것 ##이 아닌가 하 ##는 의견 ##도 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 19:0 20:0 21:1 22:1 23:2 24:2 25:3 26:3 27:4 28:5 29:5 30:6 31:7 32:7 33:8 34:8 35:9 36:10 37:11 38:11 39:12 40:13 41:13 42:14 43:14 44:15 45:15 46:15 47:16 48:16 49:17 50:17 51:17 52:17 53:18 54:19 55:20 56:20 57:21 58:21 59:21 60:22 61:23 62:23 63:23 64:24 65:24 66:24 67:24 68:24 69:25 70:26 71:27 72:27 73:27 74:28 75:28 76:29 77:29 78:30 79:30 80:30 81:30 82:31 83:31 84:31 85:31 86:31 87:31 88:32 89:32 90:33 91:33 92:34 93:34 94:34 95:35 96:35 97:35 98:36 99:36 100:37 101:38 102:38 103:38 104:39 105:39 106:39 107:39 108:40 109:40 110:41 111:42 112:43 113:43 114:44 115:44 116:44 117:45 118:45 119:46 120:47 121:47 122:47 123:48 124:48 125:49 126:49 127:50 128:50 129:51 130:51 131:51 132:51 133:51 134:52 135:52 136:53 137:54 138:54 139:54 140:55 141:55 142:56 143:56 144:57 145:58 146:59 147:59 148:60 149:60 150:60 151:61 152:61 153:62 154:62 155:62 156:62 157:63 158:63 159:64 160:64 161:65 162:65 163:66 164:66 165:66 166:67 167:67 168:68 169:68 170:68 171:69 172:69 173:70 174:70 175:70 176:71 177:71 178:72 179:72 180:73 181:74 182:74 183:75 184:75 185:76 186:76 187:77 188:77 189:78 190:78 191:79 192:79 193:79 194:80 195:80 196:81 197:81 198:82 199:82 200:83 201:83 202:84 203:84 204:84 205:84 206:85 207:85 208:86 209:86 210:87 211:87 212:88 213:88 214:89 215:90 216:91 217:91 218:91 219:92 220:92 221:93 222:94 223:94 224:95 225:95 226:95 227:96 228:96 229:96 230:97 231:98 232:98 233:98 234:99 235:99 236:99 237:99 238:100 239:100 240:100 241:100 242:101 243:102 244:102 245:103 246:103 247:103 248:103 249:104 250:105 251:105 252:106 253:106 254:107 255:107 256:108 257:108 258:109 259:110 260:110 261:110 262:110 263:110 264:110 265:110 266:111 267:112 268:112 269:113 270:113 271:113 272:114 273:114 274:115 275:115 276:115 277:115 278:116 279:116 280:116 281:116 282:116 283:116 284:117 285:117 286:118 287:118 288:118 289:118 290:119 291:119 292:119 293:119 294:120 295:121 296:121 297:122 298:122 299:123 300:123 301:124 302:125 303:125 304:126 305:126 306:126 307:127 308:127 309:127 310:127 311:128 312:128 313:128 314:129 315:129 316:129 317:129 318:130 319:130 320:131 321:132 322:132 323:132 324:133 325:133 326:133 327:133 328:134 329:135 330:135 331:136 332:136 333:137 334:137 335:137 336:137 337:138 338:138 339:138 340:139 341:139 342:140 343:140 344:140 345:141 346:141 347:141 348:141 349:141 350:141 351:142 352:142 353:142 354:143 355:144 356:144 357:144 358:145 359:145 360:146 361:146 362:146 363:146 364:147 365:148 366:149 367:149 368:150 369:151 370:151 371:152 372:152 373:153 374:154 375:154 376:155 377:156 378:156 379:157 380:157 381:158 382:158 383:158\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True 383:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 23793 25727 28139 59 28273 28212 1900 28135 553 28144 132 28151 10722 28139 595 28151 1132 3 13791 28165 10404 28140 21474 28139 23793 28144 456 2038 28147 36 726 28137 1192 28135 7173 6832 1880 28141 672 359 28139 5964 28144 406 28318 28140 667 28144 540 28140 28136 9 7 817 10404 28140 19804 28165 28137 1236 201 28784 17099 249 28178 28172 28178 28144 10 1 860 28135 28173 7490 28183 8370 28137 6316 28195 28153 28215 336 4159 28331 28901 800 28154 1485 28140 23793 28139 366 28221 28137 9404 28195 14548 77 9 255 1584 28137 28149 15434 28413 28299 28139 1036 28141 1584 15005 13266 28135 1403 28142 28140 10722 28139 5964 183 28365 28144 2023 28147 1433 28151 17925 28144 132 28354 28140 28270 13 586 28135 1541 17 28210 28137 23793 28139 25727 17099 11036 7 525 28137 2593 28135 1526 553 28144 8418 28153 28159 8338 64 28151 3710 28297 8297 28146 165 28136 9 783 28139 59 28273 28212 1900 28139 278 28137 28160 36 28139 1150 28137 8990 28 28140 64 14949 1729 28150 1351 28191 10929 28175 167 28139 28146 3431 28255 64 28135 373 28173 10722 28139 8118 28235 28414 28473 1900 28139 553 28144 132 28151 64 28144 535 46 28 28136 9 1361 28199 5964 1339 28144 13791 28165 342 1058 28165 28137 1341 1584 28137 28149 6058 28195 28153 28175 17 28448 28190 28144 1607 308 28137 1899 28195 28136 9 255 525 28139 1724 28183 852 28137 36 28140 7 25727 24 17 28448 28190 23 14 1584 15005 28139 13723 28137 28149 1403 28297 4016 28207 28348 28148 1489 28142 28201 28153 28175 13 1570 28140 455 12050 28148 28140 122 28354 28136 9 700 8792 28151 101 28165 161 28135 2062 103 28137 18694 28137 28149 1403 28177 28182 28147 184 28249 28160 455 19252 539 13 186 28137 1615 11181 28177 28147 172 28354 28136 9 36 319 28137 36 28140 189 28546 28247 28198 20222 28142 28140 23270 28144 1724 28142 28147 644 28302 28135 28400 28137 28160 6058 28142 28140 78 137 28186 28150 473 28144 1951 28140 28270 13 1514 23346 742 28135 7 595 28144 6294 28199 22 64 28135 12039 15 28140 1904 28160 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 202\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 205\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 합창 ##교 ##향 ##곡\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000005\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 5\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 바그너 ##가 파우스트 ##를 처음 ##으로 읽 ##은 년도 ##는 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나 ##의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는 ##다 . 이 시기 바그너 ##는 1838 ##년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전 ##을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했 ##으 ##며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심 ##경 ##에 공감 ##했 ##다고 한다 . 또한 파리 ##에 ##서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하 ##는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는 ##데 , 이것 ##이 이듬해 1 ##월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향 ##을 끼쳤 ##으 ##리 ##라는 것 ##은 의심 ##할 여지 ##가 없 ##다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에 ##도 그 ##의 전기 ##에 적혀 있 ##는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것 ##이 아니 ##라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향 ##을 받 ##은 것 ##을 볼 수 있 ##다 . 그렇 ##게 교향곡 작곡 ##을 1839 ##년 ##부터 40 ##년 ##에 걸쳐 파리 ##에 ##서 착수 ##했 ##으 ##나 1 ##악 ##장 ##을 쓴 뒤 ##에 중단 ##했 ##다 . 또한 작품 ##의 완성 ##과 동시 ##에 그 ##는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에 ##서 연주 ##할 파트 ##보 ##까 ##지 준비 ##하 ##였 ##으 ##나 , 실제로 ##는 이루 ##어지 ##지 ##는 않 ##았 ##다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후 ##에 드레스덴 ##에 ##서 연주 ##되 ##었 ##고 재 ##연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되 ##고 말 ##았 ##다 . 그 사이 ##에 그 ##는 리 ##엔 ##치 ##와 방황 ##하 ##는 네덜란드인 ##을 완성 ##하 ##고 탄 ##호 ##이 ##저 ##에 ##도 착수 ##하 ##는 등 분 ##주 ##한 시간 ##을 보냈 ##는 ##데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것 ##이 아닌가 하 ##는 의견 ##도 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 13:0 14:0 15:1 16:1 17:2 18:2 19:3 20:3 21:4 22:5 23:5 24:6 25:7 26:7 27:8 28:8 29:9 30:10 31:11 32:11 33:12 34:13 35:13 36:14 37:14 38:15 39:15 40:15 41:16 42:16 43:17 44:17 45:17 46:17 47:18 48:19 49:20 50:20 51:21 52:21 53:21 54:22 55:23 56:23 57:23 58:24 59:24 60:24 61:24 62:24 63:25 64:26 65:27 66:27 67:27 68:28 69:28 70:29 71:29 72:30 73:30 74:30 75:30 76:31 77:31 78:31 79:31 80:31 81:31 82:32 83:32 84:33 85:33 86:34 87:34 88:34 89:35 90:35 91:35 92:36 93:36 94:37 95:38 96:38 97:38 98:39 99:39 100:39 101:39 102:40 103:40 104:41 105:42 106:43 107:43 108:44 109:44 110:44 111:45 112:45 113:46 114:47 115:47 116:47 117:48 118:48 119:49 120:49 121:50 122:50 123:51 124:51 125:51 126:51 127:51 128:52 129:52 130:53 131:54 132:54 133:54 134:55 135:55 136:56 137:56 138:57 139:58 140:59 141:59 142:60 143:60 144:60 145:61 146:61 147:62 148:62 149:62 150:62 151:63 152:63 153:64 154:64 155:65 156:65 157:66 158:66 159:66 160:67 161:67 162:68 163:68 164:68 165:69 166:69 167:70 168:70 169:70 170:71 171:71 172:72 173:72 174:73 175:74 176:74 177:75 178:75 179:76 180:76 181:77 182:77 183:78 184:78 185:79 186:79 187:79 188:80 189:80 190:81 191:81 192:82 193:82 194:83 195:83 196:84 197:84 198:84 199:84 200:85 201:85 202:86 203:86 204:87 205:87 206:88 207:88 208:89 209:90 210:91 211:91 212:91 213:92 214:92 215:93 216:94 217:94 218:95 219:95 220:95 221:96 222:96 223:96 224:97 225:98 226:98 227:98 228:99 229:99 230:99 231:99 232:100 233:100 234:100 235:100 236:101 237:102 238:102 239:103 240:103 241:103 242:103 243:104 244:105 245:105 246:106 247:106 248:107 249:107 250:108 251:108 252:109 253:110 254:110 255:110 256:110 257:110 258:110 259:110 260:111 261:112 262:112 263:113 264:113 265:113 266:114 267:114 268:115 269:115 270:115 271:115 272:116 273:116 274:116 275:116 276:116 277:116 278:117 279:117 280:118 281:118 282:118 283:118 284:119 285:119 286:119 287:119 288:120 289:121 290:121 291:122 292:122 293:123 294:123 295:124 296:125 297:125 298:126 299:126 300:126 301:127 302:127 303:127 304:127 305:128 306:128 307:128 308:129 309:129 310:129 311:129 312:130 313:130 314:131 315:132 316:132 317:132 318:133 319:133 320:133 321:133 322:134 323:135 324:135 325:136 326:136 327:137 328:137 329:137 330:137 331:138 332:138 333:138 334:139 335:139 336:140 337:140 338:140 339:141 340:141 341:141 342:141 343:141 344:141 345:142 346:142 347:142 348:143 349:144 350:144 351:144 352:145 353:145 354:146 355:146 356:146 357:146 358:147 359:148 360:149 361:149 362:150 363:151 364:151 365:152 366:152 367:153 368:154 369:154 370:155 371:156 372:156 373:157 374:157 375:158 376:158 377:158\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 10404 28146 23793 28154 456 17099 2038 28151 4066 28140 1132 3 13791 28165 10404 28140 21474 28139 23793 28144 456 2038 28147 36 726 28137 1192 28135 7173 6832 1880 28141 672 359 28139 5964 28144 406 28318 28140 667 28144 540 28140 28136 9 7 817 10404 28140 19804 28165 28137 1236 201 28784 17099 249 28178 28172 28178 28144 10 1 860 28135 28173 7490 28183 8370 28137 6316 28195 28153 28215 336 4159 28331 28901 800 28154 1485 28140 23793 28139 366 28221 28137 9404 28195 14548 77 9 255 1584 28137 28149 15434 28413 28299 28139 1036 28141 1584 15005 13266 28135 1403 28142 28140 10722 28139 5964 183 28365 28144 2023 28147 1433 28151 17925 28144 132 28354 28140 28270 13 586 28135 1541 17 28210 28137 23793 28139 25727 17099 11036 7 525 28137 2593 28135 1526 553 28144 8418 28153 28159 8338 64 28151 3710 28297 8297 28146 165 28136 9 783 28139 59 28273 28212 1900 28139 278 28137 28160 36 28139 1150 28137 8990 28 28140 64 14949 1729 28150 1351 28191 10929 28175 167 28139 28146 3431 28255 64 28135 373 28173 10722 28139 8118 28235 28414 28473 1900 28139 553 28144 132 28151 64 28144 535 46 28 28136 9 1361 28199 5964 1339 28144 13791 28165 342 1058 28165 28137 1341 1584 28137 28149 6058 28195 28153 28175 17 28448 28190 28144 1607 308 28137 1899 28195 28136 9 255 525 28139 1724 28183 852 28137 36 28140 7 25727 24 17 28448 28190 23 14 1584 15005 28139 13723 28137 28149 1403 28297 4016 28207 28348 28148 1489 28142 28201 28153 28175 13 1570 28140 455 12050 28148 28140 122 28354 28136 9 700 8792 28151 101 28165 161 28135 2062 103 28137 18694 28137 28149 1403 28177 28182 28147 184 28249 28160 455 19252 539 13 186 28137 1615 11181 28177 28147 172 28354 28136 9 36 319 28137 36 28140 189 28546 28247 28198 20222 28142 28140 23270 28144 1724 28142 28147 644 28302 28135 28400 28137 28160 6058 28142 28140 78 137 28186 28150 473 28144 1951 28140 28270 13 1514 23346 742 28135 7 595 28144 6294 28199 22 64 28135 12039 15 28140 1904 28160 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 13\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 13\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 1839\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000006\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 6\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 바그너 ##가 처음 교향곡 작곡 ##을 한 장소 ##는 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나 ##의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는 ##다 . 이 시기 바그너 ##는 1838 ##년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전 ##을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했 ##으 ##며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심 ##경 ##에 공감 ##했 ##다고 한다 . 또한 파리 ##에 ##서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하 ##는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는 ##데 , 이것 ##이 이듬해 1 ##월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향 ##을 끼쳤 ##으 ##리 ##라는 것 ##은 의심 ##할 여지 ##가 없 ##다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에 ##도 그 ##의 전기 ##에 적혀 있 ##는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것 ##이 아니 ##라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향 ##을 받 ##은 것 ##을 볼 수 있 ##다 . 그렇 ##게 교향곡 작곡 ##을 1839 ##년 ##부터 40 ##년 ##에 걸쳐 파리 ##에 ##서 착수 ##했 ##으 ##나 1 ##악 ##장 ##을 쓴 뒤 ##에 중단 ##했 ##다 . 또한 작품 ##의 완성 ##과 동시 ##에 그 ##는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에 ##서 연주 ##할 파트 ##보 ##까 ##지 준비 ##하 ##였 ##으 ##나 , 실제로 ##는 이루 ##어지 ##지 ##는 않 ##았 ##다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후 ##에 드레스덴 ##에 ##서 연주 ##되 ##었 ##고 재 ##연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되 ##고 말 ##았 ##다 . 그 사이 ##에 그 ##는 리 ##엔 ##치 ##와 방황 ##하 ##는 네덜란드인 ##을 완성 ##하 ##고 탄 ##호 ##이 ##저 ##에 ##도 착수 ##하 ##는 등 분 ##주 ##한 시간 ##을 보냈 ##는 ##데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것 ##이 아닌가 하 ##는 의견 ##도 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 12:0 13:0 14:1 15:1 16:2 17:2 18:3 19:3 20:4 21:5 22:5 23:6 24:7 25:7 26:8 27:8 28:9 29:10 30:11 31:11 32:12 33:13 34:13 35:14 36:14 37:15 38:15 39:15 40:16 41:16 42:17 43:17 44:17 45:17 46:18 47:19 48:20 49:20 50:21 51:21 52:21 53:22 54:23 55:23 56:23 57:24 58:24 59:24 60:24 61:24 62:25 63:26 64:27 65:27 66:27 67:28 68:28 69:29 70:29 71:30 72:30 73:30 74:30 75:31 76:31 77:31 78:31 79:31 80:31 81:32 82:32 83:33 84:33 85:34 86:34 87:34 88:35 89:35 90:35 91:36 92:36 93:37 94:38 95:38 96:38 97:39 98:39 99:39 100:39 101:40 102:40 103:41 104:42 105:43 106:43 107:44 108:44 109:44 110:45 111:45 112:46 113:47 114:47 115:47 116:48 117:48 118:49 119:49 120:50 121:50 122:51 123:51 124:51 125:51 126:51 127:52 128:52 129:53 130:54 131:54 132:54 133:55 134:55 135:56 136:56 137:57 138:58 139:59 140:59 141:60 142:60 143:60 144:61 145:61 146:62 147:62 148:62 149:62 150:63 151:63 152:64 153:64 154:65 155:65 156:66 157:66 158:66 159:67 160:67 161:68 162:68 163:68 164:69 165:69 166:70 167:70 168:70 169:71 170:71 171:72 172:72 173:73 174:74 175:74 176:75 177:75 178:76 179:76 180:77 181:77 182:78 183:78 184:79 185:79 186:79 187:80 188:80 189:81 190:81 191:82 192:82 193:83 194:83 195:84 196:84 197:84 198:84 199:85 200:85 201:86 202:86 203:87 204:87 205:88 206:88 207:89 208:90 209:91 210:91 211:91 212:92 213:92 214:93 215:94 216:94 217:95 218:95 219:95 220:96 221:96 222:96 223:97 224:98 225:98 226:98 227:99 228:99 229:99 230:99 231:100 232:100 233:100 234:100 235:101 236:102 237:102 238:103 239:103 240:103 241:103 242:104 243:105 244:105 245:106 246:106 247:107 248:107 249:108 250:108 251:109 252:110 253:110 254:110 255:110 256:110 257:110 258:110 259:111 260:112 261:112 262:113 263:113 264:113 265:114 266:114 267:115 268:115 269:115 270:115 271:116 272:116 273:116 274:116 275:116 276:116 277:117 278:117 279:118 280:118 281:118 282:118 283:119 284:119 285:119 286:119 287:120 288:121 289:121 290:122 291:122 292:123 293:123 294:124 295:125 296:125 297:126 298:126 299:126 300:127 301:127 302:127 303:127 304:128 305:128 306:128 307:129 308:129 309:129 310:129 311:130 312:130 313:131 314:132 315:132 316:132 317:133 318:133 319:133 320:133 321:134 322:135 323:135 324:136 325:136 326:137 327:137 328:137 329:137 330:138 331:138 332:138 333:139 334:139 335:140 336:140 337:140 338:141 339:141 340:141 341:141 342:141 343:141 344:142 345:142 346:142 347:143 348:144 349:144 350:144 351:145 352:145 353:146 354:146 355:146 356:146 357:147 358:148 359:149 360:149 361:150 362:151 363:151 364:152 365:152 366:153 367:154 368:154 369:155 370:156 371:156 372:157 373:157 374:158 375:158 376:158\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 10404 28146 456 5964 1339 28144 22 1821 28140 1132 3 13791 28165 10404 28140 21474 28139 23793 28144 456 2038 28147 36 726 28137 1192 28135 7173 6832 1880 28141 672 359 28139 5964 28144 406 28318 28140 667 28144 540 28140 28136 9 7 817 10404 28140 19804 28165 28137 1236 201 28784 17099 249 28178 28172 28178 28144 10 1 860 28135 28173 7490 28183 8370 28137 6316 28195 28153 28215 336 4159 28331 28901 800 28154 1485 28140 23793 28139 366 28221 28137 9404 28195 14548 77 9 255 1584 28137 28149 15434 28413 28299 28139 1036 28141 1584 15005 13266 28135 1403 28142 28140 10722 28139 5964 183 28365 28144 2023 28147 1433 28151 17925 28144 132 28354 28140 28270 13 586 28135 1541 17 28210 28137 23793 28139 25727 17099 11036 7 525 28137 2593 28135 1526 553 28144 8418 28153 28159 8338 64 28151 3710 28297 8297 28146 165 28136 9 783 28139 59 28273 28212 1900 28139 278 28137 28160 36 28139 1150 28137 8990 28 28140 64 14949 1729 28150 1351 28191 10929 28175 167 28139 28146 3431 28255 64 28135 373 28173 10722 28139 8118 28235 28414 28473 1900 28139 553 28144 132 28151 64 28144 535 46 28 28136 9 1361 28199 5964 1339 28144 13791 28165 342 1058 28165 28137 1341 1584 28137 28149 6058 28195 28153 28175 17 28448 28190 28144 1607 308 28137 1899 28195 28136 9 255 525 28139 1724 28183 852 28137 36 28140 7 25727 24 17 28448 28190 23 14 1584 15005 28139 13723 28137 28149 1403 28297 4016 28207 28348 28148 1489 28142 28201 28153 28175 13 1570 28140 455 12050 28148 28140 122 28354 28136 9 700 8792 28151 101 28165 161 28135 2062 103 28137 18694 28137 28149 1403 28177 28182 28147 184 28249 28160 455 19252 539 13 186 28137 1615 11181 28177 28147 172 28354 28136 9 36 319 28137 36 28140 189 28546 28247 28198 20222 28142 28140 23270 28144 1724 28142 28147 644 28302 28135 28400 28137 28160 6058 28142 28140 78 137 28186 28150 473 28144 1951 28140 28270 13 1514 23346 742 28135 7 595 28144 6294 28199 22 64 28135 12039 15 28140 1904 28160 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 224\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 224\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 파리\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000007\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 7\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 바그너 ##의 1 ##악 ##장 ##의 초연 ##은 어디 ##서 연주 ##되 ##었 ##는 ##가 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나 ##의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는 ##다 . 이 시기 바그너 ##는 1838 ##년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전 ##을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했 ##으 ##며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심 ##경 ##에 공감 ##했 ##다고 한다 . 또한 파리 ##에 ##서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하 ##는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는 ##데 , 이것 ##이 이듬해 1 ##월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향 ##을 끼쳤 ##으 ##리 ##라는 것 ##은 의심 ##할 여지 ##가 없 ##다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에 ##도 그 ##의 전기 ##에 적혀 있 ##는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것 ##이 아니 ##라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향 ##을 받 ##은 것 ##을 볼 수 있 ##다 . 그렇 ##게 교향곡 작곡 ##을 1839 ##년 ##부터 40 ##년 ##에 걸쳐 파리 ##에 ##서 착수 ##했 ##으 ##나 1 ##악 ##장 ##을 쓴 뒤 ##에 중단 ##했 ##다 . 또한 작품 ##의 완성 ##과 동시 ##에 그 ##는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에 ##서 연주 ##할 파트 ##보 ##까 ##지 준비 ##하 ##였 ##으 ##나 , 실제로 ##는 이루 ##어지 ##지 ##는 않 ##았 ##다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후 ##에 드레스덴 ##에 ##서 연주 ##되 ##었 ##고 재 ##연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되 ##고 말 ##았 ##다 . 그 사이 ##에 그 ##는 리 ##엔 ##치 ##와 방황 ##하 ##는 네덜란드인 ##을 완성 ##하 ##고 탄 ##호 ##이 ##저 ##에 ##도 착수 ##하 ##는 등 분 ##주 ##한 시간 ##을 보냈 ##는 ##데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것 ##이 아닌가 하 ##는 의견 ##도 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 18:0 19:0 20:1 21:1 22:2 23:2 24:3 25:3 26:4 27:5 28:5 29:6 30:7 31:7 32:8 33:8 34:9 35:10 36:11 37:11 38:12 39:13 40:13 41:14 42:14 43:15 44:15 45:15 46:16 47:16 48:17 49:17 50:17 51:17 52:18 53:19 54:20 55:20 56:21 57:21 58:21 59:22 60:23 61:23 62:23 63:24 64:24 65:24 66:24 67:24 68:25 69:26 70:27 71:27 72:27 73:28 74:28 75:29 76:29 77:30 78:30 79:30 80:30 81:31 82:31 83:31 84:31 85:31 86:31 87:32 88:32 89:33 90:33 91:34 92:34 93:34 94:35 95:35 96:35 97:36 98:36 99:37 100:38 101:38 102:38 103:39 104:39 105:39 106:39 107:40 108:40 109:41 110:42 111:43 112:43 113:44 114:44 115:44 116:45 117:45 118:46 119:47 120:47 121:47 122:48 123:48 124:49 125:49 126:50 127:50 128:51 129:51 130:51 131:51 132:51 133:52 134:52 135:53 136:54 137:54 138:54 139:55 140:55 141:56 142:56 143:57 144:58 145:59 146:59 147:60 148:60 149:60 150:61 151:61 152:62 153:62 154:62 155:62 156:63 157:63 158:64 159:64 160:65 161:65 162:66 163:66 164:66 165:67 166:67 167:68 168:68 169:68 170:69 171:69 172:70 173:70 174:70 175:71 176:71 177:72 178:72 179:73 180:74 181:74 182:75 183:75 184:76 185:76 186:77 187:77 188:78 189:78 190:79 191:79 192:79 193:80 194:80 195:81 196:81 197:82 198:82 199:83 200:83 201:84 202:84 203:84 204:84 205:85 206:85 207:86 208:86 209:87 210:87 211:88 212:88 213:89 214:90 215:91 216:91 217:91 218:92 219:92 220:93 221:94 222:94 223:95 224:95 225:95 226:96 227:96 228:96 229:97 230:98 231:98 232:98 233:99 234:99 235:99 236:99 237:100 238:100 239:100 240:100 241:101 242:102 243:102 244:103 245:103 246:103 247:103 248:104 249:105 250:105 251:106 252:106 253:107 254:107 255:108 256:108 257:109 258:110 259:110 260:110 261:110 262:110 263:110 264:110 265:111 266:112 267:112 268:113 269:113 270:113 271:114 272:114 273:115 274:115 275:115 276:115 277:116 278:116 279:116 280:116 281:116 282:116 283:117 284:117 285:118 286:118 287:118 288:118 289:119 290:119 291:119 292:119 293:120 294:121 295:121 296:122 297:122 298:123 299:123 300:124 301:125 302:125 303:126 304:126 305:126 306:127 307:127 308:127 309:127 310:128 311:128 312:128 313:129 314:129 315:129 316:129 317:130 318:130 319:131 320:132 321:132 322:132 323:133 324:133 325:133 326:133 327:134 328:135 329:135 330:136 331:136 332:137 333:137 334:137 335:137 336:138 337:138 338:138 339:139 340:139 341:140 342:140 343:140 344:141 345:141 346:141 347:141 348:141 349:141 350:142 351:142 352:142 353:143 354:144 355:144 356:144 357:145 358:145 359:146 360:146 361:146 362:146 363:147 364:148 365:149 366:149 367:150 368:151 369:151 370:152 371:152 372:153 373:154 374:154 375:155 376:156 377:156 378:157 379:157 380:158 381:158 382:158\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 10404 28139 17 28448 28190 28139 8792 28151 3990 28149 1403 28177 28182 28140 28146 1132 3 13791 28165 10404 28140 21474 28139 23793 28144 456 2038 28147 36 726 28137 1192 28135 7173 6832 1880 28141 672 359 28139 5964 28144 406 28318 28140 667 28144 540 28140 28136 9 7 817 10404 28140 19804 28165 28137 1236 201 28784 17099 249 28178 28172 28178 28144 10 1 860 28135 28173 7490 28183 8370 28137 6316 28195 28153 28215 336 4159 28331 28901 800 28154 1485 28140 23793 28139 366 28221 28137 9404 28195 14548 77 9 255 1584 28137 28149 15434 28413 28299 28139 1036 28141 1584 15005 13266 28135 1403 28142 28140 10722 28139 5964 183 28365 28144 2023 28147 1433 28151 17925 28144 132 28354 28140 28270 13 586 28135 1541 17 28210 28137 23793 28139 25727 17099 11036 7 525 28137 2593 28135 1526 553 28144 8418 28153 28159 8338 64 28151 3710 28297 8297 28146 165 28136 9 783 28139 59 28273 28212 1900 28139 278 28137 28160 36 28139 1150 28137 8990 28 28140 64 14949 1729 28150 1351 28191 10929 28175 167 28139 28146 3431 28255 64 28135 373 28173 10722 28139 8118 28235 28414 28473 1900 28139 553 28144 132 28151 64 28144 535 46 28 28136 9 1361 28199 5964 1339 28144 13791 28165 342 1058 28165 28137 1341 1584 28137 28149 6058 28195 28153 28175 17 28448 28190 28144 1607 308 28137 1899 28195 28136 9 255 525 28139 1724 28183 852 28137 36 28140 7 25727 24 17 28448 28190 23 14 1584 15005 28139 13723 28137 28149 1403 28297 4016 28207 28348 28148 1489 28142 28201 28153 28175 13 1570 28140 455 12050 28148 28140 122 28354 28136 9 700 8792 28151 101 28165 161 28135 2062 103 28137 18694 28137 28149 1403 28177 28182 28147 184 28249 28160 455 19252 539 13 186 28137 1615 11181 28177 28147 172 28354 28136 9 36 319 28137 36 28140 189 28546 28247 28198 20222 28142 28140 23270 28144 1724 28142 28147 644 28302 28135 28400 28137 28160 6058 28142 28140 78 137 28186 28150 473 28144 1951 28140 28270 13 1514 23346 742 28135 7 595 28144 6294 28199 22 64 28135 12039 15 28140 1904 28160 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 303\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 303\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 드레스덴\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000008\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 8\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 바그너 ##의 작품 ##을 시인 ##의 피로 쓰여졌 ##다고 극찬 ##한 것 ##은 누구 ##인 ##가 ? [SEP] 한편 1840 ##년 ##부터 바그너 ##와 알 ##고 지내 ##던 리스트 ##가 잊혀 ##져 있 ##던 1 ##악 ##장 ##을 부활 ##시 ##켜 1852 ##년 ##에 바이마르 ##에 ##서 연주 ##했 ##다 . 이것 ##을 계기 ##로 바그너 ##도 이 작품 ##에 다시 관심 ##을 갖 ##게 되 ##었 ##고 , 그 해 9 ##월 ##에 ##는 총 ##보 ##의 반환 ##을 요구 ##하여 이를 서곡 ##으로 간 ##추 ##린 다음 수정 ##을 했 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##서 출판 ##할 개정판 ##도 준비 ##했 ##다 . 1853 ##년 5 ##월 ##에 ##는 리스트 ##가 이 작품 ##이 수정 ##되 ##었 ##다는 것 ##을 인정 ##했 ##지만 , 끝내 바그너 ##의 출판 계획 ##은 무산 ##되 ##고 말 ##았 ##다 . 이후 1855 ##년 ##에 리스트 ##가 자신 ##의 작품 파우스트 교향곡 ##을 거의 완성 ##하여 그 사실 ##을 바그너 ##에 ##게 알렸 ##고 , 바그너 ##는 다시 개정 ##된 총 ##보 ##를 리스트 ##에 ##게 보내 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##는 20 ##루이 ##의 금 ##을 받 ##고 팔 ##았 ##다 . 또한 그 ##의 작품 ##을 “ 하나하나 ##의 음 ##표 ##가 시인 ##의 피로 쓰여졌 ##다 ” 며 극찬 ##했 ##던 한스 폰 [UNK] 그것 ##을 피아노 독주 ##용 ##으로 편곡 ##했 ##는 ##데 , 리스트 ##는 그것 ##을 약간 변형 ##되 ##었 ##을 뿐 ##이 ##라고 지적 ##했 ##다 . 이 서곡 ##의 총 ##보 첫 ##머리 ##에 ##는 파우스트 1 ##부 ##의 내용 중 한 구절 ##을 인용 ##하 ##고 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 19:0 20:1 21:1 22:1 23:2 24:2 25:3 26:3 27:4 28:4 29:5 30:5 31:6 32:6 33:7 34:7 35:8 36:8 37:8 38:8 39:9 40:9 41:9 42:10 43:10 44:10 45:11 46:11 47:11 48:12 49:12 50:12 51:12 52:13 53:13 54:14 55:14 56:15 57:15 58:16 59:17 60:17 61:18 62:19 63:19 64:20 65:20 66:21 67:21 68:21 69:21 70:22 71:23 72:24 73:24 74:24 75:24 76:25 77:25 78:25 79:26 80:26 81:27 82:27 83:28 84:29 85:29 86:30 87:30 88:30 89:31 90:32 91:32 92:33 93:33 94:34 95:34 96:34 97:34 98:35 99:36 100:36 101:37 102:37 103:37 104:38 105:38 106:39 107:39 108:40 109:40 110:40 111:40 112:41 113:41 114:42 115:42 116:42 117:42 118:43 119:43 120:44 121:45 122:45 123:46 124:46 125:46 126:46 127:47 128:47 129:48 130:48 131:48 132:48 133:49 134:50 135:50 136:51 137:52 138:52 139:53 140:53 141:53 142:54 143:54 144:54 145:54 146:55 147:56 148:56 149:56 150:57 151:57 152:58 153:58 154:59 155:60 156:61 157:61 158:62 159:63 160:63 161:64 162:65 163:65 164:66 165:66 166:66 167:67 168:67 169:67 170:68 171:68 172:69 173:70 174:70 175:71 176:71 177:71 178:72 179:72 180:72 181:73 182:73 183:74 184:74 185:74 186:74 187:75 188:76 189:76 190:77 191:77 192:77 193:78 194:78 195:78 196:79 197:79 198:80 199:80 200:81 201:81 202:81 203:81 204:82 205:83 206:83 207:84 208:84 209:85 210:85 211:85 212:86 213:86 214:86 215:87 216:87 217:88 218:89 219:89 220:89 221:89 222:90 223:90 224:90 225:91 226:92 227:93 228:94 229:94 230:95 231:96 232:96 233:96 234:97 235:97 236:97 237:97 238:97 239:98 240:98 241:99 242:99 243:100 244:101 245:101 246:101 247:101 248:102 249:102 250:102 251:103 252:103 253:103 254:103 255:104 256:105 257:105 258:106 259:106 260:107 261:107 262:107 263:107 264:108 265:109 266:109 267:109 268:110 269:111 270:112 271:113 272:113 273:114 274:114 275:114 276:115 277:115 278:115\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 10404 28139 525 28144 2761 28139 10929 20432 14548 13444 28150 64 28151 3328 28164 28146 1132 3 693 12103 28165 342 10404 28198 173 28147 2208 28317 7293 28146 18358 28465 28 28317 17 28448 28190 28144 2907 28158 28705 16268 28165 28137 14640 28137 28149 1403 28195 28136 9 586 28144 1939 28141 10404 28160 7 525 28137 378 1323 28144 540 28199 31 28182 28147 13 36 63 183 28210 28137 28140 276 28207 28139 5448 28144 930 91 6832 25727 17099 212 28381 28408 320 2091 28144 47 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28149 1449 28297 22140 28160 1489 28195 28136 9 16026 28165 106 28210 28137 28140 7293 28146 7 525 28135 2091 28177 28182 3654 64 28144 825 28195 539 13 3372 10404 28139 1449 665 28151 5521 28177 28147 172 28354 28136 9 186 14866 28165 28137 7293 28146 285 28139 525 23793 5964 28144 828 1724 91 36 593 28144 10404 28137 28199 6581 28147 13 10404 28140 378 1931 28255 276 28207 28154 7293 28137 28199 1094 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28140 56 17814 28139 375 28144 132 28147 807 28354 28136 9 255 36 28139 525 28144 547 19108 28139 205 28324 28146 2761 28139 10929 20432 28136 550 96 13444 28195 28317 9851 2453 1 898 28144 4254 15416 28250 17099 6534 28195 28140 28270 13 7293 28140 898 28144 2036 3603 28177 28182 28144 676 28135 6619 2029 28195 28136 9 7 25727 28139 276 28207 402 4755 28137 28140 23793 17 28176 28139 726 62 22 8981 28144 4304 28142 28147 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 225\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 227\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 한스 폰 [UNK]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000009\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 9\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 잊혀 ##져 있 ##는 파우스트 서곡 1 ##악 ##장 ##을 부활 ##시 ##킨 것 ##은 누구 ##인 ##가 ? [SEP] 한편 1840 ##년 ##부터 바그너 ##와 알 ##고 지내 ##던 리스트 ##가 잊혀 ##져 있 ##던 1 ##악 ##장 ##을 부활 ##시 ##켜 1852 ##년 ##에 바이마르 ##에 ##서 연주 ##했 ##다 . 이것 ##을 계기 ##로 바그너 ##도 이 작품 ##에 다시 관심 ##을 갖 ##게 되 ##었 ##고 , 그 해 9 ##월 ##에 ##는 총 ##보 ##의 반환 ##을 요구 ##하여 이를 서곡 ##으로 간 ##추 ##린 다음 수정 ##을 했 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##서 출판 ##할 개정판 ##도 준비 ##했 ##다 . 1853 ##년 5 ##월 ##에 ##는 리스트 ##가 이 작품 ##이 수정 ##되 ##었 ##다는 것 ##을 인정 ##했 ##지만 , 끝내 바그너 ##의 출판 계획 ##은 무산 ##되 ##고 말 ##았 ##다 . 이후 1855 ##년 ##에 리스트 ##가 자신 ##의 작품 파우스트 교향곡 ##을 거의 완성 ##하여 그 사실 ##을 바그너 ##에 ##게 알렸 ##고 , 바그너 ##는 다시 개정 ##된 총 ##보 ##를 리스트 ##에 ##게 보내 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##는 20 ##루이 ##의 금 ##을 받 ##고 팔 ##았 ##다 . 또한 그 ##의 작품 ##을 “ 하나하나 ##의 음 ##표 ##가 시인 ##의 피로 쓰여졌 ##다 ” 며 극찬 ##했 ##던 한스 폰 [UNK] 그것 ##을 피아노 독주 ##용 ##으로 편곡 ##했 ##는 ##데 , 리스트 ##는 그것 ##을 약간 변형 ##되 ##었 ##을 뿐 ##이 ##라고 지적 ##했 ##다 . 이 서곡 ##의 총 ##보 첫 ##머리 ##에 ##는 파우스트 1 ##부 ##의 내용 중 한 구절 ##을 인용 ##하 ##고 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 21:0 22:1 23:1 24:1 25:2 26:2 27:3 28:3 29:4 30:4 31:5 32:5 33:6 34:6 35:7 36:7 37:8 38:8 39:8 40:8 41:9 42:9 43:9 44:10 45:10 46:10 47:11 48:11 49:11 50:12 51:12 52:12 53:12 54:13 55:13 56:14 57:14 58:15 59:15 60:16 61:17 62:17 63:18 64:19 65:19 66:20 67:20 68:21 69:21 70:21 71:21 72:22 73:23 74:24 75:24 76:24 77:24 78:25 79:25 80:25 81:26 82:26 83:27 84:27 85:28 86:29 87:29 88:30 89:30 90:30 91:31 92:32 93:32 94:33 95:33 96:34 97:34 98:34 99:34 100:35 101:36 102:36 103:37 104:37 105:37 106:38 107:38 108:39 109:39 110:40 111:40 112:40 113:40 114:41 115:41 116:42 117:42 118:42 119:42 120:43 121:43 122:44 123:45 124:45 125:46 126:46 127:46 128:46 129:47 130:47 131:48 132:48 133:48 134:48 135:49 136:50 137:50 138:51 139:52 140:52 141:53 142:53 143:53 144:54 145:54 146:54 147:54 148:55 149:56 150:56 151:56 152:57 153:57 154:58 155:58 156:59 157:60 158:61 159:61 160:62 161:63 162:63 163:64 164:65 165:65 166:66 167:66 168:66 169:67 170:67 171:67 172:68 173:68 174:69 175:70 176:70 177:71 178:71 179:71 180:72 181:72 182:72 183:73 184:73 185:74 186:74 187:74 188:74 189:75 190:76 191:76 192:77 193:77 194:77 195:78 196:78 197:78 198:79 199:79 200:80 201:80 202:81 203:81 204:81 205:81 206:82 207:83 208:83 209:84 210:84 211:85 212:85 213:85 214:86 215:86 216:86 217:87 218:87 219:88 220:89 221:89 222:89 223:89 224:90 225:90 226:90 227:91 228:92 229:93 230:94 231:94 232:95 233:96 234:96 235:96 236:97 237:97 238:97 239:97 240:97 241:98 242:98 243:99 244:99 245:100 246:101 247:101 248:101 249:101 250:102 251:102 252:102 253:103 254:103 255:103 256:103 257:104 258:105 259:105 260:106 261:106 262:107 263:107 264:107 265:107 266:108 267:109 268:109 269:109 270:110 271:111 272:112 273:113 274:113 275:114 276:114 277:114 278:115 279:115 280:115\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 18358 28465 28 28140 23793 25727 17 28448 28190 28144 2907 28158 28673 64 28151 3328 28164 28146 1132 3 693 12103 28165 342 10404 28198 173 28147 2208 28317 7293 28146 18358 28465 28 28317 17 28448 28190 28144 2907 28158 28705 16268 28165 28137 14640 28137 28149 1403 28195 28136 9 586 28144 1939 28141 10404 28160 7 525 28137 378 1323 28144 540 28199 31 28182 28147 13 36 63 183 28210 28137 28140 276 28207 28139 5448 28144 930 91 6832 25727 17099 212 28381 28408 320 2091 28144 47 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28149 1449 28297 22140 28160 1489 28195 28136 9 16026 28165 106 28210 28137 28140 7293 28146 7 525 28135 2091 28177 28182 3654 64 28144 825 28195 539 13 3372 10404 28139 1449 665 28151 5521 28177 28147 172 28354 28136 9 186 14866 28165 28137 7293 28146 285 28139 525 23793 5964 28144 828 1724 91 36 593 28144 10404 28137 28199 6581 28147 13 10404 28140 378 1931 28255 276 28207 28154 7293 28137 28199 1094 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28140 56 17814 28139 375 28144 132 28147 807 28354 28136 9 255 36 28139 525 28144 547 19108 28139 205 28324 28146 2761 28139 10929 20432 28136 550 96 13444 28195 28317 9851 2453 1 898 28144 4254 15416 28250 17099 6534 28195 28140 28270 13 7293 28140 898 28144 2036 3603 28177 28182 28144 676 28135 6619 2029 28195 28136 9 7 25727 28139 276 28207 402 4755 28137 28140 23793 17 28176 28139 726 62 22 8981 28144 4304 28142 28147 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 31\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 31\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 리스트\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000010\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 10\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 바그너 ##는 다시 개정 ##된 총 ##보 ##를 얼마 ##를 받 ##고 팔 ##았 ##는 ##가 ? [SEP] 한편 1840 ##년 ##부터 바그너 ##와 알 ##고 지내 ##던 리스트 ##가 잊혀 ##져 있 ##던 1 ##악 ##장 ##을 부활 ##시 ##켜 1852 ##년 ##에 바이마르 ##에 ##서 연주 ##했 ##다 . 이것 ##을 계기 ##로 바그너 ##도 이 작품 ##에 다시 관심 ##을 갖 ##게 되 ##었 ##고 , 그 해 9 ##월 ##에 ##는 총 ##보 ##의 반환 ##을 요구 ##하여 이를 서곡 ##으로 간 ##추 ##린 다음 수정 ##을 했 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##서 출판 ##할 개정판 ##도 준비 ##했 ##다 . 1853 ##년 5 ##월 ##에 ##는 리스트 ##가 이 작품 ##이 수정 ##되 ##었 ##다는 것 ##을 인정 ##했 ##지만 , 끝내 바그너 ##의 출판 계획 ##은 무산 ##되 ##고 말 ##았 ##다 . 이후 1855 ##년 ##에 리스트 ##가 자신 ##의 작품 파우스트 교향곡 ##을 거의 완성 ##하여 그 사실 ##을 바그너 ##에 ##게 알렸 ##고 , 바그너 ##는 다시 개정 ##된 총 ##보 ##를 리스트 ##에 ##게 보내 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##는 20 ##루이 ##의 금 ##을 받 ##고 팔 ##았 ##다 . 또한 그 ##의 작품 ##을 “ 하나하나 ##의 음 ##표 ##가 시인 ##의 피로 쓰여졌 ##다 ” 며 극찬 ##했 ##던 한스 폰 [UNK] 그것 ##을 피아노 독주 ##용 ##으로 편곡 ##했 ##는 ##데 , 리스트 ##는 그것 ##을 약간 변형 ##되 ##었 ##을 뿐 ##이 ##라고 지적 ##했 ##다 . 이 서곡 ##의 총 ##보 첫 ##머리 ##에 ##는 파우스트 1 ##부 ##의 내용 중 한 구절 ##을 인용 ##하 ##고 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 19:0 20:1 21:1 22:1 23:2 24:2 25:3 26:3 27:4 28:4 29:5 30:5 31:6 32:6 33:7 34:7 35:8 36:8 37:8 38:8 39:9 40:9 41:9 42:10 43:10 44:10 45:11 46:11 47:11 48:12 49:12 50:12 51:12 52:13 53:13 54:14 55:14 56:15 57:15 58:16 59:17 60:17 61:18 62:19 63:19 64:20 65:20 66:21 67:21 68:21 69:21 70:22 71:23 72:24 73:24 74:24 75:24 76:25 77:25 78:25 79:26 80:26 81:27 82:27 83:28 84:29 85:29 86:30 87:30 88:30 89:31 90:32 91:32 92:33 93:33 94:34 95:34 96:34 97:34 98:35 99:36 100:36 101:37 102:37 103:37 104:38 105:38 106:39 107:39 108:40 109:40 110:40 111:40 112:41 113:41 114:42 115:42 116:42 117:42 118:43 119:43 120:44 121:45 122:45 123:46 124:46 125:46 126:46 127:47 128:47 129:48 130:48 131:48 132:48 133:49 134:50 135:50 136:51 137:52 138:52 139:53 140:53 141:53 142:54 143:54 144:54 145:54 146:55 147:56 148:56 149:56 150:57 151:57 152:58 153:58 154:59 155:60 156:61 157:61 158:62 159:63 160:63 161:64 162:65 163:65 164:66 165:66 166:66 167:67 168:67 169:67 170:68 171:68 172:69 173:70 174:70 175:71 176:71 177:71 178:72 179:72 180:72 181:73 182:73 183:74 184:74 185:74 186:74 187:75 188:76 189:76 190:77 191:77 192:77 193:78 194:78 195:78 196:79 197:79 198:80 199:80 200:81 201:81 202:81 203:81 204:82 205:83 206:83 207:84 208:84 209:85 210:85 211:85 212:86 213:86 214:86 215:87 216:87 217:88 218:89 219:89 220:89 221:89 222:90 223:90 224:90 225:91 226:92 227:93 228:94 229:94 230:95 231:96 232:96 233:96 234:97 235:97 236:97 237:97 238:97 239:98 240:98 241:99 242:99 243:100 244:101 245:101 246:101 247:101 248:102 249:102 250:102 251:103 252:103 253:103 254:103 255:104 256:105 257:105 258:106 259:106 260:107 261:107 262:107 263:107 264:108 265:109 266:109 267:109 268:110 269:111 270:112 271:113 272:113 273:114 274:114 275:114 276:115 277:115 278:115\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 10404 28140 378 1931 28255 276 28207 28154 1914 28154 132 28147 807 28354 28140 28146 1132 3 693 12103 28165 342 10404 28198 173 28147 2208 28317 7293 28146 18358 28465 28 28317 17 28448 28190 28144 2907 28158 28705 16268 28165 28137 14640 28137 28149 1403 28195 28136 9 586 28144 1939 28141 10404 28160 7 525 28137 378 1323 28144 540 28199 31 28182 28147 13 36 63 183 28210 28137 28140 276 28207 28139 5448 28144 930 91 6832 25727 17099 212 28381 28408 320 2091 28144 47 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28149 1449 28297 22140 28160 1489 28195 28136 9 16026 28165 106 28210 28137 28140 7293 28146 7 525 28135 2091 28177 28182 3654 64 28144 825 28195 539 13 3372 10404 28139 1449 665 28151 5521 28177 28147 172 28354 28136 9 186 14866 28165 28137 7293 28146 285 28139 525 23793 5964 28144 828 1724 91 36 593 28144 10404 28137 28199 6581 28147 13 10404 28140 378 1931 28255 276 28207 28154 7293 28137 28199 1094 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28140 56 17814 28139 375 28144 132 28147 807 28354 28136 9 255 36 28139 525 28144 547 19108 28139 205 28324 28146 2761 28139 10929 20432 28136 550 96 13444 28195 28317 9851 2453 1 898 28144 4254 15416 28250 17099 6534 28195 28140 28270 13 7293 28140 898 28144 2036 3603 28177 28182 28144 676 28135 6619 2029 28195 28136 9 7 25727 28139 276 28207 402 4755 28137 28140 23793 17 28176 28139 726 62 22 8981 28144 4304 28142 28147 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 193\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 196\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 20 ##루이 ##의 금\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000011\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 11\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 파우스트 교향곡 ##을 부활 ##시 ##킨 사람 ##은 ? [SEP] 한편 1840 ##년 ##부터 바그너 ##와 알 ##고 지내 ##던 리스트 ##가 잊혀 ##져 있 ##던 1 ##악 ##장 ##을 부활 ##시 ##켜 1852 ##년 ##에 바이마르 ##에 ##서 연주 ##했 ##다 . 이것 ##을 계기 ##로 바그너 ##도 이 작품 ##에 다시 관심 ##을 갖 ##게 되 ##었 ##고 , 그 해 9 ##월 ##에 ##는 총 ##보 ##의 반환 ##을 요구 ##하여 이를 서곡 ##으로 간 ##추 ##린 다음 수정 ##을 했 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##서 출판 ##할 개정판 ##도 준비 ##했 ##다 . 1853 ##년 5 ##월 ##에 ##는 리스트 ##가 이 작품 ##이 수정 ##되 ##었 ##다는 것 ##을 인정 ##했 ##지만 , 끝내 바그너 ##의 출판 계획 ##은 무산 ##되 ##고 말 ##았 ##다 . 이후 1855 ##년 ##에 리스트 ##가 자신 ##의 작품 파우스트 교향곡 ##을 거의 완성 ##하여 그 사실 ##을 바그너 ##에 ##게 알렸 ##고 , 바그너 ##는 다시 개정 ##된 총 ##보 ##를 리스트 ##에 ##게 보내 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##는 20 ##루이 ##의 금 ##을 받 ##고 팔 ##았 ##다 . 또한 그 ##의 작품 ##을 “ 하나하나 ##의 음 ##표 ##가 시인 ##의 피로 쓰여졌 ##다 ” 며 극찬 ##했 ##던 한스 폰 [UNK] 그것 ##을 피아노 독주 ##용 ##으로 편곡 ##했 ##는 ##데 , 리스트 ##는 그것 ##을 약간 변형 ##되 ##었 ##을 뿐 ##이 ##라고 지적 ##했 ##다 . 이 서곡 ##의 총 ##보 첫 ##머리 ##에 ##는 파우스트 1 ##부 ##의 내용 중 한 구절 ##을 인용 ##하 ##고 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 11:0 12:1 13:1 14:1 15:2 16:2 17:3 18:3 19:4 20:4 21:5 22:5 23:6 24:6 25:7 26:7 27:8 28:8 29:8 30:8 31:9 32:9 33:9 34:10 35:10 36:10 37:11 38:11 39:11 40:12 41:12 42:12 43:12 44:13 45:13 46:14 47:14 48:15 49:15 50:16 51:17 52:17 53:18 54:19 55:19 56:20 57:20 58:21 59:21 60:21 61:21 62:22 63:23 64:24 65:24 66:24 67:24 68:25 69:25 70:25 71:26 72:26 73:27 74:27 75:28 76:29 77:29 78:30 79:30 80:30 81:31 82:32 83:32 84:33 85:33 86:34 87:34 88:34 89:34 90:35 91:36 92:36 93:37 94:37 95:37 96:38 97:38 98:39 99:39 100:40 101:40 102:40 103:40 104:41 105:41 106:42 107:42 108:42 109:42 110:43 111:43 112:44 113:45 114:45 115:46 116:46 117:46 118:46 119:47 120:47 121:48 122:48 123:48 124:48 125:49 126:50 127:50 128:51 129:52 130:52 131:53 132:53 133:53 134:54 135:54 136:54 137:54 138:55 139:56 140:56 141:56 142:57 143:57 144:58 145:58 146:59 147:60 148:61 149:61 150:62 151:63 152:63 153:64 154:65 155:65 156:66 157:66 158:66 159:67 160:67 161:67 162:68 163:68 164:69 165:70 166:70 167:71 168:71 169:71 170:72 171:72 172:72 173:73 174:73 175:74 176:74 177:74 178:74 179:75 180:76 181:76 182:77 183:77 184:77 185:78 186:78 187:78 188:79 189:79 190:80 191:80 192:81 193:81 194:81 195:81 196:82 197:83 198:83 199:84 200:84 201:85 202:85 203:85 204:86 205:86 206:86 207:87 208:87 209:88 210:89 211:89 212:89 213:89 214:90 215:90 216:90 217:91 218:92 219:93 220:94 221:94 222:95 223:96 224:96 225:96 226:97 227:97 228:97 229:97 230:97 231:98 232:98 233:99 234:99 235:100 236:101 237:101 238:101 239:101 240:102 241:102 242:102 243:103 244:103 245:103 246:103 247:104 248:105 249:105 250:106 251:106 252:107 253:107 254:107 255:107 256:108 257:109 258:109 259:109 260:110 261:111 262:112 263:113 264:113 265:114 266:114 267:114 268:115 269:115 270:115\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 23793 5964 28144 2907 28158 28673 267 28151 1132 3 693 12103 28165 342 10404 28198 173 28147 2208 28317 7293 28146 18358 28465 28 28317 17 28448 28190 28144 2907 28158 28705 16268 28165 28137 14640 28137 28149 1403 28195 28136 9 586 28144 1939 28141 10404 28160 7 525 28137 378 1323 28144 540 28199 31 28182 28147 13 36 63 183 28210 28137 28140 276 28207 28139 5448 28144 930 91 6832 25727 17099 212 28381 28408 320 2091 28144 47 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28149 1449 28297 22140 28160 1489 28195 28136 9 16026 28165 106 28210 28137 28140 7293 28146 7 525 28135 2091 28177 28182 3654 64 28144 825 28195 539 13 3372 10404 28139 1449 665 28151 5521 28177 28147 172 28354 28136 9 186 14866 28165 28137 7293 28146 285 28139 525 23793 5964 28144 828 1724 91 36 593 28144 10404 28137 28199 6581 28147 13 10404 28140 378 1931 28255 276 28207 28154 7293 28137 28199 1094 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28140 56 17814 28139 375 28144 132 28147 807 28354 28136 9 255 36 28139 525 28144 547 19108 28139 205 28324 28146 2761 28139 10929 20432 28136 550 96 13444 28195 28317 9851 2453 1 898 28144 4254 15416 28250 17099 6534 28195 28140 28270 13 7293 28140 898 28144 2036 3603 28177 28182 28144 676 28135 6619 2029 28195 28136 9 7 25727 28139 276 28207 402 4755 28137 28140 23793 17 28176 28139 726 62 22 8981 28144 4304 28142 28147 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 21\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 21\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 리스트\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000012\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 12\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 파우스트 교향곡 ##을 피아노 독주 ##용 ##으로 편곡 ##한 사람 ##은 ? [SEP] 한편 1840 ##년 ##부터 바그너 ##와 알 ##고 지내 ##던 리스트 ##가 잊혀 ##져 있 ##던 1 ##악 ##장 ##을 부활 ##시 ##켜 1852 ##년 ##에 바이마르 ##에 ##서 연주 ##했 ##다 . 이것 ##을 계기 ##로 바그너 ##도 이 작품 ##에 다시 관심 ##을 갖 ##게 되 ##었 ##고 , 그 해 9 ##월 ##에 ##는 총 ##보 ##의 반환 ##을 요구 ##하여 이를 서곡 ##으로 간 ##추 ##린 다음 수정 ##을 했 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##서 출판 ##할 개정판 ##도 준비 ##했 ##다 . 1853 ##년 5 ##월 ##에 ##는 리스트 ##가 이 작품 ##이 수정 ##되 ##었 ##다는 것 ##을 인정 ##했 ##지만 , 끝내 바그너 ##의 출판 계획 ##은 무산 ##되 ##고 말 ##았 ##다 . 이후 1855 ##년 ##에 리스트 ##가 자신 ##의 작품 파우스트 교향곡 ##을 거의 완성 ##하여 그 사실 ##을 바그너 ##에 ##게 알렸 ##고 , 바그너 ##는 다시 개정 ##된 총 ##보 ##를 리스트 ##에 ##게 보내 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##는 20 ##루이 ##의 금 ##을 받 ##고 팔 ##았 ##다 . 또한 그 ##의 작품 ##을 “ 하나하나 ##의 음 ##표 ##가 시인 ##의 피로 쓰여졌 ##다 ” 며 극찬 ##했 ##던 한스 폰 [UNK] 그것 ##을 피아노 독주 ##용 ##으로 편곡 ##했 ##는 ##데 , 리스트 ##는 그것 ##을 약간 변형 ##되 ##었 ##을 뿐 ##이 ##라고 지적 ##했 ##다 . 이 서곡 ##의 총 ##보 첫 ##머리 ##에 ##는 파우스트 1 ##부 ##의 내용 중 한 구절 ##을 인용 ##하 ##고 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 14:0 15:1 16:1 17:1 18:2 19:2 20:3 21:3 22:4 23:4 24:5 25:5 26:6 27:6 28:7 29:7 30:8 31:8 32:8 33:8 34:9 35:9 36:9 37:10 38:10 39:10 40:11 41:11 42:11 43:12 44:12 45:12 46:12 47:13 48:13 49:14 50:14 51:15 52:15 53:16 54:17 55:17 56:18 57:19 58:19 59:20 60:20 61:21 62:21 63:21 64:21 65:22 66:23 67:24 68:24 69:24 70:24 71:25 72:25 73:25 74:26 75:26 76:27 77:27 78:28 79:29 80:29 81:30 82:30 83:30 84:31 85:32 86:32 87:33 88:33 89:34 90:34 91:34 92:34 93:35 94:36 95:36 96:37 97:37 98:37 99:38 100:38 101:39 102:39 103:40 104:40 105:40 106:40 107:41 108:41 109:42 110:42 111:42 112:42 113:43 114:43 115:44 116:45 117:45 118:46 119:46 120:46 121:46 122:47 123:47 124:48 125:48 126:48 127:48 128:49 129:50 130:50 131:51 132:52 133:52 134:53 135:53 136:53 137:54 138:54 139:54 140:54 141:55 142:56 143:56 144:56 145:57 146:57 147:58 148:58 149:59 150:60 151:61 152:61 153:62 154:63 155:63 156:64 157:65 158:65 159:66 160:66 161:66 162:67 163:67 164:67 165:68 166:68 167:69 168:70 169:70 170:71 171:71 172:71 173:72 174:72 175:72 176:73 177:73 178:74 179:74 180:74 181:74 182:75 183:76 184:76 185:77 186:77 187:77 188:78 189:78 190:78 191:79 192:79 193:80 194:80 195:81 196:81 197:81 198:81 199:82 200:83 201:83 202:84 203:84 204:85 205:85 206:85 207:86 208:86 209:86 210:87 211:87 212:88 213:89 214:89 215:89 216:89 217:90 218:90 219:90 220:91 221:92 222:93 223:94 224:94 225:95 226:96 227:96 228:96 229:97 230:97 231:97 232:97 233:97 234:98 235:98 236:99 237:99 238:100 239:101 240:101 241:101 242:101 243:102 244:102 245:102 246:103 247:103 248:103 249:103 250:104 251:105 252:105 253:106 254:106 255:107 256:107 257:107 258:107 259:108 260:109 261:109 262:109 263:110 264:111 265:112 266:113 267:113 268:114 269:114 270:114 271:115 272:115 273:115\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 23793 5964 28144 4254 15416 28250 17099 6534 28150 267 28151 1132 3 693 12103 28165 342 10404 28198 173 28147 2208 28317 7293 28146 18358 28465 28 28317 17 28448 28190 28144 2907 28158 28705 16268 28165 28137 14640 28137 28149 1403 28195 28136 9 586 28144 1939 28141 10404 28160 7 525 28137 378 1323 28144 540 28199 31 28182 28147 13 36 63 183 28210 28137 28140 276 28207 28139 5448 28144 930 91 6832 25727 17099 212 28381 28408 320 2091 28144 47 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28149 1449 28297 22140 28160 1489 28195 28136 9 16026 28165 106 28210 28137 28140 7293 28146 7 525 28135 2091 28177 28182 3654 64 28144 825 28195 539 13 3372 10404 28139 1449 665 28151 5521 28177 28147 172 28354 28136 9 186 14866 28165 28137 7293 28146 285 28139 525 23793 5964 28144 828 1724 91 36 593 28144 10404 28137 28199 6581 28147 13 10404 28140 378 1931 28255 276 28207 28154 7293 28137 28199 1094 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28140 56 17814 28139 375 28144 132 28147 807 28354 28136 9 255 36 28139 525 28144 547 19108 28139 205 28324 28146 2761 28139 10929 20432 28136 550 96 13444 28195 28317 9851 2453 1 898 28144 4254 15416 28250 17099 6534 28195 28140 28270 13 7293 28140 898 28144 2036 3603 28177 28182 28144 676 28135 6619 2029 28195 28136 9 7 25727 28139 276 28207 402 4755 28137 28140 23793 17 28176 28139 726 62 22 8981 28144 4304 28142 28147 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 220\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 222\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 한스 폰 [UNK]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000013\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 13\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 1 ##악 ##장 ##을 부활 ##시 ##켜 연주 ##한 사람 ##은 ? [SEP] 한편 1840 ##년 ##부터 바그너 ##와 알 ##고 지내 ##던 리스트 ##가 잊혀 ##져 있 ##던 1 ##악 ##장 ##을 부활 ##시 ##켜 1852 ##년 ##에 바이마르 ##에 ##서 연주 ##했 ##다 . 이것 ##을 계기 ##로 바그너 ##도 이 작품 ##에 다시 관심 ##을 갖 ##게 되 ##었 ##고 , 그 해 9 ##월 ##에 ##는 총 ##보 ##의 반환 ##을 요구 ##하여 이를 서곡 ##으로 간 ##추 ##린 다음 수정 ##을 했 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##서 출판 ##할 개정판 ##도 준비 ##했 ##다 . 1853 ##년 5 ##월 ##에 ##는 리스트 ##가 이 작품 ##이 수정 ##되 ##었 ##다는 것 ##을 인정 ##했 ##지만 , 끝내 바그너 ##의 출판 계획 ##은 무산 ##되 ##고 말 ##았 ##다 . 이후 1855 ##년 ##에 리스트 ##가 자신 ##의 작품 파우스트 교향곡 ##을 거의 완성 ##하여 그 사실 ##을 바그너 ##에 ##게 알렸 ##고 , 바그너 ##는 다시 개정 ##된 총 ##보 ##를 리스트 ##에 ##게 보내 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##는 20 ##루이 ##의 금 ##을 받 ##고 팔 ##았 ##다 . 또한 그 ##의 작품 ##을 “ 하나하나 ##의 음 ##표 ##가 시인 ##의 피로 쓰여졌 ##다 ” 며 극찬 ##했 ##던 한스 폰 [UNK] 그것 ##을 피아노 독주 ##용 ##으로 편곡 ##했 ##는 ##데 , 리스트 ##는 그것 ##을 약간 변형 ##되 ##었 ##을 뿐 ##이 ##라고 지적 ##했 ##다 . 이 서곡 ##의 총 ##보 첫 ##머리 ##에 ##는 파우스트 1 ##부 ##의 내용 중 한 구절 ##을 인용 ##하 ##고 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 14:0 15:1 16:1 17:1 18:2 19:2 20:3 21:3 22:4 23:4 24:5 25:5 26:6 27:6 28:7 29:7 30:8 31:8 32:8 33:8 34:9 35:9 36:9 37:10 38:10 39:10 40:11 41:11 42:11 43:12 44:12 45:12 46:12 47:13 48:13 49:14 50:14 51:15 52:15 53:16 54:17 55:17 56:18 57:19 58:19 59:20 60:20 61:21 62:21 63:21 64:21 65:22 66:23 67:24 68:24 69:24 70:24 71:25 72:25 73:25 74:26 75:26 76:27 77:27 78:28 79:29 80:29 81:30 82:30 83:30 84:31 85:32 86:32 87:33 88:33 89:34 90:34 91:34 92:34 93:35 94:36 95:36 96:37 97:37 98:37 99:38 100:38 101:39 102:39 103:40 104:40 105:40 106:40 107:41 108:41 109:42 110:42 111:42 112:42 113:43 114:43 115:44 116:45 117:45 118:46 119:46 120:46 121:46 122:47 123:47 124:48 125:48 126:48 127:48 128:49 129:50 130:50 131:51 132:52 133:52 134:53 135:53 136:53 137:54 138:54 139:54 140:54 141:55 142:56 143:56 144:56 145:57 146:57 147:58 148:58 149:59 150:60 151:61 152:61 153:62 154:63 155:63 156:64 157:65 158:65 159:66 160:66 161:66 162:67 163:67 164:67 165:68 166:68 167:69 168:70 169:70 170:71 171:71 172:71 173:72 174:72 175:72 176:73 177:73 178:74 179:74 180:74 181:74 182:75 183:76 184:76 185:77 186:77 187:77 188:78 189:78 190:78 191:79 192:79 193:80 194:80 195:81 196:81 197:81 198:81 199:82 200:83 201:83 202:84 203:84 204:85 205:85 206:85 207:86 208:86 209:86 210:87 211:87 212:88 213:89 214:89 215:89 216:89 217:90 218:90 219:90 220:91 221:92 222:93 223:94 224:94 225:95 226:96 227:96 228:96 229:97 230:97 231:97 232:97 233:97 234:98 235:98 236:99 237:99 238:100 239:101 240:101 241:101 242:101 243:102 244:102 245:102 246:103 247:103 248:103 249:103 250:104 251:105 252:105 253:106 254:106 255:107 256:107 257:107 258:107 259:108 260:109 261:109 262:109 263:110 264:111 265:112 266:113 267:113 268:114 269:114 270:114 271:115 272:115 273:115\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 17 28448 28190 28144 2907 28158 28705 1403 28150 267 28151 1132 3 693 12103 28165 342 10404 28198 173 28147 2208 28317 7293 28146 18358 28465 28 28317 17 28448 28190 28144 2907 28158 28705 16268 28165 28137 14640 28137 28149 1403 28195 28136 9 586 28144 1939 28141 10404 28160 7 525 28137 378 1323 28144 540 28199 31 28182 28147 13 36 63 183 28210 28137 28140 276 28207 28139 5448 28144 930 91 6832 25727 17099 212 28381 28408 320 2091 28144 47 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28149 1449 28297 22140 28160 1489 28195 28136 9 16026 28165 106 28210 28137 28140 7293 28146 7 525 28135 2091 28177 28182 3654 64 28144 825 28195 539 13 3372 10404 28139 1449 665 28151 5521 28177 28147 172 28354 28136 9 186 14866 28165 28137 7293 28146 285 28139 525 23793 5964 28144 828 1724 91 36 593 28144 10404 28137 28199 6581 28147 13 10404 28140 378 1931 28255 276 28207 28154 7293 28137 28199 1094 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28140 56 17814 28139 375 28144 132 28147 807 28354 28136 9 255 36 28139 525 28144 547 19108 28139 205 28324 28146 2761 28139 10929 20432 28136 550 96 13444 28195 28317 9851 2453 1 898 28144 4254 15416 28250 17099 6534 28195 28140 28270 13 7293 28140 898 28144 2036 3603 28177 28182 28144 676 28135 6619 2029 28195 28136 9 7 25727 28139 276 28207 402 4755 28137 28140 23793 17 28176 28139 726 62 22 8981 28144 4304 28142 28147 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 24\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 24\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 리스트\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000014\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 14\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 파우스트 교향곡 ##에 감탄 ##하여 피아노 ##곡 ##으로 편곡 ##한 사람 ##은 ? [SEP] 한편 1840 ##년 ##부터 바그너 ##와 알 ##고 지내 ##던 리스트 ##가 잊혀 ##져 있 ##던 1 ##악 ##장 ##을 부활 ##시 ##켜 1852 ##년 ##에 바이마르 ##에 ##서 연주 ##했 ##다 . 이것 ##을 계기 ##로 바그너 ##도 이 작품 ##에 다시 관심 ##을 갖 ##게 되 ##었 ##고 , 그 해 9 ##월 ##에 ##는 총 ##보 ##의 반환 ##을 요구 ##하여 이를 서곡 ##으로 간 ##추 ##린 다음 수정 ##을 했 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##서 출판 ##할 개정판 ##도 준비 ##했 ##다 . 1853 ##년 5 ##월 ##에 ##는 리스트 ##가 이 작품 ##이 수정 ##되 ##었 ##다는 것 ##을 인정 ##했 ##지만 , 끝내 바그너 ##의 출판 계획 ##은 무산 ##되 ##고 말 ##았 ##다 . 이후 1855 ##년 ##에 리스트 ##가 자신 ##의 작품 파우스트 교향곡 ##을 거의 완성 ##하여 그 사실 ##을 바그너 ##에 ##게 알렸 ##고 , 바그너 ##는 다시 개정 ##된 총 ##보 ##를 리스트 ##에 ##게 보내 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##는 20 ##루이 ##의 금 ##을 받 ##고 팔 ##았 ##다 . 또한 그 ##의 작품 ##을 “ 하나하나 ##의 음 ##표 ##가 시인 ##의 피로 쓰여졌 ##다 ” 며 극찬 ##했 ##던 한스 폰 [UNK] 그것 ##을 피아노 독주 ##용 ##으로 편곡 ##했 ##는 ##데 , 리스트 ##는 그것 ##을 약간 변형 ##되 ##었 ##을 뿐 ##이 ##라고 지적 ##했 ##다 . 이 서곡 ##의 총 ##보 첫 ##머리 ##에 ##는 파우스트 1 ##부 ##의 내용 중 한 구절 ##을 인용 ##하 ##고 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 15:0 16:1 17:1 18:1 19:2 20:2 21:3 22:3 23:4 24:4 25:5 26:5 27:6 28:6 29:7 30:7 31:8 32:8 33:8 34:8 35:9 36:9 37:9 38:10 39:10 40:10 41:11 42:11 43:11 44:12 45:12 46:12 47:12 48:13 49:13 50:14 51:14 52:15 53:15 54:16 55:17 56:17 57:18 58:19 59:19 60:20 61:20 62:21 63:21 64:21 65:21 66:22 67:23 68:24 69:24 70:24 71:24 72:25 73:25 74:25 75:26 76:26 77:27 78:27 79:28 80:29 81:29 82:30 83:30 84:30 85:31 86:32 87:32 88:33 89:33 90:34 91:34 92:34 93:34 94:35 95:36 96:36 97:37 98:37 99:37 100:38 101:38 102:39 103:39 104:40 105:40 106:40 107:40 108:41 109:41 110:42 111:42 112:42 113:42 114:43 115:43 116:44 117:45 118:45 119:46 120:46 121:46 122:46 123:47 124:47 125:48 126:48 127:48 128:48 129:49 130:50 131:50 132:51 133:52 134:52 135:53 136:53 137:53 138:54 139:54 140:54 141:54 142:55 143:56 144:56 145:56 146:57 147:57 148:58 149:58 150:59 151:60 152:61 153:61 154:62 155:63 156:63 157:64 158:65 159:65 160:66 161:66 162:66 163:67 164:67 165:67 166:68 167:68 168:69 169:70 170:70 171:71 172:71 173:71 174:72 175:72 176:72 177:73 178:73 179:74 180:74 181:74 182:74 183:75 184:76 185:76 186:77 187:77 188:77 189:78 190:78 191:78 192:79 193:79 194:80 195:80 196:81 197:81 198:81 199:81 200:82 201:83 202:83 203:84 204:84 205:85 206:85 207:85 208:86 209:86 210:86 211:87 212:87 213:88 214:89 215:89 216:89 217:89 218:90 219:90 220:90 221:91 222:92 223:93 224:94 225:94 226:95 227:96 228:96 229:96 230:97 231:97 232:97 233:97 234:97 235:98 236:98 237:99 238:99 239:100 240:101 241:101 242:101 243:101 244:102 245:102 246:102 247:103 248:103 249:103 250:103 251:104 252:105 253:105 254:106 255:106 256:107 257:107 258:107 259:107 260:108 261:109 262:109 263:109 264:110 265:111 266:112 267:113 268:113 269:114 270:114 271:114 272:115 273:115 274:115\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 23793 5964 28137 16903 91 4254 28473 17099 6534 28150 267 28151 1132 3 693 12103 28165 342 10404 28198 173 28147 2208 28317 7293 28146 18358 28465 28 28317 17 28448 28190 28144 2907 28158 28705 16268 28165 28137 14640 28137 28149 1403 28195 28136 9 586 28144 1939 28141 10404 28160 7 525 28137 378 1323 28144 540 28199 31 28182 28147 13 36 63 183 28210 28137 28140 276 28207 28139 5448 28144 930 91 6832 25727 17099 212 28381 28408 320 2091 28144 47 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28149 1449 28297 22140 28160 1489 28195 28136 9 16026 28165 106 28210 28137 28140 7293 28146 7 525 28135 2091 28177 28182 3654 64 28144 825 28195 539 13 3372 10404 28139 1449 665 28151 5521 28177 28147 172 28354 28136 9 186 14866 28165 28137 7293 28146 285 28139 525 23793 5964 28144 828 1724 91 36 593 28144 10404 28137 28199 6581 28147 13 10404 28140 378 1931 28255 276 28207 28154 7293 28137 28199 1094 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28140 56 17814 28139 375 28144 132 28147 807 28354 28136 9 255 36 28139 525 28144 547 19108 28139 205 28324 28146 2761 28139 10929 20432 28136 550 96 13444 28195 28317 9851 2453 1 898 28144 4254 15416 28250 17099 6534 28195 28140 28270 13 7293 28140 898 28144 2036 3603 28177 28182 28144 676 28135 6619 2029 28195 28136 9 7 25727 28139 276 28207 402 4755 28137 28140 23793 17 28176 28139 726 62 22 8981 28144 4304 28142 28147 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 221\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 223\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 한스 폰 [UNK]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000015\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 15\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 리스트 ##가 바그너 ##와 알 ##게 된 연도 ##는 ? [SEP] 한편 1840 ##년 ##부터 바그너 ##와 알 ##고 지내 ##던 리스트 ##가 잊혀 ##져 있 ##던 1 ##악 ##장 ##을 부활 ##시 ##켜 1852 ##년 ##에 바이마르 ##에 ##서 연주 ##했 ##다 . 이것 ##을 계기 ##로 바그너 ##도 이 작품 ##에 다시 관심 ##을 갖 ##게 되 ##었 ##고 , 그 해 9 ##월 ##에 ##는 총 ##보 ##의 반환 ##을 요구 ##하여 이를 서곡 ##으로 간 ##추 ##린 다음 수정 ##을 했 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##서 출판 ##할 개정판 ##도 준비 ##했 ##다 . 1853 ##년 5 ##월 ##에 ##는 리스트 ##가 이 작품 ##이 수정 ##되 ##었 ##다는 것 ##을 인정 ##했 ##지만 , 끝내 바그너 ##의 출판 계획 ##은 무산 ##되 ##고 말 ##았 ##다 . 이후 1855 ##년 ##에 리스트 ##가 자신 ##의 작품 파우스트 교향곡 ##을 거의 완성 ##하여 그 사실 ##을 바그너 ##에 ##게 알렸 ##고 , 바그너 ##는 다시 개정 ##된 총 ##보 ##를 리스트 ##에 ##게 보내 ##고 브라 ##이트 ##코프 ##흐 & 헤르 ##텔 출판사 ##에 ##는 20 ##루이 ##의 금 ##을 받 ##고 팔 ##았 ##다 . 또한 그 ##의 작품 ##을 “ 하나하나 ##의 음 ##표 ##가 시인 ##의 피로 쓰여졌 ##다 ” 며 극찬 ##했 ##던 한스 폰 [UNK] 그것 ##을 피아노 독주 ##용 ##으로 편곡 ##했 ##는 ##데 , 리스트 ##는 그것 ##을 약간 변형 ##되 ##었 ##을 뿐 ##이 ##라고 지적 ##했 ##다 . 이 서곡 ##의 총 ##보 첫 ##머리 ##에 ##는 파우스트 1 ##부 ##의 내용 중 한 구절 ##을 인용 ##하 ##고 있 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 12:0 13:1 14:1 15:1 16:2 17:2 18:3 19:3 20:4 21:4 22:5 23:5 24:6 25:6 26:7 27:7 28:8 29:8 30:8 31:8 32:9 33:9 34:9 35:10 36:10 37:10 38:11 39:11 40:11 41:12 42:12 43:12 44:12 45:13 46:13 47:14 48:14 49:15 50:15 51:16 52:17 53:17 54:18 55:19 56:19 57:20 58:20 59:21 60:21 61:21 62:21 63:22 64:23 65:24 66:24 67:24 68:24 69:25 70:25 71:25 72:26 73:26 74:27 75:27 76:28 77:29 78:29 79:30 80:30 81:30 82:31 83:32 84:32 85:33 86:33 87:34 88:34 89:34 90:34 91:35 92:36 93:36 94:37 95:37 96:37 97:38 98:38 99:39 100:39 101:40 102:40 103:40 104:40 105:41 106:41 107:42 108:42 109:42 110:42 111:43 112:43 113:44 114:45 115:45 116:46 117:46 118:46 119:46 120:47 121:47 122:48 123:48 124:48 125:48 126:49 127:50 128:50 129:51 130:52 131:52 132:53 133:53 134:53 135:54 136:54 137:54 138:54 139:55 140:56 141:56 142:56 143:57 144:57 145:58 146:58 147:59 148:60 149:61 150:61 151:62 152:63 153:63 154:64 155:65 156:65 157:66 158:66 159:66 160:67 161:67 162:67 163:68 164:68 165:69 166:70 167:70 168:71 169:71 170:71 171:72 172:72 173:72 174:73 175:73 176:74 177:74 178:74 179:74 180:75 181:76 182:76 183:77 184:77 185:77 186:78 187:78 188:78 189:79 190:79 191:80 192:80 193:81 194:81 195:81 196:81 197:82 198:83 199:83 200:84 201:84 202:85 203:85 204:85 205:86 206:86 207:86 208:87 209:87 210:88 211:89 212:89 213:89 214:89 215:90 216:90 217:90 218:91 219:92 220:93 221:94 222:94 223:95 224:96 225:96 226:96 227:97 228:97 229:97 230:97 231:97 232:98 233:98 234:99 235:99 236:100 237:101 238:101 239:101 240:101 241:102 242:102 243:102 244:103 245:103 246:103 247:103 248:104 249:105 250:105 251:106 252:106 253:107 254:107 255:107 256:107 257:108 258:109 259:109 260:109 261:110 262:111 263:112 264:113 265:113 266:114 267:114 268:114 269:115 270:115 271:115\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 7293 28146 10404 28198 173 28199 65 8397 28140 1132 3 693 12103 28165 342 10404 28198 173 28147 2208 28317 7293 28146 18358 28465 28 28317 17 28448 28190 28144 2907 28158 28705 16268 28165 28137 14640 28137 28149 1403 28195 28136 9 586 28144 1939 28141 10404 28160 7 525 28137 378 1323 28144 540 28199 31 28182 28147 13 36 63 183 28210 28137 28140 276 28207 28139 5448 28144 930 91 6832 25727 17099 212 28381 28408 320 2091 28144 47 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28149 1449 28297 22140 28160 1489 28195 28136 9 16026 28165 106 28210 28137 28140 7293 28146 7 525 28135 2091 28177 28182 3654 64 28144 825 28195 539 13 3372 10404 28139 1449 665 28151 5521 28177 28147 172 28354 28136 9 186 14866 28165 28137 7293 28146 285 28139 525 23793 5964 28144 828 1724 91 36 593 28144 10404 28137 28199 6581 28147 13 10404 28140 378 1931 28255 276 28207 28154 7293 28137 28199 1094 28147 1045 648 4161 28700 1776 4098 28706 6918 28137 28140 56 17814 28139 375 28144 132 28147 807 28354 28136 9 255 36 28139 525 28144 547 19108 28139 205 28324 28146 2761 28139 10929 20432 28136 550 96 13444 28195 28317 9851 2453 1 898 28144 4254 15416 28250 17099 6534 28195 28140 28270 13 7293 28140 898 28144 2036 3603 28177 28182 28144 676 28135 6619 2029 28195 28136 9 7 25727 28139 276 28207 402 4755 28137 28140 23793 17 28176 28139 726 62 22 8981 28144 4304 28142 28147 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 13\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 14\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 1840 ##년\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000016\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 16\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 서주 ##에 ##는 무엇 ##이 암시 ##되 ##어 있 ##는 ##가 ? [SEP] 이 작품 ##은 라 ##단 ##조 , se ##hr ge ##ha ##l ##te ##n ( 아주 신중 ##하 ##게 ) , 4 / 4 ##박 ##자 ##의 부드러운 서주 ##로 서주 ##로 시작 ##되 ##는 ##데 , 여기 ##에 ##는 주요 주제 , 동기 ##의 대부분 ##이 암시 , 예고 ##되 ##어 있 ##다 . 첫 부분 ##의 저 ##음 주제 ##는 주요 주제 ( 고뇌 ##와 갈망 동기 , 청춘 ##의 사랑 동기 ) 를 암시 ##하 ##고 있 ##으 ##며 , 제 ##1 ##바이 ##올 ##린 ##으로 더욱 명확 ##하 ##게 나타난다 . 또한 그것 ##을 이어받 ##는 동기 ##도 중요 ##한 역할 ##을 한다 . 여기 ##에 새로운 소재 ##가 더해 ##진 뒤 ##에 새로운 주제 ##도 연주 ##된 ##다 . 주요 ##부 ##는 se ##hr be ##we ##g ##t ( 아주 격 ##동 ##적 ##으로 ) , 2 / 2 ##박 ##자 ##의 자유 ##로운 소나타 형식 ##으로 매우 드라마 ##틱 ##한 구상 ##과 유기 ##적 ##인 구성 ##을 하고 있 ##다 . 여기 ##에 ##는 지금 ##까 ##지 ##의 주제 ##나 소재 외 ##에 ##도 오보 ##에 ##에 의한 선율 ##과 제 ##2 ##주 ##제 ##를 떠올리 ##게 하 ##는 부차 ##적 ##인 주제가 더해 ##지 ##는 ##데 , 중간 ##부 ##에 ##서 ##는 약 ##보 ##3 ##이 중심 ##이 되 ##고 제 ##2 ##주 ##제 ##는 축소 ##된 재현 ##부 ##에 ##서 d ##장조 ##로 재현 ##된 ##다 . 마지막 ##에 ##는 주요 주제 ##를 회상 ##하면 ##서 조용히 마친 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:2 21:3 22:3 23:4 24:4 25:4 26:4 27:4 28:4 29:4 30:5 31:5 32:5 33:5 34:5 35:6 36:6 37:6 38:6 39:6 40:6 41:7 42:8 43:8 44:9 45:9 46:10 47:10 48:10 49:10 50:10 51:11 52:11 53:11 54:12 55:13 56:13 57:14 58:14 59:15 60:15 61:16 62:16 63:17 64:17 65:17 66:18 67:18 68:18 69:19 70:20 71:20 72:21 73:21 74:22 75:22 76:23 77:24 78:24 79:24 80:24 81:25 82:26 83:26 84:27 85:27 86:28 87:29 88:29 89:29 90:30 91:30 92:30 93:31 94:31 95:31 96:31 97:32 98:32 99:32 100:32 101:32 102:32 103:33 104:34 105:34 106:34 107:35 108:35 109:36 110:37 111:37 112:38 113:38 114:39 115:39 116:40 117:40 118:41 119:41 120:42 121:42 122:43 123:43 124:44 125:45 126:45 127:46 128:46 129:47 130:47 131:48 132:49 133:49 134:50 135:50 136:50 137:50 138:51 139:51 140:51 141:52 142:52 143:53 144:53 145:53 146:53 147:53 148:53 149:54 150:54 151:54 152:54 153:54 154:54 155:55 156:55 157:55 158:55 159:55 160:55 161:56 162:56 163:57 164:58 165:58 166:59 167:60 168:60 169:60 170:61 171:61 172:62 173:62 174:62 175:63 176:63 177:64 178:65 179:65 180:65 181:66 182:66 183:66 184:67 185:67 186:67 187:67 188:68 189:68 190:69 191:70 192:70 193:70 194:71 195:71 196:71 197:72 198:73 199:73 200:74 201:74 202:74 203:74 204:74 205:75 206:75 207:76 208:76 209:77 210:77 211:77 212:78 213:79 214:79 215:79 216:79 217:79 218:80 219:80 220:80 221:80 222:80 223:81 224:81 225:81 226:81 227:82 228:82 229:83 230:83 231:84 232:84 233:84 234:84 235:84 236:85 237:85 238:86 239:86 240:86 241:86 242:87 243:87 244:87 245:88 246:88 247:88 248:88 249:89 250:89 251:89 252:90 253:91 254:91 255:92 256:92 257:92 258:93 259:94 260:94 261:94\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 13260 28137 28140 3081 28135 8482 28177 28168 28 28140 28146 1132 3 7 525 28151 59 28273 28212 13 2854 15825 5441 9875 28248 2596 28236 24 2602 8414 28142 28199 23 13 101 403 101 28446 28167 28139 10374 13260 28141 13260 28141 250 28177 28140 28270 13 783 28137 28140 755 1771 13 3817 28139 543 28135 8482 13 9552 28177 28168 28 28136 9 402 571 28139 303 28287 1771 28140 755 1771 24 25381 28198 25517 3817 13 11689 28139 1169 3817 23 21 8482 28142 28147 28 28153 28215 13 58 28145 2292 28443 28408 17099 1256 3375 28142 28199 3532 9 255 898 28144 6939 28140 3817 28160 656 28150 803 28144 77 9 783 28137 627 1880 28146 6821 28252 308 28137 627 1771 28160 1403 28255 28136 9 755 28176 28140 2854 15825 3076 3257 28344 28234 24 2602 750 28197 28191 17099 23 13 33 403 33 28446 28167 28139 619 6188 15378 1111 17099 658 1303 28939 28150 4780 28183 4189 28191 28164 487 28144 12005 28 28136 9 783 28137 28140 875 28348 28148 28139 1771 28175 1880 268 28137 28160 15887 28137 28137 1018 12838 28183 58 28161 28186 28187 28154 21451 28199 15 28140 24759 28191 28164 12686 6821 28148 28140 28270 13 1893 28176 28137 28149 28140 286 28207 28196 28135 492 28135 31 28147 58 28161 28186 28187 28140 4772 28255 8726 28176 28137 28149 256 24324 28141 8726 28255 28136 9 881 28137 28140 755 1771 28154 9758 6523 28149 16001 6717 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 55\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 57\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 주제 , 동기\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000017\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 17\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 첫 ##부분 ##에 ##는 어떤 악기 ##를 사용 ##해 더욱 명확 ##하 ##게 나타내 ##는 ##가 ? [SEP] 이 작품 ##은 라 ##단 ##조 , se ##hr ge ##ha ##l ##te ##n ( 아주 신중 ##하 ##게 ) , 4 / 4 ##박 ##자 ##의 부드러운 서주 ##로 서주 ##로 시작 ##되 ##는 ##데 , 여기 ##에 ##는 주요 주제 , 동기 ##의 대부분 ##이 암시 , 예고 ##되 ##어 있 ##다 . 첫 부분 ##의 저 ##음 주제 ##는 주요 주제 ( 고뇌 ##와 갈망 동기 , 청춘 ##의 사랑 동기 ) 를 암시 ##하 ##고 있 ##으 ##며 , 제 ##1 ##바이 ##올 ##린 ##으로 더욱 명확 ##하 ##게 나타난다 . 또한 그것 ##을 이어받 ##는 동기 ##도 중요 ##한 역할 ##을 한다 . 여기 ##에 새로운 소재 ##가 더해 ##진 뒤 ##에 새로운 주제 ##도 연주 ##된 ##다 . 주요 ##부 ##는 se ##hr be ##we ##g ##t ( 아주 격 ##동 ##적 ##으로 ) , 2 / 2 ##박 ##자 ##의 자유 ##로운 소나타 형식 ##으로 매우 드라마 ##틱 ##한 구상 ##과 유기 ##적 ##인 구성 ##을 하고 있 ##다 . 여기 ##에 ##는 지금 ##까 ##지 ##의 주제 ##나 소재 외 ##에 ##도 오보 ##에 ##에 의한 선율 ##과 제 ##2 ##주 ##제 ##를 떠올리 ##게 하 ##는 부차 ##적 ##인 주제가 더해 ##지 ##는 ##데 , 중간 ##부 ##에 ##서 ##는 약 ##보 ##3 ##이 중심 ##이 되 ##고 제 ##2 ##주 ##제 ##는 축소 ##된 재현 ##부 ##에 ##서 d ##장조 ##로 재현 ##된 ##다 . 마지막 ##에 ##는 주요 주제 ##를 회상 ##하면 ##서 조용히 마친 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 19:0 20:1 21:1 22:2 23:2 24:2 25:2 26:3 27:3 28:4 29:4 30:4 31:4 32:4 33:4 34:4 35:5 36:5 37:5 38:5 39:5 40:6 41:6 42:6 43:6 44:6 45:6 46:7 47:8 48:8 49:9 50:9 51:10 52:10 53:10 54:10 55:10 56:11 57:11 58:11 59:12 60:13 61:13 62:14 63:14 64:15 65:15 66:16 67:16 68:17 69:17 70:17 71:18 72:18 73:18 74:19 75:20 76:20 77:21 78:21 79:22 80:22 81:23 82:24 83:24 84:24 85:24 86:25 87:26 88:26 89:27 90:27 91:28 92:29 93:29 94:29 95:30 96:30 97:30 98:31 99:31 100:31 101:31 102:32 103:32 104:32 105:32 106:32 107:32 108:33 109:34 110:34 111:34 112:35 113:35 114:36 115:37 116:37 117:38 118:38 119:39 120:39 121:40 122:40 123:41 124:41 125:42 126:42 127:43 128:43 129:44 130:45 131:45 132:46 133:46 134:47 135:47 136:48 137:49 138:49 139:50 140:50 141:50 142:50 143:51 144:51 145:51 146:52 147:52 148:53 149:53 150:53 151:53 152:53 153:53 154:54 155:54 156:54 157:54 158:54 159:54 160:55 161:55 162:55 163:55 164:55 165:55 166:56 167:56 168:57 169:58 170:58 171:59 172:60 173:60 174:60 175:61 176:61 177:62 178:62 179:62 180:63 181:63 182:64 183:65 184:65 185:65 186:66 187:66 188:66 189:67 190:67 191:67 192:67 193:68 194:68 195:69 196:70 197:70 198:70 199:71 200:71 201:71 202:72 203:73 204:73 205:74 206:74 207:74 208:74 209:74 210:75 211:75 212:76 213:76 214:77 215:77 216:77 217:78 218:79 219:79 220:79 221:79 222:79 223:80 224:80 225:80 226:80 227:80 228:81 229:81 230:81 231:81 232:82 233:82 234:83 235:83 236:84 237:84 238:84 239:84 240:84 241:85 242:85 243:86 244:86 245:86 246:86 247:87 248:87 249:87 250:88 251:88 252:88 253:88 254:89 255:89 256:89 257:90 258:91 259:91 260:92 261:92 262:92 263:93 264:94 265:94 266:94\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 402 6954 28137 28140 995 3860 28154 187 28181 1256 3375 28142 28199 1732 28140 28146 1132 3 7 525 28151 59 28273 28212 13 2854 15825 5441 9875 28248 2596 28236 24 2602 8414 28142 28199 23 13 101 403 101 28446 28167 28139 10374 13260 28141 13260 28141 250 28177 28140 28270 13 783 28137 28140 755 1771 13 3817 28139 543 28135 8482 13 9552 28177 28168 28 28136 9 402 571 28139 303 28287 1771 28140 755 1771 24 25381 28198 25517 3817 13 11689 28139 1169 3817 23 21 8482 28142 28147 28 28153 28215 13 58 28145 2292 28443 28408 17099 1256 3375 28142 28199 3532 9 255 898 28144 6939 28140 3817 28160 656 28150 803 28144 77 9 783 28137 627 1880 28146 6821 28252 308 28137 627 1771 28160 1403 28255 28136 9 755 28176 28140 2854 15825 3076 3257 28344 28234 24 2602 750 28197 28191 17099 23 13 33 403 33 28446 28167 28139 619 6188 15378 1111 17099 658 1303 28939 28150 4780 28183 4189 28191 28164 487 28144 12005 28 28136 9 783 28137 28140 875 28348 28148 28139 1771 28175 1880 268 28137 28160 15887 28137 28137 1018 12838 28183 58 28161 28186 28187 28154 21451 28199 15 28140 24759 28191 28164 12686 6821 28148 28140 28270 13 1893 28176 28137 28149 28140 286 28207 28196 28135 492 28135 31 28147 58 28161 28186 28187 28140 4772 28255 8726 28176 28137 28149 256 24324 28141 8726 28255 28136 9 881 28137 28140 755 1771 28154 9758 6523 28149 16001 6717 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 102\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 106\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 제 ##1 ##바이 ##올 ##린\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000018\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 18\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 주요 ##부 ##는 어떤 형식 ##으로 되 ##어 있 ##는 ##가 ? [SEP] 이 작품 ##은 라 ##단 ##조 , se ##hr ge ##ha ##l ##te ##n ( 아주 신중 ##하 ##게 ) , 4 / 4 ##박 ##자 ##의 부드러운 서주 ##로 서주 ##로 시작 ##되 ##는 ##데 , 여기 ##에 ##는 주요 주제 , 동기 ##의 대부분 ##이 암시 , 예고 ##되 ##어 있 ##다 . 첫 부분 ##의 저 ##음 주제 ##는 주요 주제 ( 고뇌 ##와 갈망 동기 , 청춘 ##의 사랑 동기 ) 를 암시 ##하 ##고 있 ##으 ##며 , 제 ##1 ##바이 ##올 ##린 ##으로 더욱 명확 ##하 ##게 나타난다 . 또한 그것 ##을 이어받 ##는 동기 ##도 중요 ##한 역할 ##을 한다 . 여기 ##에 새로운 소재 ##가 더해 ##진 뒤 ##에 새로운 주제 ##도 연주 ##된 ##다 . 주요 ##부 ##는 se ##hr be ##we ##g ##t ( 아주 격 ##동 ##적 ##으로 ) , 2 / 2 ##박 ##자 ##의 자유 ##로운 소나타 형식 ##으로 매우 드라마 ##틱 ##한 구상 ##과 유기 ##적 ##인 구성 ##을 하고 있 ##다 . 여기 ##에 ##는 지금 ##까 ##지 ##의 주제 ##나 소재 외 ##에 ##도 오보 ##에 ##에 의한 선율 ##과 제 ##2 ##주 ##제 ##를 떠올리 ##게 하 ##는 부차 ##적 ##인 주제가 더해 ##지 ##는 ##데 , 중간 ##부 ##에 ##서 ##는 약 ##보 ##3 ##이 중심 ##이 되 ##고 제 ##2 ##주 ##제 ##는 축소 ##된 재현 ##부 ##에 ##서 d ##장조 ##로 재현 ##된 ##다 . 마지막 ##에 ##는 주요 주제 ##를 회상 ##하면 ##서 조용히 마친 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 14:0 15:1 16:1 17:2 18:2 19:2 20:2 21:3 22:3 23:4 24:4 25:4 26:4 27:4 28:4 29:4 30:5 31:5 32:5 33:5 34:5 35:6 36:6 37:6 38:6 39:6 40:6 41:7 42:8 43:8 44:9 45:9 46:10 47:10 48:10 49:10 50:10 51:11 52:11 53:11 54:12 55:13 56:13 57:14 58:14 59:15 60:15 61:16 62:16 63:17 64:17 65:17 66:18 67:18 68:18 69:19 70:20 71:20 72:21 73:21 74:22 75:22 76:23 77:24 78:24 79:24 80:24 81:25 82:26 83:26 84:27 85:27 86:28 87:29 88:29 89:29 90:30 91:30 92:30 93:31 94:31 95:31 96:31 97:32 98:32 99:32 100:32 101:32 102:32 103:33 104:34 105:34 106:34 107:35 108:35 109:36 110:37 111:37 112:38 113:38 114:39 115:39 116:40 117:40 118:41 119:41 120:42 121:42 122:43 123:43 124:44 125:45 126:45 127:46 128:46 129:47 130:47 131:48 132:49 133:49 134:50 135:50 136:50 137:50 138:51 139:51 140:51 141:52 142:52 143:53 144:53 145:53 146:53 147:53 148:53 149:54 150:54 151:54 152:54 153:54 154:54 155:55 156:55 157:55 158:55 159:55 160:55 161:56 162:56 163:57 164:58 165:58 166:59 167:60 168:60 169:60 170:61 171:61 172:62 173:62 174:62 175:63 176:63 177:64 178:65 179:65 180:65 181:66 182:66 183:66 184:67 185:67 186:67 187:67 188:68 189:68 190:69 191:70 192:70 193:70 194:71 195:71 196:71 197:72 198:73 199:73 200:74 201:74 202:74 203:74 204:74 205:75 206:75 207:76 208:76 209:77 210:77 211:77 212:78 213:79 214:79 215:79 216:79 217:79 218:80 219:80 220:80 221:80 222:80 223:81 224:81 225:81 226:81 227:82 228:82 229:83 230:83 231:84 232:84 233:84 234:84 235:84 236:85 237:85 238:86 239:86 240:86 241:86 242:87 243:87 244:87 245:88 246:88 247:88 248:88 249:89 250:89 251:89 252:90 253:91 254:91 255:92 256:92 257:92 258:93 259:94 260:94 261:94\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 755 28176 28140 995 1111 17099 31 28168 28 28140 28146 1132 3 7 525 28151 59 28273 28212 13 2854 15825 5441 9875 28248 2596 28236 24 2602 8414 28142 28199 23 13 101 403 101 28446 28167 28139 10374 13260 28141 13260 28141 250 28177 28140 28270 13 783 28137 28140 755 1771 13 3817 28139 543 28135 8482 13 9552 28177 28168 28 28136 9 402 571 28139 303 28287 1771 28140 755 1771 24 25381 28198 25517 3817 13 11689 28139 1169 3817 23 21 8482 28142 28147 28 28153 28215 13 58 28145 2292 28443 28408 17099 1256 3375 28142 28199 3532 9 255 898 28144 6939 28140 3817 28160 656 28150 803 28144 77 9 783 28137 627 1880 28146 6821 28252 308 28137 627 1771 28160 1403 28255 28136 9 755 28176 28140 2854 15825 3076 3257 28344 28234 24 2602 750 28197 28191 17099 23 13 33 403 33 28446 28167 28139 619 6188 15378 1111 17099 658 1303 28939 28150 4780 28183 4189 28191 28164 487 28144 12005 28 28136 9 783 28137 28140 875 28348 28148 28139 1771 28175 1880 268 28137 28160 15887 28137 28137 1018 12838 28183 58 28161 28186 28187 28154 21451 28199 15 28140 24759 28191 28164 12686 6821 28148 28140 28270 13 1893 28176 28137 28149 28140 286 28207 28196 28135 492 28135 31 28147 58 28161 28186 28187 28140 4772 28255 8726 28176 28137 28149 256 24324 28141 8726 28255 28136 9 881 28137 28140 755 1771 28154 9758 6523 28149 16001 6717 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 163\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 164\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 소나타 형식\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   unique_id: 1000000019\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   example_index: 19\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   tokens: [CLS] 첫 부분 ##의 주요 ##주 ##제 ##를 암시 ##하 ##는 주제 ##는 ? [SEP] 이 작품 ##은 라 ##단 ##조 , se ##hr ge ##ha ##l ##te ##n ( 아주 신중 ##하 ##게 ) , 4 / 4 ##박 ##자 ##의 부드러운 서주 ##로 서주 ##로 시작 ##되 ##는 ##데 , 여기 ##에 ##는 주요 주제 , 동기 ##의 대부분 ##이 암시 , 예고 ##되 ##어 있 ##다 . 첫 부분 ##의 저 ##음 주제 ##는 주요 주제 ( 고뇌 ##와 갈망 동기 , 청춘 ##의 사랑 동기 ) 를 암시 ##하 ##고 있 ##으 ##며 , 제 ##1 ##바이 ##올 ##린 ##으로 더욱 명확 ##하 ##게 나타난다 . 또한 그것 ##을 이어받 ##는 동기 ##도 중요 ##한 역할 ##을 한다 . 여기 ##에 새로운 소재 ##가 더해 ##진 뒤 ##에 새로운 주제 ##도 연주 ##된 ##다 . 주요 ##부 ##는 se ##hr be ##we ##g ##t ( 아주 격 ##동 ##적 ##으로 ) , 2 / 2 ##박 ##자 ##의 자유 ##로운 소나타 형식 ##으로 매우 드라마 ##틱 ##한 구상 ##과 유기 ##적 ##인 구성 ##을 하고 있 ##다 . 여기 ##에 ##는 지금 ##까 ##지 ##의 주제 ##나 소재 외 ##에 ##도 오보 ##에 ##에 의한 선율 ##과 제 ##2 ##주 ##제 ##를 떠올리 ##게 하 ##는 부차 ##적 ##인 주제가 더해 ##지 ##는 ##데 , 중간 ##부 ##에 ##서 ##는 약 ##보 ##3 ##이 중심 ##이 되 ##고 제 ##2 ##주 ##제 ##는 축소 ##된 재현 ##부 ##에 ##서 d ##장조 ##로 재현 ##된 ##다 . 마지막 ##에 ##는 주요 주제 ##를 회상 ##하면 ##서 조용히 마친 ##다 . [SEP]\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_to_orig_map: 15:0 16:1 17:1 18:2 19:2 20:2 21:2 22:3 23:3 24:4 25:4 26:4 27:4 28:4 29:4 30:4 31:5 32:5 33:5 34:5 35:5 36:6 37:6 38:6 39:6 40:6 41:6 42:7 43:8 44:8 45:9 46:9 47:10 48:10 49:10 50:10 51:10 52:11 53:11 54:11 55:12 56:13 57:13 58:14 59:14 60:15 61:15 62:16 63:16 64:17 65:17 66:17 67:18 68:18 69:18 70:19 71:20 72:20 73:21 74:21 75:22 76:22 77:23 78:24 79:24 80:24 81:24 82:25 83:26 84:26 85:27 86:27 87:28 88:29 89:29 90:29 91:30 92:30 93:30 94:31 95:31 96:31 97:31 98:32 99:32 100:32 101:32 102:32 103:32 104:33 105:34 106:34 107:34 108:35 109:35 110:36 111:37 112:37 113:38 114:38 115:39 116:39 117:40 118:40 119:41 120:41 121:42 122:42 123:43 124:43 125:44 126:45 127:45 128:46 129:46 130:47 131:47 132:48 133:49 134:49 135:50 136:50 137:50 138:50 139:51 140:51 141:51 142:52 143:52 144:53 145:53 146:53 147:53 148:53 149:53 150:54 151:54 152:54 153:54 154:54 155:54 156:55 157:55 158:55 159:55 160:55 161:55 162:56 163:56 164:57 165:58 166:58 167:59 168:60 169:60 170:60 171:61 172:61 173:62 174:62 175:62 176:63 177:63 178:64 179:65 180:65 181:65 182:66 183:66 184:66 185:67 186:67 187:67 188:67 189:68 190:68 191:69 192:70 193:70 194:70 195:71 196:71 197:71 198:72 199:73 200:73 201:74 202:74 203:74 204:74 205:74 206:75 207:75 208:76 209:76 210:77 211:77 212:77 213:78 214:79 215:79 216:79 217:79 218:79 219:80 220:80 221:80 222:80 223:80 224:81 225:81 226:81 227:81 228:82 229:82 230:83 231:83 232:84 233:84 234:84 235:84 236:84 237:85 238:85 239:86 240:86 241:86 242:86 243:87 244:87 245:87 246:88 247:88 248:88 249:88 250:89 251:89 252:89 253:90 254:91 255:91 256:92 257:92 258:92 259:93 260:94 261:94 262:94\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_ids: 2 402 571 28139 755 28186 28187 28154 8482 28142 28140 1771 28140 1132 3 7 525 28151 59 28273 28212 13 2854 15825 5441 9875 28248 2596 28236 24 2602 8414 28142 28199 23 13 101 403 101 28446 28167 28139 10374 13260 28141 13260 28141 250 28177 28140 28270 13 783 28137 28140 755 1771 13 3817 28139 543 28135 8482 13 9552 28177 28168 28 28136 9 402 571 28139 303 28287 1771 28140 755 1771 24 25381 28198 25517 3817 13 11689 28139 1169 3817 23 21 8482 28142 28147 28 28153 28215 13 58 28145 2292 28443 28408 17099 1256 3375 28142 28199 3532 9 255 898 28144 6939 28140 3817 28160 656 28150 803 28144 77 9 783 28137 627 1880 28146 6821 28252 308 28137 627 1771 28160 1403 28255 28136 9 755 28176 28140 2854 15825 3076 3257 28344 28234 24 2602 750 28197 28191 17099 23 13 33 403 33 28446 28167 28139 619 6188 15378 1111 17099 658 1303 28939 28150 4780 28183 4189 28191 28164 487 28144 12005 28 28136 9 783 28137 28140 875 28348 28148 28139 1771 28175 1880 268 28137 28160 15887 28137 28137 1018 12838 28183 58 28161 28186 28187 28154 21451 28199 15 28140 24759 28191 28164 12686 6821 28148 28140 28270 13 1893 28176 28137 28149 28140 286 28207 28196 28135 492 28135 31 28147 58 28161 28186 28187 28140 4772 28255 8726 28176 28137 28149 256 24324 28141 8726 28255 28136 9 881 28137 28140 755 1771 28154 9758 6523 28149 16001 6717 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   start_position: 73\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   end_position: 75\n",
            "05/15/2020 01:32:01 - INFO - __main__ -   answer: 저 ##음 주제\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uehvfrms0AiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_optimization_steps = int(len(train_features) / train_batch_size) * num_train_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAemMDITGY9A",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58Ge11Sg0Af9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': weight_decay},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                  lr=learning_rate,\n",
        "                  eps=adam_epsilon)\n",
        "scheduler = WarmupLinearSchedule(optimizer,\n",
        "                                 warmup_steps=num_train_optimization_steps*0.1,\n",
        "                                 t_total=num_train_optimization_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_K32QKc0Aeh",
        "colab_type": "code",
        "outputId": "4202f124-8a90-4ffe-f33c-bc57e34e0d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(\"  Num orig examples = %d\", len(train_examples))\n",
        "logger.info(\"  Num split examples = %d\", len(train_features))\n",
        "logger.info(\"  Batch size = %d\", train_batch_size)\n",
        "logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
        "num_train_step = num_train_optimization_steps"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 01:34:47 - INFO - __main__ -   ***** Running training *****\n",
            "05/15/2020 01:34:47 - INFO - __main__ -     Num orig examples = 60407\n",
            "05/15/2020 01:34:47 - INFO - __main__ -     Num split examples = 64360\n",
            "05/15/2020 01:34:47 - INFO - __main__ -     Batch size = 16\n",
            "05/15/2020 01:34:47 - INFO - __main__ -     Num steps = 16088\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS1xyG2Y0AcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "all_start_positions = torch.tensor([f.start_position for f in train_features], dtype=torch.long)\n",
        "all_end_positions = torch.tensor([f.end_position for f in train_features], dtype=torch.long)\n",
        "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_start_positions, all_end_positions)\n",
        "\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K033k0pf0AYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train()\n",
        "global_step = 0\n",
        "epoch = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMlcW5yVGd_1",
        "colab_type": "text"
      },
      "source": [
        "## KorQuAD1.0 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTRmx2FN0AWR",
        "colab_type": "code",
        "outputId": "c0ad7bb7-7023-4067-c5b4-4d06e71c8e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "140c4e20939d443aa2a9eb480bcc2244",
            "05a43f1037be44be91ef4932de927bd1",
            "30d722d631eb4928a1dc0dfe8313ea45",
            "64da43656f43476395ca9754b88ce1fc",
            "3694b19c632f4764898c530657c6e636",
            "f404231693cb4f7ca4c8eb911586c32a",
            "7332c9e54ba54e8cab7b97066dc9b6df",
            "63a382e23d374080b826c1a1de85fc81",
            "44ff86e536f8440a970ba95fd2740d20",
            "5a048cb7b75c416692465e818ad22dfa",
            "0b694c8bc65a4fdd95de3203290f0029",
            "14c35e772b4848479337508f2adf65d9",
            "5da94d2b31c1475caf63f3251b522549",
            "d2586a3fb0b3403ca2bda27aac3c4d9b",
            "8c2731053d924e1d9b3d5248b408f09a",
            "430b975abe05466f80f24250078a5158",
            "ba9062a03b4047639b0b6456a83a4b78",
            "a98c967c27df4be08cfd2c8b817b21e9",
            "c1f97c608941428ab408c0010a7aca72",
            "9d2c674e501b47279c4bc35c9e29fff4",
            "21bcfbbe35ed41e4a916fdc3ae466341",
            "f8879e8b511e4355b729381139860a87",
            "0d5a1931cbb24dc4a9d0aa04777f9779",
            "0bfe6f5728e24c62b2ae817db2a296ca",
            "d6b5da14ff804cf0a041f91d7dd71ff0",
            "b2655decd73e4333804d3ffb4629f0bb",
            "14276dd8994c46beb889ae51e8222301",
            "7efe4178b8e54d86922524a18f9699ab",
            "26ab7e201b7444bc852b1afdb5fbbc67",
            "64cbfb2ace974d6e9fe59dc98f21b92a",
            "b350ad0a7c884b4b9007fc39182445ad",
            "7322af938f4a49d4864a55e11b820740",
            "b15e4ed855c6466893ebb1c261b0b718",
            "643d5c4b26eb4ed9b465b05a2d861f37",
            "ec77cd82dd754f5089fe49f11678c5b8",
            "358ac6c1a160409fb32db2c29d27dc2f",
            "227e408492ae4e949b71dd120dc4a94f",
            "305a23f9e2004631bd314af17ff86ccc",
            "b453ea309fc84dc39e8c28963358b208",
            "986af53733cd483c8edc79f19225a105"
          ]
        }
      },
      "source": [
        "for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
        "    iter_bar = tqdm(train_dataloader, desc=\"Train Step(XX/XX) (Mean loss=X.X) (loss=X.X)\", leave=False, ncols=1000)\n",
        "    tr_step, total_loss, mean_loss = 0, 0., 0.\n",
        "    for step, batch in enumerate(iter_bar):\n",
        "        batch = tuple(t.to(device) for t in batch)  # multi-gpu does scattering it-self\n",
        "        input_ids, input_mask, segment_ids, start_positions, end_positions = batch\n",
        "        loss = model(input_ids, segment_ids, input_mask, start_positions, end_positions)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "        scheduler.step()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        global_step += 1\n",
        "        tr_step += 1\n",
        "        total_loss += loss\n",
        "        mean_loss = total_loss / tr_step\n",
        "        iter_bar.set_description(\"Train Step(%d / %d) (Mean loss=%5.5f) (loss=%5.5f)\" % (global_step, num_train_step, mean_loss, loss.item()))\n",
        "            \n",
        "    logger.info(\"***** Saving file *****\")\n",
        "    model_checkpoint = \"korquad_%d.bin\" % (epoch)\n",
        "    logger.info(model_checkpoint)\n",
        "    output_model_file = os.path.join(output_dir,model_checkpoint)\n",
        "    torch.save(model.state_dict(), output_model_file)\n",
        "    epoch += 1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "140c4e20939d443aa2a9eb480bcc2244",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44ff86e536f8440a970ba95fd2740d20",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Train Step(XX/XX) (Mean loss=X.X) (loss=X.X)', layout=Lay…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "05/15/2020 01:50:56 - INFO - __main__ -   ***** Saving file *****\n",
            "05/15/2020 01:50:56 - INFO - __main__ -   korquad_0.bin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba9062a03b4047639b0b6456a83a4b78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Train Step(XX/XX) (Mean loss=X.X) (loss=X.X)', layout=Lay…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 02:07:08 - INFO - __main__ -   ***** Saving file *****\n",
            "05/15/2020 02:07:08 - INFO - __main__ -   korquad_1.bin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6b5da14ff804cf0a041f91d7dd71ff0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Train Step(XX/XX) (Mean loss=X.X) (loss=X.X)', layout=Lay…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 02:23:22 - INFO - __main__ -   ***** Saving file *****\n",
            "05/15/2020 02:23:22 - INFO - __main__ -   korquad_2.bin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b15e4ed855c6466893ebb1c261b0b718",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Train Step(XX/XX) (Mean loss=X.X) (loss=X.X)', layout=Lay…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 02:39:40 - INFO - __main__ -   ***** Saving file *****\n",
            "05/15/2020 02:39:40 - INFO - __main__ -   korquad_3.bin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_76hfZn6cfB",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv_NH6blGspb",
        "colab_type": "text"
      },
      "source": [
        "## 최종 모델 로딩 및 KorQuAD Devset 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXjo-o0O6rTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = os.path.join(gdrive_path, \"korquad_3.bin\")\n",
        "predict = os.path.join(gdrive_path, \"KorQuAD_v1.0_dev.json\")\n",
        "\n",
        "predict_batch_size = 16 #@param {type: \"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymZR9vi06Tst",
        "colab_type": "code",
        "outputId": "6bffe10d-2f25-424f-a613-63df8e524926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load(checkpoint))\n",
        "num_params = count_parameters(model)\n",
        "logger.info(\"Total Parameter: %d\" % num_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 02:39:40 - INFO - __main__ -   Total Parameter: 17867522\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ltwxhw47Pbq",
        "colab_type": "code",
        "outputId": "ad59c808-d7b3-46a2-baf2-3e447a81e0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "eval_examples = read_squad_examples(input_file=predict,\n",
        "                               is_training=False,\n",
        "                               version_2_with_negative=False)\n",
        "eval_features = convert_examples_to_features(examples=eval_examples,\n",
        "                                        tokenizer=tokenizer,\n",
        "                                        max_seq_length=max_seq_length,\n",
        "                                        doc_stride=doc_stride,\n",
        "                                        max_query_length=max_query_length,\n",
        "                                        is_training=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000000\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 임종 ##석 ##이 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ##로 지명 ##수 ##배 된 날 ##은 ? [SEP] 1989 ##년 2 ##월 15 ##일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되 ##었 ##다 . 1989 ##년 3 ##월 12 ##일 서울 ##지방검찰청 공안 ##부 ##는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장 ##을 발부 ##받 ##았 ##다 . 같 ##은 해 6 ##월 30 ##일 평양 ##축 ##전 ##에 임수 ##경 ##을 대표 ##로 파견하여 국가보안법 ##위 ##반 혐의 ##가 추가 ##되 ##었 ##다 . 경찰 ##은 12 ##월 18 ##일 ~ 20 ##일 사이 서울 경희대학교 ##에 ##서 임종 ##석 ##이 성명 발표 ##를 추진 ##하 ##고 있 ##다는 첩보 ##를 입수 ##했 ##고 , 12 ##월 18 ##일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명 ##의 사복 경찰 ##을 승용차 8 ##대 ##에 나누 ##어 경희대학교 ##에 투입 ##했 ##다 . 1989 ##년 12 ##월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰서 ##는 호위 학생 5 ##명 ##과 함께 경희대학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했 ##다 . 임종 ##석 ##은 청량리 ##경찰서 ##에 ##서 약 1 ##시간 동안 조사 ##를 받 ##은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되 ##었 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 21:0 22:0 23:1 24:1 25:2 26:2 27:3 28:4 29:5 30:6 31:6 32:7 33:7 34:8 35:8 36:8 37:8 38:8 39:8 40:8 41:8 42:8 43:8 44:8 45:8 46:8 47:8 48:8 49:8 50:9 51:9 52:9 53:9 54:9 55:9 56:9 57:10 58:10 59:11 60:11 61:12 62:12 63:13 64:13 65:14 66:14 67:14 68:15 69:15 70:15 71:16 72:16 73:16 74:16 75:16 76:16 77:17 78:17 79:17 80:17 81:17 82:18 83:18 84:19 85:20 86:20 87:21 88:21 89:22 90:22 91:22 92:22 93:23 94:23 95:23 96:24 97:24 98:25 99:26 100:26 101:26 102:27 103:27 104:28 105:28 106:28 107:28 108:28 109:29 110:29 111:30 112:30 113:31 114:31 115:31 116:31 117:31 118:32 119:33 120:34 121:34 122:34 123:35 124:35 125:35 126:36 127:37 128:37 129:38 130:38 131:38 132:39 133:39 134:40 135:40 136:41 137:41 138:41 139:41 140:42 141:42 142:43 143:43 144:44 145:45 146:45 147:46 148:46 149:47 150:48 151:48 152:48 153:49 154:49 155:49 156:50 157:50 158:51 159:51 160:52 161:53 162:53 163:54 164:55 165:55 166:56 167:57 168:57 169:57 170:58 171:59 172:59 173:60 174:61 175:61 176:61 177:62 178:62 179:63 180:63 181:64 182:64 183:64 184:64 185:65 186:65 187:66 188:66 189:67 190:67 191:68 192:69 193:69 194:70 195:70 196:71 197:72 198:72 199:72 200:72 201:72 202:72 203:73 204:74 205:75 206:75 207:75 208:76 209:77 210:78 211:78 212:79 213:80 214:80 215:81 216:81 217:82 218:82 219:82 220:83 221:83 222:84 223:84 224:85 225:85 226:86 227:86 228:86 229:86 230:87 231:87 232:87 233:88 234:88 235:88 236:88 237:89 238:90 239:90 240:91 241:92 242:92 243:93 244:93 245:94 246:95 247:96 248:96 249:97 250:97 251:98 252:99 253:100 254:100 255:100 256:101 257:101 258:101 259:101 260:102 261:102 262:102 263:102 264:103 265:103 266:103 267:103 268:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 14919 28411 28135 12006 3244 2959 1988 28154 1568 28150 2386 28141 1468 28172 28361 65 433 28151 1132 3 1981 28165 33 28210 298 28171 12006 3244 2959 1988 28154 1568 28150 2386 24 2959 8166 28257 28378 28531 28137 28251 28150 28334 28693 28202 28282 23 27 1468 28172 28361 28177 28182 28136 9 1981 28165 73 28210 218 28171 478 25023 13369 28176 28140 14919 28411 28139 2014 28200 28320 28264 28190 28144 23922 28349 28354 28136 9 156 28151 63 133 28210 527 28171 2547 28456 28178 28137 23357 28221 28144 392 28141 11566 14746 28202 28282 2386 28146 903 28177 28182 28136 9 1008 28151 218 28210 197 28171 239 56 28171 319 478 16897 28137 28149 14919 28411 28135 5410 512 28154 1537 28142 28147 28 3654 12513 28154 8606 28195 28147 13 218 28210 197 28171 2943 157 28158 1058 28279 71 2124 28436 28183 1135 28517 17099 2022 28150 16795 28212 275 6101 28183 2871 218 28243 78 727 28243 28139 24285 1008 28144 11759 160 28157 28137 2138 28168 16897 28137 2622 28195 28136 9 1981 28165 218 28210 197 28171 2943 160 28158 298 28279 71 478 28399 28460 28159 15533 28140 7737 924 106 28243 28183 280 16897 12995 28251 958 6541 28144 7947 28140 14919 28411 28144 562 13 10859 28181 3100 28144 2760 28195 28136 9 14919 28411 28151 22681 15533 28137 28149 286 17 26568 458 851 28154 132 28151 308 2943 183 28158 938 28279 71 478 10666 28197 28139 478 7366 10069 28399 13369 28279 28308 28141 15421 28177 28182 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000001\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 1\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 1989 ##년 6 ##월 30 ##일 평양 ##축 ##전 ##에 대표 ##로 파견 된 인물 ##은 ? [SEP] 1989 ##년 2 ##월 15 ##일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되 ##었 ##다 . 1989 ##년 3 ##월 12 ##일 서울 ##지방검찰청 공안 ##부 ##는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장 ##을 발부 ##받 ##았 ##다 . 같 ##은 해 6 ##월 30 ##일 평양 ##축 ##전 ##에 임수 ##경 ##을 대표 ##로 파견하여 국가보안법 ##위 ##반 혐의 ##가 추가 ##되 ##었 ##다 . 경찰 ##은 12 ##월 18 ##일 ~ 20 ##일 사이 서울 경희대학교 ##에 ##서 임종 ##석 ##이 성명 발표 ##를 추진 ##하 ##고 있 ##다는 첩보 ##를 입수 ##했 ##고 , 12 ##월 18 ##일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명 ##의 사복 경찰 ##을 승용차 8 ##대 ##에 나누 ##어 경희대학교 ##에 투입 ##했 ##다 . 1989 ##년 12 ##월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰서 ##는 호위 학생 5 ##명 ##과 함께 경희대학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했 ##다 . 임종 ##석 ##은 청량리 ##경찰서 ##에 ##서 약 1 ##시간 동안 조사 ##를 받 ##은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되 ##었 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 19:0 20:0 21:1 22:1 23:2 24:2 25:3 26:4 27:5 28:6 29:6 30:7 31:7 32:8 33:8 34:8 35:8 36:8 37:8 38:8 39:8 40:8 41:8 42:8 43:8 44:8 45:8 46:8 47:8 48:9 49:9 50:9 51:9 52:9 53:9 54:9 55:10 56:10 57:11 58:11 59:12 60:12 61:13 62:13 63:14 64:14 65:14 66:15 67:15 68:15 69:16 70:16 71:16 72:16 73:16 74:16 75:17 76:17 77:17 78:17 79:17 80:18 81:18 82:19 83:20 84:20 85:21 86:21 87:22 88:22 89:22 90:22 91:23 92:23 93:23 94:24 95:24 96:25 97:26 98:26 99:26 100:27 101:27 102:28 103:28 104:28 105:28 106:28 107:29 108:29 109:30 110:30 111:31 112:31 113:31 114:31 115:31 116:32 117:33 118:34 119:34 120:34 121:35 122:35 123:35 124:36 125:37 126:37 127:38 128:38 129:38 130:39 131:39 132:40 133:40 134:41 135:41 136:41 137:41 138:42 139:42 140:43 141:43 142:44 143:45 144:45 145:46 146:46 147:47 148:48 149:48 150:48 151:49 152:49 153:49 154:50 155:50 156:51 157:51 158:52 159:53 160:53 161:54 162:55 163:55 164:56 165:57 166:57 167:57 168:58 169:59 170:59 171:60 172:61 173:61 174:61 175:62 176:62 177:63 178:63 179:64 180:64 181:64 182:64 183:65 184:65 185:66 186:66 187:67 188:67 189:68 190:69 191:69 192:70 193:70 194:71 195:72 196:72 197:72 198:72 199:72 200:72 201:73 202:74 203:75 204:75 205:75 206:76 207:77 208:78 209:78 210:79 211:80 212:80 213:81 214:81 215:82 216:82 217:82 218:83 219:83 220:84 221:84 222:85 223:85 224:86 225:86 226:86 227:86 228:87 229:87 230:87 231:88 232:88 233:88 234:88 235:89 236:90 237:90 238:91 239:92 240:92 241:93 242:93 243:94 244:95 245:96 246:96 247:97 248:97 249:98 250:99 251:100 252:100 253:100 254:101 255:101 256:101 257:101 258:102 259:102 260:102 261:102 262:103 263:103 264:103 265:103 266:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 1981 28165 133 28210 527 28171 2547 28456 28178 28137 392 28141 1753 65 951 28151 1132 3 1981 28165 33 28210 298 28171 12006 3244 2959 1988 28154 1568 28150 2386 24 2959 8166 28257 28378 28531 28137 28251 28150 28334 28693 28202 28282 23 27 1468 28172 28361 28177 28182 28136 9 1981 28165 73 28210 218 28171 478 25023 13369 28176 28140 14919 28411 28139 2014 28200 28320 28264 28190 28144 23922 28349 28354 28136 9 156 28151 63 133 28210 527 28171 2547 28456 28178 28137 23357 28221 28144 392 28141 11566 14746 28202 28282 2386 28146 903 28177 28182 28136 9 1008 28151 218 28210 197 28171 239 56 28171 319 478 16897 28137 28149 14919 28411 28135 5410 512 28154 1537 28142 28147 28 3654 12513 28154 8606 28195 28147 13 218 28210 197 28171 2943 157 28158 1058 28279 71 2124 28436 28183 1135 28517 17099 2022 28150 16795 28212 275 6101 28183 2871 218 28243 78 727 28243 28139 24285 1008 28144 11759 160 28157 28137 2138 28168 16897 28137 2622 28195 28136 9 1981 28165 218 28210 197 28171 2943 160 28158 298 28279 71 478 28399 28460 28159 15533 28140 7737 924 106 28243 28183 280 16897 12995 28251 958 6541 28144 7947 28140 14919 28411 28144 562 13 10859 28181 3100 28144 2760 28195 28136 9 14919 28411 28151 22681 15533 28137 28149 286 17 26568 458 851 28154 132 28151 308 2943 183 28158 938 28279 71 478 10666 28197 28139 478 7366 10069 28399 13369 28279 28308 28141 15421 28177 28182 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000002\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 2\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 임종 ##석 ##이 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ##로 지명 ##수 ##배 ##된 연도 ##는 ? [SEP] 1989 ##년 2 ##월 15 ##일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되 ##었 ##다 . 1989 ##년 3 ##월 12 ##일 서울 ##지방검찰청 공안 ##부 ##는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장 ##을 발부 ##받 ##았 ##다 . 같 ##은 해 6 ##월 30 ##일 평양 ##축 ##전 ##에 임수 ##경 ##을 대표 ##로 파견하여 국가보안법 ##위 ##반 혐의 ##가 추가 ##되 ##었 ##다 . 경찰 ##은 12 ##월 18 ##일 ~ 20 ##일 사이 서울 경희대학교 ##에 ##서 임종 ##석 ##이 성명 발표 ##를 추진 ##하 ##고 있 ##다는 첩보 ##를 입수 ##했 ##고 , 12 ##월 18 ##일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명 ##의 사복 경찰 ##을 승용차 8 ##대 ##에 나누 ##어 경희대학교 ##에 투입 ##했 ##다 . 1989 ##년 12 ##월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰서 ##는 호위 학생 5 ##명 ##과 함께 경희대학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했 ##다 . 임종 ##석 ##은 청량리 ##경찰서 ##에 ##서 약 1 ##시간 동안 조사 ##를 받 ##은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되 ##었 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 21:0 22:0 23:1 24:1 25:2 26:2 27:3 28:4 29:5 30:6 31:6 32:7 33:7 34:8 35:8 36:8 37:8 38:8 39:8 40:8 41:8 42:8 43:8 44:8 45:8 46:8 47:8 48:8 49:8 50:9 51:9 52:9 53:9 54:9 55:9 56:9 57:10 58:10 59:11 60:11 61:12 62:12 63:13 64:13 65:14 66:14 67:14 68:15 69:15 70:15 71:16 72:16 73:16 74:16 75:16 76:16 77:17 78:17 79:17 80:17 81:17 82:18 83:18 84:19 85:20 86:20 87:21 88:21 89:22 90:22 91:22 92:22 93:23 94:23 95:23 96:24 97:24 98:25 99:26 100:26 101:26 102:27 103:27 104:28 105:28 106:28 107:28 108:28 109:29 110:29 111:30 112:30 113:31 114:31 115:31 116:31 117:31 118:32 119:33 120:34 121:34 122:34 123:35 124:35 125:35 126:36 127:37 128:37 129:38 130:38 131:38 132:39 133:39 134:40 135:40 136:41 137:41 138:41 139:41 140:42 141:42 142:43 143:43 144:44 145:45 146:45 147:46 148:46 149:47 150:48 151:48 152:48 153:49 154:49 155:49 156:50 157:50 158:51 159:51 160:52 161:53 162:53 163:54 164:55 165:55 166:56 167:57 168:57 169:57 170:58 171:59 172:59 173:60 174:61 175:61 176:61 177:62 178:62 179:63 180:63 181:64 182:64 183:64 184:64 185:65 186:65 187:66 188:66 189:67 190:67 191:68 192:69 193:69 194:70 195:70 196:71 197:72 198:72 199:72 200:72 201:72 202:72 203:73 204:74 205:75 206:75 207:75 208:76 209:77 210:78 211:78 212:79 213:80 214:80 215:81 216:81 217:82 218:82 219:82 220:83 221:83 222:84 223:84 224:85 225:85 226:86 227:86 228:86 229:86 230:87 231:87 232:87 233:88 234:88 235:88 236:88 237:89 238:90 239:90 240:91 241:92 242:92 243:93 244:93 245:94 246:95 247:96 248:96 249:97 250:97 251:98 252:99 253:100 254:100 255:100 256:101 257:101 258:101 259:101 260:102 261:102 262:102 263:102 264:103 265:103 266:103 267:103 268:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 14919 28411 28135 12006 3244 2959 1988 28154 1568 28150 2386 28141 1468 28172 28361 28255 8397 28140 1132 3 1981 28165 33 28210 298 28171 12006 3244 2959 1988 28154 1568 28150 2386 24 2959 8166 28257 28378 28531 28137 28251 28150 28334 28693 28202 28282 23 27 1468 28172 28361 28177 28182 28136 9 1981 28165 73 28210 218 28171 478 25023 13369 28176 28140 14919 28411 28139 2014 28200 28320 28264 28190 28144 23922 28349 28354 28136 9 156 28151 63 133 28210 527 28171 2547 28456 28178 28137 23357 28221 28144 392 28141 11566 14746 28202 28282 2386 28146 903 28177 28182 28136 9 1008 28151 218 28210 197 28171 239 56 28171 319 478 16897 28137 28149 14919 28411 28135 5410 512 28154 1537 28142 28147 28 3654 12513 28154 8606 28195 28147 13 218 28210 197 28171 2943 157 28158 1058 28279 71 2124 28436 28183 1135 28517 17099 2022 28150 16795 28212 275 6101 28183 2871 218 28243 78 727 28243 28139 24285 1008 28144 11759 160 28157 28137 2138 28168 16897 28137 2622 28195 28136 9 1981 28165 218 28210 197 28171 2943 160 28158 298 28279 71 478 28399 28460 28159 15533 28140 7737 924 106 28243 28183 280 16897 12995 28251 958 6541 28144 7947 28140 14919 28411 28144 562 13 10859 28181 3100 28144 2760 28195 28136 9 14919 28411 28151 22681 15533 28137 28149 286 17 26568 458 851 28154 132 28151 308 2943 183 28158 938 28279 71 478 10666 28197 28139 478 7366 10069 28399 13369 28279 28308 28141 15421 28177 28182 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000003\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 3\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 임종 ##석 ##을 검거 ##한 장소 ##는 경희 ##대 내 어디 ##인 ##가 ? [SEP] 1989 ##년 2 ##월 15 ##일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되 ##었 ##다 . 1989 ##년 3 ##월 12 ##일 서울 ##지방검찰청 공안 ##부 ##는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장 ##을 발부 ##받 ##았 ##다 . 같 ##은 해 6 ##월 30 ##일 평양 ##축 ##전 ##에 임수 ##경 ##을 대표 ##로 파견하여 국가보안법 ##위 ##반 혐의 ##가 추가 ##되 ##었 ##다 . 경찰 ##은 12 ##월 18 ##일 ~ 20 ##일 사이 서울 경희대학교 ##에 ##서 임종 ##석 ##이 성명 발표 ##를 추진 ##하 ##고 있 ##다는 첩보 ##를 입수 ##했 ##고 , 12 ##월 18 ##일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명 ##의 사복 경찰 ##을 승용차 8 ##대 ##에 나누 ##어 경희대학교 ##에 투입 ##했 ##다 . 1989 ##년 12 ##월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰서 ##는 호위 학생 5 ##명 ##과 함께 경희대학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했 ##다 . 임종 ##석 ##은 청량리 ##경찰서 ##에 ##서 약 1 ##시간 동안 조사 ##를 받 ##은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되 ##었 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 16:0 17:0 18:1 19:1 20:2 21:2 22:3 23:4 24:5 25:6 26:6 27:7 28:7 29:8 30:8 31:8 32:8 33:8 34:8 35:8 36:8 37:8 38:8 39:8 40:8 41:8 42:8 43:8 44:8 45:9 46:9 47:9 48:9 49:9 50:9 51:9 52:10 53:10 54:11 55:11 56:12 57:12 58:13 59:13 60:14 61:14 62:14 63:15 64:15 65:15 66:16 67:16 68:16 69:16 70:16 71:16 72:17 73:17 74:17 75:17 76:17 77:18 78:18 79:19 80:20 81:20 82:21 83:21 84:22 85:22 86:22 87:22 88:23 89:23 90:23 91:24 92:24 93:25 94:26 95:26 96:26 97:27 98:27 99:28 100:28 101:28 102:28 103:28 104:29 105:29 106:30 107:30 108:31 109:31 110:31 111:31 112:31 113:32 114:33 115:34 116:34 117:34 118:35 119:35 120:35 121:36 122:37 123:37 124:38 125:38 126:38 127:39 128:39 129:40 130:40 131:41 132:41 133:41 134:41 135:42 136:42 137:43 138:43 139:44 140:45 141:45 142:46 143:46 144:47 145:48 146:48 147:48 148:49 149:49 150:49 151:50 152:50 153:51 154:51 155:52 156:53 157:53 158:54 159:55 160:55 161:56 162:57 163:57 164:57 165:58 166:59 167:59 168:60 169:61 170:61 171:61 172:62 173:62 174:63 175:63 176:64 177:64 178:64 179:64 180:65 181:65 182:66 183:66 184:67 185:67 186:68 187:69 188:69 189:70 190:70 191:71 192:72 193:72 194:72 195:72 196:72 197:72 198:73 199:74 200:75 201:75 202:75 203:76 204:77 205:78 206:78 207:79 208:80 209:80 210:81 211:81 212:82 213:82 214:82 215:83 216:83 217:84 218:84 219:85 220:85 221:86 222:86 223:86 224:86 225:87 226:87 227:87 228:88 229:88 230:88 231:88 232:89 233:90 234:90 235:91 236:92 237:92 238:93 239:93 240:94 241:95 242:96 243:96 244:97 245:97 246:98 247:99 248:100 249:100 250:100 251:101 252:101 253:101 254:101 255:102 256:102 257:102 258:102 259:103 260:103 261:103 262:103 263:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 14919 28411 28144 10859 28150 1821 28140 10846 28157 119 3990 28164 28146 1132 3 1981 28165 33 28210 298 28171 12006 3244 2959 1988 28154 1568 28150 2386 24 2959 8166 28257 28378 28531 28137 28251 28150 28334 28693 28202 28282 23 27 1468 28172 28361 28177 28182 28136 9 1981 28165 73 28210 218 28171 478 25023 13369 28176 28140 14919 28411 28139 2014 28200 28320 28264 28190 28144 23922 28349 28354 28136 9 156 28151 63 133 28210 527 28171 2547 28456 28178 28137 23357 28221 28144 392 28141 11566 14746 28202 28282 2386 28146 903 28177 28182 28136 9 1008 28151 218 28210 197 28171 239 56 28171 319 478 16897 28137 28149 14919 28411 28135 5410 512 28154 1537 28142 28147 28 3654 12513 28154 8606 28195 28147 13 218 28210 197 28171 2943 157 28158 1058 28279 71 2124 28436 28183 1135 28517 17099 2022 28150 16795 28212 275 6101 28183 2871 218 28243 78 727 28243 28139 24285 1008 28144 11759 160 28157 28137 2138 28168 16897 28137 2622 28195 28136 9 1981 28165 218 28210 197 28171 2943 160 28158 298 28279 71 478 28399 28460 28159 15533 28140 7737 924 106 28243 28183 280 16897 12995 28251 958 6541 28144 7947 28140 14919 28411 28144 562 13 10859 28181 3100 28144 2760 28195 28136 9 14919 28411 28151 22681 15533 28137 28149 286 17 26568 458 851 28154 132 28151 308 2943 183 28158 938 28279 71 478 10666 28197 28139 478 7366 10069 28399 13369 28279 28308 28141 15421 28177 28182 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000004\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 4\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 임종 ##석 ##이 조사 ##를 받 ##은 뒤 인계 ##된 곳 ##은 어딘가 ? [SEP] 1989 ##년 2 ##월 15 ##일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되 ##었 ##다 . 1989 ##년 3 ##월 12 ##일 서울 ##지방검찰청 공안 ##부 ##는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장 ##을 발부 ##받 ##았 ##다 . 같 ##은 해 6 ##월 30 ##일 평양 ##축 ##전 ##에 임수 ##경 ##을 대표 ##로 파견하여 국가보안법 ##위 ##반 혐의 ##가 추가 ##되 ##었 ##다 . 경찰 ##은 12 ##월 18 ##일 ~ 20 ##일 사이 서울 경희대학교 ##에 ##서 임종 ##석 ##이 성명 발표 ##를 추진 ##하 ##고 있 ##다는 첩보 ##를 입수 ##했 ##고 , 12 ##월 18 ##일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명 ##의 사복 경찰 ##을 승용차 8 ##대 ##에 나누 ##어 경희대학교 ##에 투입 ##했 ##다 . 1989 ##년 12 ##월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰서 ##는 호위 학생 5 ##명 ##과 함께 경희대학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했 ##다 . 임종 ##석 ##은 청량리 ##경찰서 ##에 ##서 약 1 ##시간 동안 조사 ##를 받 ##은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되 ##었 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 16:0 17:0 18:1 19:1 20:2 21:2 22:3 23:4 24:5 25:6 26:6 27:7 28:7 29:8 30:8 31:8 32:8 33:8 34:8 35:8 36:8 37:8 38:8 39:8 40:8 41:8 42:8 43:8 44:8 45:9 46:9 47:9 48:9 49:9 50:9 51:9 52:10 53:10 54:11 55:11 56:12 57:12 58:13 59:13 60:14 61:14 62:14 63:15 64:15 65:15 66:16 67:16 68:16 69:16 70:16 71:16 72:17 73:17 74:17 75:17 76:17 77:18 78:18 79:19 80:20 81:20 82:21 83:21 84:22 85:22 86:22 87:22 88:23 89:23 90:23 91:24 92:24 93:25 94:26 95:26 96:26 97:27 98:27 99:28 100:28 101:28 102:28 103:28 104:29 105:29 106:30 107:30 108:31 109:31 110:31 111:31 112:31 113:32 114:33 115:34 116:34 117:34 118:35 119:35 120:35 121:36 122:37 123:37 124:38 125:38 126:38 127:39 128:39 129:40 130:40 131:41 132:41 133:41 134:41 135:42 136:42 137:43 138:43 139:44 140:45 141:45 142:46 143:46 144:47 145:48 146:48 147:48 148:49 149:49 150:49 151:50 152:50 153:51 154:51 155:52 156:53 157:53 158:54 159:55 160:55 161:56 162:57 163:57 164:57 165:58 166:59 167:59 168:60 169:61 170:61 171:61 172:62 173:62 174:63 175:63 176:64 177:64 178:64 179:64 180:65 181:65 182:66 183:66 184:67 185:67 186:68 187:69 188:69 189:70 190:70 191:71 192:72 193:72 194:72 195:72 196:72 197:72 198:73 199:74 200:75 201:75 202:75 203:76 204:77 205:78 206:78 207:79 208:80 209:80 210:81 211:81 212:82 213:82 214:82 215:83 216:83 217:84 218:84 219:85 220:85 221:86 222:86 223:86 224:86 225:87 226:87 227:87 228:88 229:88 230:88 231:88 232:89 233:90 234:90 235:91 236:92 237:92 238:93 239:93 240:94 241:95 242:96 243:96 244:97 245:97 246:98 247:99 248:100 249:100 250:100 251:101 252:101 253:101 254:101 255:102 256:102 257:102 258:102 259:103 260:103 261:103 262:103 263:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 14919 28411 28135 851 28154 132 28151 308 15421 28255 517 28151 21123 1132 3 1981 28165 33 28210 298 28171 12006 3244 2959 1988 28154 1568 28150 2386 24 2959 8166 28257 28378 28531 28137 28251 28150 28334 28693 28202 28282 23 27 1468 28172 28361 28177 28182 28136 9 1981 28165 73 28210 218 28171 478 25023 13369 28176 28140 14919 28411 28139 2014 28200 28320 28264 28190 28144 23922 28349 28354 28136 9 156 28151 63 133 28210 527 28171 2547 28456 28178 28137 23357 28221 28144 392 28141 11566 14746 28202 28282 2386 28146 903 28177 28182 28136 9 1008 28151 218 28210 197 28171 239 56 28171 319 478 16897 28137 28149 14919 28411 28135 5410 512 28154 1537 28142 28147 28 3654 12513 28154 8606 28195 28147 13 218 28210 197 28171 2943 157 28158 1058 28279 71 2124 28436 28183 1135 28517 17099 2022 28150 16795 28212 275 6101 28183 2871 218 28243 78 727 28243 28139 24285 1008 28144 11759 160 28157 28137 2138 28168 16897 28137 2622 28195 28136 9 1981 28165 218 28210 197 28171 2943 160 28158 298 28279 71 478 28399 28460 28159 15533 28140 7737 924 106 28243 28183 280 16897 12995 28251 958 6541 28144 7947 28140 14919 28411 28144 562 13 10859 28181 3100 28144 2760 28195 28136 9 14919 28411 28151 22681 15533 28137 28149 286 17 26568 458 851 28154 132 28151 308 2943 183 28158 938 28279 71 478 10666 28197 28139 478 7366 10069 28399 13369 28279 28308 28141 15421 28177 28182 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000005\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 5\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 1989 ##년 2 ##월 15 ##일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ##로 지명 ##수 ##배 ##된 사람 ##의 이름 ##은 ? [SEP] 1989 ##년 2 ##월 15 ##일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되 ##었 ##다 . 1989 ##년 3 ##월 12 ##일 서울 ##지방검찰청 공안 ##부 ##는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장 ##을 발부 ##받 ##았 ##다 . 같 ##은 해 6 ##월 30 ##일 평양 ##축 ##전 ##에 임수 ##경 ##을 대표 ##로 파견하여 국가보안법 ##위 ##반 혐의 ##가 추가 ##되 ##었 ##다 . 경찰 ##은 12 ##월 18 ##일 ~ 20 ##일 사이 서울 경희대학교 ##에 ##서 임종 ##석 ##이 성명 발표 ##를 추진 ##하 ##고 있 ##다는 첩보 ##를 입수 ##했 ##고 , 12 ##월 18 ##일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명 ##의 사복 경찰 ##을 승용차 8 ##대 ##에 나누 ##어 경희대학교 ##에 투입 ##했 ##다 . 1989 ##년 12 ##월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰서 ##는 호위 학생 5 ##명 ##과 함께 경희대학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했 ##다 . 임종 ##석 ##은 청량리 ##경찰서 ##에 ##서 약 1 ##시간 동안 조사 ##를 받 ##은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되 ##었 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 26:0 27:0 28:1 29:1 30:2 31:2 32:3 33:4 34:5 35:6 36:6 37:7 38:7 39:8 40:8 41:8 42:8 43:8 44:8 45:8 46:8 47:8 48:8 49:8 50:8 51:8 52:8 53:8 54:8 55:9 56:9 57:9 58:9 59:9 60:9 61:9 62:10 63:10 64:11 65:11 66:12 67:12 68:13 69:13 70:14 71:14 72:14 73:15 74:15 75:15 76:16 77:16 78:16 79:16 80:16 81:16 82:17 83:17 84:17 85:17 86:17 87:18 88:18 89:19 90:20 91:20 92:21 93:21 94:22 95:22 96:22 97:22 98:23 99:23 100:23 101:24 102:24 103:25 104:26 105:26 106:26 107:27 108:27 109:28 110:28 111:28 112:28 113:28 114:29 115:29 116:30 117:30 118:31 119:31 120:31 121:31 122:31 123:32 124:33 125:34 126:34 127:34 128:35 129:35 130:35 131:36 132:37 133:37 134:38 135:38 136:38 137:39 138:39 139:40 140:40 141:41 142:41 143:41 144:41 145:42 146:42 147:43 148:43 149:44 150:45 151:45 152:46 153:46 154:47 155:48 156:48 157:48 158:49 159:49 160:49 161:50 162:50 163:51 164:51 165:52 166:53 167:53 168:54 169:55 170:55 171:56 172:57 173:57 174:57 175:58 176:59 177:59 178:60 179:61 180:61 181:61 182:62 183:62 184:63 185:63 186:64 187:64 188:64 189:64 190:65 191:65 192:66 193:66 194:67 195:67 196:68 197:69 198:69 199:70 200:70 201:71 202:72 203:72 204:72 205:72 206:72 207:72 208:73 209:74 210:75 211:75 212:75 213:76 214:77 215:78 216:78 217:79 218:80 219:80 220:81 221:81 222:82 223:82 224:82 225:83 226:83 227:84 228:84 229:85 230:85 231:86 232:86 233:86 234:86 235:87 236:87 237:87 238:88 239:88 240:88 241:88 242:89 243:90 244:90 245:91 246:92 247:92 248:93 249:93 250:94 251:95 252:96 253:96 254:97 255:97 256:98 257:99 258:100 259:100 260:100 261:101 262:101 263:101 264:101 265:102 266:102 267:102 268:102 269:103 270:103 271:103 272:103 273:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 1981 28165 33 28210 298 28171 12006 3244 2959 1988 28154 1568 28150 2386 28141 1468 28172 28361 28255 267 28139 323 28151 1132 3 1981 28165 33 28210 298 28171 12006 3244 2959 1988 28154 1568 28150 2386 24 2959 8166 28257 28378 28531 28137 28251 28150 28334 28693 28202 28282 23 27 1468 28172 28361 28177 28182 28136 9 1981 28165 73 28210 218 28171 478 25023 13369 28176 28140 14919 28411 28139 2014 28200 28320 28264 28190 28144 23922 28349 28354 28136 9 156 28151 63 133 28210 527 28171 2547 28456 28178 28137 23357 28221 28144 392 28141 11566 14746 28202 28282 2386 28146 903 28177 28182 28136 9 1008 28151 218 28210 197 28171 239 56 28171 319 478 16897 28137 28149 14919 28411 28135 5410 512 28154 1537 28142 28147 28 3654 12513 28154 8606 28195 28147 13 218 28210 197 28171 2943 157 28158 1058 28279 71 2124 28436 28183 1135 28517 17099 2022 28150 16795 28212 275 6101 28183 2871 218 28243 78 727 28243 28139 24285 1008 28144 11759 160 28157 28137 2138 28168 16897 28137 2622 28195 28136 9 1981 28165 218 28210 197 28171 2943 160 28158 298 28279 71 478 28399 28460 28159 15533 28140 7737 924 106 28243 28183 280 16897 12995 28251 958 6541 28144 7947 28140 14919 28411 28144 562 13 10859 28181 3100 28144 2760 28195 28136 9 14919 28411 28151 22681 15533 28137 28149 286 17 26568 458 851 28154 132 28151 308 2943 183 28158 938 28279 71 478 10666 28197 28139 478 7366 10069 28399 13369 28279 28308 28141 15421 28177 28182 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000006\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 6\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 임종 ##석 ##이 1989 ##년 2 ##월 15 ##일 ##에 지명 ##수 ##배 받 ##은 혐의 ##는 어떤 시위 ##를 주도 ##했 ##다는 것 ##인 ##가 ? [SEP] 1989 ##년 2 ##월 15 ##일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되 ##었 ##다 . 1989 ##년 3 ##월 12 ##일 서울 ##지방검찰청 공안 ##부 ##는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장 ##을 발부 ##받 ##았 ##다 . 같 ##은 해 6 ##월 30 ##일 평양 ##축 ##전 ##에 임수 ##경 ##을 대표 ##로 파견하여 국가보안법 ##위 ##반 혐의 ##가 추가 ##되 ##었 ##다 . 경찰 ##은 12 ##월 18 ##일 ~ 20 ##일 사이 서울 경희대학교 ##에 ##서 임종 ##석 ##이 성명 발표 ##를 추진 ##하 ##고 있 ##다는 첩보 ##를 입수 ##했 ##고 , 12 ##월 18 ##일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명 ##의 사복 경찰 ##을 승용차 8 ##대 ##에 나누 ##어 경희대학교 ##에 투입 ##했 ##다 . 1989 ##년 12 ##월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰서 ##는 호위 학생 5 ##명 ##과 함께 경희대학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했 ##다 . 임종 ##석 ##은 청량리 ##경찰서 ##에 ##서 약 1 ##시간 동안 조사 ##를 받 ##은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되 ##었 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 29:0 30:0 31:1 32:1 33:2 34:2 35:3 36:4 37:5 38:6 39:6 40:7 41:7 42:8 43:8 44:8 45:8 46:8 47:8 48:8 49:8 50:8 51:8 52:8 53:8 54:8 55:8 56:8 57:8 58:9 59:9 60:9 61:9 62:9 63:9 64:9 65:10 66:10 67:11 68:11 69:12 70:12 71:13 72:13 73:14 74:14 75:14 76:15 77:15 78:15 79:16 80:16 81:16 82:16 83:16 84:16 85:17 86:17 87:17 88:17 89:17 90:18 91:18 92:19 93:20 94:20 95:21 96:21 97:22 98:22 99:22 100:22 101:23 102:23 103:23 104:24 105:24 106:25 107:26 108:26 109:26 110:27 111:27 112:28 113:28 114:28 115:28 116:28 117:29 118:29 119:30 120:30 121:31 122:31 123:31 124:31 125:31 126:32 127:33 128:34 129:34 130:34 131:35 132:35 133:35 134:36 135:37 136:37 137:38 138:38 139:38 140:39 141:39 142:40 143:40 144:41 145:41 146:41 147:41 148:42 149:42 150:43 151:43 152:44 153:45 154:45 155:46 156:46 157:47 158:48 159:48 160:48 161:49 162:49 163:49 164:50 165:50 166:51 167:51 168:52 169:53 170:53 171:54 172:55 173:55 174:56 175:57 176:57 177:57 178:58 179:59 180:59 181:60 182:61 183:61 184:61 185:62 186:62 187:63 188:63 189:64 190:64 191:64 192:64 193:65 194:65 195:66 196:66 197:67 198:67 199:68 200:69 201:69 202:70 203:70 204:71 205:72 206:72 207:72 208:72 209:72 210:72 211:73 212:74 213:75 214:75 215:75 216:76 217:77 218:78 219:78 220:79 221:80 222:80 223:81 224:81 225:82 226:82 227:82 228:83 229:83 230:84 231:84 232:85 233:85 234:86 235:86 236:86 237:86 238:87 239:87 240:87 241:88 242:88 243:88 244:88 245:89 246:90 247:90 248:91 249:92 250:92 251:93 252:93 253:94 254:95 255:96 256:96 257:97 258:97 259:98 260:99 261:100 262:100 263:100 264:101 265:101 266:101 267:101 268:102 269:102 270:102 271:102 272:103 273:103 274:103 275:103 276:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 14919 28411 28135 1981 28165 33 28210 298 28171 28137 1468 28172 28361 132 28151 2386 28140 995 1988 28154 1568 28195 3654 64 28164 28146 1132 3 1981 28165 33 28210 298 28171 12006 3244 2959 1988 28154 1568 28150 2386 24 2959 8166 28257 28378 28531 28137 28251 28150 28334 28693 28202 28282 23 27 1468 28172 28361 28177 28182 28136 9 1981 28165 73 28210 218 28171 478 25023 13369 28176 28140 14919 28411 28139 2014 28200 28320 28264 28190 28144 23922 28349 28354 28136 9 156 28151 63 133 28210 527 28171 2547 28456 28178 28137 23357 28221 28144 392 28141 11566 14746 28202 28282 2386 28146 903 28177 28182 28136 9 1008 28151 218 28210 197 28171 239 56 28171 319 478 16897 28137 28149 14919 28411 28135 5410 512 28154 1537 28142 28147 28 3654 12513 28154 8606 28195 28147 13 218 28210 197 28171 2943 157 28158 1058 28279 71 2124 28436 28183 1135 28517 17099 2022 28150 16795 28212 275 6101 28183 2871 218 28243 78 727 28243 28139 24285 1008 28144 11759 160 28157 28137 2138 28168 16897 28137 2622 28195 28136 9 1981 28165 218 28210 197 28171 2943 160 28158 298 28279 71 478 28399 28460 28159 15533 28140 7737 924 106 28243 28183 280 16897 12995 28251 958 6541 28144 7947 28140 14919 28411 28144 562 13 10859 28181 3100 28144 2760 28195 28136 9 14919 28411 28151 22681 15533 28137 28149 286 17 26568 458 851 28154 132 28151 308 2943 183 28158 938 28279 71 478 10666 28197 28139 478 7366 10069 28399 13369 28279 28308 28141 15421 28177 28182 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000007\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 7\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 정부 ##의 헌법 ##개 ##정 ##안 준비 과정 ##에 대해서 청와대 비서실 ##이 아니 ##라 국무 ##회의 중심 ##으로 이뤄졌 ##어 ##야 했 ##다고 지적 ##한 원로 헌법 ##학자 ##는 ? [SEP] \" 내각 ##과 장관 ##들이 소외 ##되 ##고 대통령 ##비 ##서 ##실 ##의 권한 ##이 너무 크 ##다 \" , \" 행보 ##가 비서 본연 ##의 역할 ##을 벗어난 ##다 \" 는 의견 ##이 제기 ##되 ##었 ##다 . 대표 ##적 ##인 예 ##가 10 ##차 개헌 ##안 발표 ##이 ##다 . 원로 헌법 ##학자 ##인 허영 경희 ##대 석좌 ##교 ##수 ##는 정부 ##의 헌법 ##개 ##정 ##안 준비 과정 ##에 대해 \" 청와대 비서실 ##이 아닌 국무 ##회의 중심 ##으로 이뤄졌 ##어 ##야 했 ##다 \" 고 지적 ##했 ##다 . ' 국무 ##회의 ##의 심의 ##를 거쳐야 한다 ' ( 제 ##8 ##9 ##조 ) 는 헌법 규정 ##에 충실 ##하 ##지 않 ##았 ##다는 것 ##이 ##다 . 그러면서 \" 법무부 장관 ##을 제 ##쳐 ##놓 ##고 민정 ##수 ##석 ##이 개정안 ##을 설명 ##하 ##는 게 이해 ##가 안 된다 \" 고 지적 ##했 ##다 . 민정 ##수 ##석 ##은 국회의원 ##에 대해 책임지 ##는 법무부 장관 ##도 아니 ##고 , 국민 ##에 대해 책임지 ##는 사람 ##도 아니 ##기 때문 ##에 정당 ##성이 없 ##고 , 단지 대통령 ##의 신임 ##이 있 ##을 뿐 ##이 ##라는 것 ##이 ##다 . 또한 국무총리 선출 방식 ##에 대한 기자 ##의 질문 ##에 \" 문 대통령 ##도 취임 전 ##에 국무총리 ##에 ##게 실질 ##적 권한 ##을 주 ##겠 ##다고 했 ##지만 그러 ##지 못하 ##고 있 ##다 . 대통령 ##비 ##서 ##실장 ##만 ##도 못한 권한 ##을 행사 ##하 ##고 있 ##다 . \" 고 답변 ##했 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 33:0 34:0 35:0 36:1 37:1 38:2 39:2 40:2 41:3 42:3 43:3 44:3 45:3 46:4 47:4 48:5 49:6 50:6 51:6 52:6 53:7 54:7 55:7 56:8 57:9 58:9 59:10 60:10 61:11 62:11 63:11 64:11 65:12 66:12 67:13 68:13 69:13 70:13 71:13 72:14 73:14 74:14 75:15 76:15 77:16 78:16 79:17 80:17 81:18 82:18 83:18 84:18 85:19 86:20 87:20 88:20 89:21 90:22 91:22 92:23 93:23 94:23 95:23 96:24 97:24 98:25 99:25 100:25 101:25 102:26 103:27 104:27 105:28 106:29 107:29 108:30 109:30 110:31 111:32 112:32 113:33 114:33 115:34 116:34 117:34 118:35 119:35 120:35 121:35 122:36 123:36 124:36 125:36 126:37 127:37 128:37 129:37 130:38 131:38 132:39 133:40 134:40 135:40 136:40 137:40 138:40 139:40 140:40 141:40 142:41 143:42 144:42 145:43 146:43 147:43 148:44 149:44 150:44 151:45 152:45 153:45 154:45 155:46 156:47 157:47 158:48 159:48 160:49 161:49 162:49 163:49 164:50 165:50 166:50 167:50 168:51 169:51 170:52 171:52 172:52 173:53 174:54 175:54 176:55 177:56 178:56 179:56 180:57 181:57 182:57 183:57 184:58 185:58 186:58 187:58 188:59 189:59 190:60 191:61 192:61 193:62 194:63 195:63 196:64 197:64 198:64 199:65 200:65 201:66 202:67 203:67 204:68 205:68 206:69 207:69 208:70 209:70 210:71 211:71 212:72 213:72 214:72 215:73 216:74 217:74 218:75 219:75 220:76 221:76 222:77 223:77 224:77 225:78 226:78 227:78 228:78 229:79 230:80 231:81 232:82 233:82 234:83 235:84 236:84 237:85 238:85 239:86 240:86 241:87 242:87 243:88 244:89 245:89 246:90 247:90 248:90 249:91 250:91 251:92 252:92 253:93 254:93 255:93 256:94 257:94 258:95 259:95 260:96 261:96 262:97 263:97 264:97 265:98 266:98 267:98 268:98 269:98 270:98 271:99 272:100 273:100 274:101 275:101 276:101 277:102 278:102 279:102 280:102 281:102 282:103 283:103 284:103 285:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 393 28139 1325 28246 28180 28290 1489 606 28137 975 7039 26387 28135 373 28173 3940 6137 492 17099 11510 28168 28322 47 14548 2029 28150 6110 1325 680 28140 1132 3 68 2086 28183 1319 7694 12283 28177 28147 579 28230 28149 28308 28139 2733 28135 2115 270 28136 68 13 68 14740 28146 5424 27219 28139 803 28144 13168 28136 68 12 1904 28135 1804 28177 28182 28136 9 392 28191 28164 188 28146 149 28283 10141 28290 512 28135 28136 9 6110 1325 680 28164 18964 10846 28157 26890 28235 28172 28140 393 28139 1325 28246 28180 28290 1489 606 28137 387 68 7039 26387 28135 1024 3940 6137 492 17099 11510 28168 28322 47 28136 68 20 2029 28195 28136 9 84 3940 6137 28139 7316 28154 22421 77 84 24 58 28209 28179 28212 23 12 1325 1268 28137 6898 28142 28148 122 28354 3654 64 28135 28136 9 14639 68 10616 1319 28144 58 28541 28685 28147 10217 28172 28411 28135 12439 28144 1070 28142 28140 61 1453 28146 194 152 68 20 2029 28195 28136 9 10217 28172 28411 28151 2704 28137 387 26024 28140 10616 1319 28160 373 28147 13 772 28137 387 26024 28140 267 28160 373 28152 230 28137 1378 17700 165 28147 13 2508 579 28139 5296 28135 28 28144 676 28135 8338 64 28135 28136 9 255 7295 1387 773 28137 148 1963 28139 4571 28137 68 127 579 28160 1955 51 28137 7295 28137 28199 3440 28191 2733 28144 60 28755 14548 47 539 235 28148 740 28147 28 28136 9 579 28230 28149 9682 28203 28160 1985 2733 28144 1492 28142 28147 28 28136 9 68 20 8966 28195 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000008\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 8\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] ' 행보 ##가 비서 본연 ##의 역할 ##을 벗어난 ##다 ' , ' 장관 ##들 ##과 내각 ##이 소외 ##되 ##고 대통령 ##비 ##서 ##실 ##의 권한 ##이 너무 크 ##다 ' 는 의견 ##이 제기 ##된 대표 ##적 ##인 예 ##는 ? [SEP] \" 내각 ##과 장관 ##들이 소외 ##되 ##고 대통령 ##비 ##서 ##실 ##의 권한 ##이 너무 크 ##다 \" , \" 행보 ##가 비서 본연 ##의 역할 ##을 벗어난 ##다 \" 는 의견 ##이 제기 ##되 ##었 ##다 . 대표 ##적 ##인 예 ##가 10 ##차 개헌 ##안 발표 ##이 ##다 . 원로 헌법 ##학자 ##인 허영 경희 ##대 석좌 ##교 ##수 ##는 정부 ##의 헌법 ##개 ##정 ##안 준비 과정 ##에 대해 \" 청와대 비서실 ##이 아닌 국무 ##회의 중심 ##으로 이뤄졌 ##어 ##야 했 ##다 \" 고 지적 ##했 ##다 . ' 국무 ##회의 ##의 심의 ##를 거쳐야 한다 ' ( 제 ##8 ##9 ##조 ) 는 헌법 규정 ##에 충실 ##하 ##지 않 ##았 ##다는 것 ##이 ##다 . 그러면서 \" 법무부 장관 ##을 제 ##쳐 ##놓 ##고 민정 ##수 ##석 ##이 개정안 ##을 설명 ##하 ##는 게 이해 ##가 안 된다 \" 고 지적 ##했 ##다 . 민정 ##수 ##석 ##은 국회의원 ##에 대해 책임지 ##는 법무부 장관 ##도 아니 ##고 , 국민 ##에 대해 책임지 ##는 사람 ##도 아니 ##기 때문 ##에 정당 ##성이 없 ##고 , 단지 대통령 ##의 신임 ##이 있 ##을 뿐 ##이 ##라는 것 ##이 ##다 . 또한 국무총리 선출 방식 ##에 대한 기자 ##의 질문 ##에 \" 문 대통령 ##도 취임 전 ##에 국무총리 ##에 ##게 실질 ##적 권한 ##을 주 ##겠 ##다고 했 ##지만 그러 ##지 못하 ##고 있 ##다 . 대통령 ##비 ##서 ##실장 ##만 ##도 못한 권한 ##을 행사 ##하 ##고 있 ##다 . \" 고 답변 ##했 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 45:0 46:0 47:0 48:1 49:1 50:2 51:2 52:2 53:3 54:3 55:3 56:3 57:3 58:4 59:4 60:5 61:6 62:6 63:6 64:6 65:7 66:7 67:7 68:8 69:9 70:9 71:10 72:10 73:11 74:11 75:11 76:11 77:12 78:12 79:13 80:13 81:13 82:13 83:13 84:14 85:14 86:14 87:15 88:15 89:16 90:16 91:17 92:17 93:18 94:18 95:18 96:18 97:19 98:20 99:20 100:20 101:21 102:22 103:22 104:23 105:23 106:23 107:23 108:24 109:24 110:25 111:25 112:25 113:25 114:26 115:27 116:27 117:28 118:29 119:29 120:30 121:30 122:31 123:32 124:32 125:33 126:33 127:34 128:34 129:34 130:35 131:35 132:35 133:35 134:36 135:36 136:36 137:36 138:37 139:37 140:37 141:37 142:38 143:38 144:39 145:40 146:40 147:40 148:40 149:40 150:40 151:40 152:40 153:40 154:41 155:42 156:42 157:43 158:43 159:43 160:44 161:44 162:44 163:45 164:45 165:45 166:45 167:46 168:47 169:47 170:48 171:48 172:49 173:49 174:49 175:49 176:50 177:50 178:50 179:50 180:51 181:51 182:52 183:52 184:52 185:53 186:54 187:54 188:55 189:56 190:56 191:56 192:57 193:57 194:57 195:57 196:58 197:58 198:58 199:58 200:59 201:59 202:60 203:61 204:61 205:62 206:63 207:63 208:64 209:64 210:64 211:65 212:65 213:66 214:67 215:67 216:68 217:68 218:69 219:69 220:70 221:70 222:71 223:71 224:72 225:72 226:72 227:73 228:74 229:74 230:75 231:75 232:76 233:76 234:77 235:77 236:77 237:78 238:78 239:78 240:78 241:79 242:80 243:81 244:82 245:82 246:83 247:84 248:84 249:85 250:85 251:86 252:86 253:87 254:87 255:88 256:89 257:89 258:90 259:90 260:90 261:91 262:91 263:92 264:92 265:93 266:93 267:93 268:94 269:94 270:95 271:95 272:96 273:96 274:97 275:97 276:97 277:98 278:98 279:98 280:98 281:98 282:98 283:99 284:100 285:100 286:101 287:101 288:101 289:102 290:102 291:102 292:102 293:102 294:103 295:103 296:103 297:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 84 14740 28146 5424 27219 28139 803 28144 13168 28136 84 13 84 1319 28184 28183 2086 28135 12283 28177 28147 579 28230 28149 28308 28139 2733 28135 2115 270 28136 84 12 1904 28135 1804 28255 392 28191 28164 188 28140 1132 3 68 2086 28183 1319 7694 12283 28177 28147 579 28230 28149 28308 28139 2733 28135 2115 270 28136 68 13 68 14740 28146 5424 27219 28139 803 28144 13168 28136 68 12 1904 28135 1804 28177 28182 28136 9 392 28191 28164 188 28146 149 28283 10141 28290 512 28135 28136 9 6110 1325 680 28164 18964 10846 28157 26890 28235 28172 28140 393 28139 1325 28246 28180 28290 1489 606 28137 387 68 7039 26387 28135 1024 3940 6137 492 17099 11510 28168 28322 47 28136 68 20 2029 28195 28136 9 84 3940 6137 28139 7316 28154 22421 77 84 24 58 28209 28179 28212 23 12 1325 1268 28137 6898 28142 28148 122 28354 3654 64 28135 28136 9 14639 68 10616 1319 28144 58 28541 28685 28147 10217 28172 28411 28135 12439 28144 1070 28142 28140 61 1453 28146 194 152 68 20 2029 28195 28136 9 10217 28172 28411 28151 2704 28137 387 26024 28140 10616 1319 28160 373 28147 13 772 28137 387 26024 28140 267 28160 373 28152 230 28137 1378 17700 165 28147 13 2508 579 28139 5296 28135 28 28144 676 28135 8338 64 28135 28136 9 255 7295 1387 773 28137 148 1963 28139 4571 28137 68 127 579 28160 1955 51 28137 7295 28137 28199 3440 28191 2733 28144 60 28755 14548 47 539 235 28148 740 28147 28 28136 9 579 28230 28149 9682 28203 28160 1985 2733 28144 1492 28142 28147 28 28136 9 68 20 8966 28195 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000009\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 9\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 국무 ##회의 ##의 심의 ##를 거쳐야 한다는 헌법 제 몇 조 ##의 내용 ##인 ##가 ? [SEP] \" 내각 ##과 장관 ##들이 소외 ##되 ##고 대통령 ##비 ##서 ##실 ##의 권한 ##이 너무 크 ##다 \" , \" 행보 ##가 비서 본연 ##의 역할 ##을 벗어난 ##다 \" 는 의견 ##이 제기 ##되 ##었 ##다 . 대표 ##적 ##인 예 ##가 10 ##차 개헌 ##안 발표 ##이 ##다 . 원로 헌법 ##학자 ##인 허영 경희 ##대 석좌 ##교 ##수 ##는 정부 ##의 헌법 ##개 ##정 ##안 준비 과정 ##에 대해 \" 청와대 비서실 ##이 아닌 국무 ##회의 중심 ##으로 이뤄졌 ##어 ##야 했 ##다 \" 고 지적 ##했 ##다 . ' 국무 ##회의 ##의 심의 ##를 거쳐야 한다 ' ( 제 ##8 ##9 ##조 ) 는 헌법 규정 ##에 충실 ##하 ##지 않 ##았 ##다는 것 ##이 ##다 . 그러면서 \" 법무부 장관 ##을 제 ##쳐 ##놓 ##고 민정 ##수 ##석 ##이 개정안 ##을 설명 ##하 ##는 게 이해 ##가 안 된다 \" 고 지적 ##했 ##다 . 민정 ##수 ##석 ##은 국회의원 ##에 대해 책임지 ##는 법무부 장관 ##도 아니 ##고 , 국민 ##에 대해 책임지 ##는 사람 ##도 아니 ##기 때문 ##에 정당 ##성이 없 ##고 , 단지 대통령 ##의 신임 ##이 있 ##을 뿐 ##이 ##라는 것 ##이 ##다 . 또한 국무총리 선출 방식 ##에 대한 기자 ##의 질문 ##에 \" 문 대통령 ##도 취임 전 ##에 국무총리 ##에 ##게 실질 ##적 권한 ##을 주 ##겠 ##다고 했 ##지만 그러 ##지 못하 ##고 있 ##다 . 대통령 ##비 ##서 ##실장 ##만 ##도 못한 권한 ##을 행사 ##하 ##고 있 ##다 . \" 고 답변 ##했 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 18:0 19:0 20:0 21:1 22:1 23:2 24:2 25:2 26:3 27:3 28:3 29:3 30:3 31:4 32:4 33:5 34:6 35:6 36:6 37:6 38:7 39:7 40:7 41:8 42:9 43:9 44:10 45:10 46:11 47:11 48:11 49:11 50:12 51:12 52:13 53:13 54:13 55:13 56:13 57:14 58:14 59:14 60:15 61:15 62:16 63:16 64:17 65:17 66:18 67:18 68:18 69:18 70:19 71:20 72:20 73:20 74:21 75:22 76:22 77:23 78:23 79:23 80:23 81:24 82:24 83:25 84:25 85:25 86:25 87:26 88:27 89:27 90:28 91:29 92:29 93:30 94:30 95:31 96:32 97:32 98:33 99:33 100:34 101:34 102:34 103:35 104:35 105:35 106:35 107:36 108:36 109:36 110:36 111:37 112:37 113:37 114:37 115:38 116:38 117:39 118:40 119:40 120:40 121:40 122:40 123:40 124:40 125:40 126:40 127:41 128:42 129:42 130:43 131:43 132:43 133:44 134:44 135:44 136:45 137:45 138:45 139:45 140:46 141:47 142:47 143:48 144:48 145:49 146:49 147:49 148:49 149:50 150:50 151:50 152:50 153:51 154:51 155:52 156:52 157:52 158:53 159:54 160:54 161:55 162:56 163:56 164:56 165:57 166:57 167:57 168:57 169:58 170:58 171:58 172:58 173:59 174:59 175:60 176:61 177:61 178:62 179:63 180:63 181:64 182:64 183:64 184:65 185:65 186:66 187:67 188:67 189:68 190:68 191:69 192:69 193:70 194:70 195:71 196:71 197:72 198:72 199:72 200:73 201:74 202:74 203:75 204:75 205:76 206:76 207:77 208:77 209:77 210:78 211:78 212:78 213:78 214:79 215:80 216:81 217:82 218:82 219:83 220:84 221:84 222:85 223:85 224:86 225:86 226:87 227:87 228:88 229:89 230:89 231:90 232:90 233:90 234:91 235:91 236:92 237:92 238:93 239:93 240:93 241:94 242:94 243:95 244:95 245:96 246:96 247:97 248:97 249:97 250:98 251:98 252:98 253:98 254:98 255:98 256:99 257:100 258:100 259:101 260:101 261:101 262:102 263:102 264:102 265:102 266:102 267:103 268:103 269:103 270:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 3940 6137 28139 7316 28154 22421 1021 1325 58 678 76 28139 726 28164 28146 1132 3 68 2086 28183 1319 7694 12283 28177 28147 579 28230 28149 28308 28139 2733 28135 2115 270 28136 68 13 68 14740 28146 5424 27219 28139 803 28144 13168 28136 68 12 1904 28135 1804 28177 28182 28136 9 392 28191 28164 188 28146 149 28283 10141 28290 512 28135 28136 9 6110 1325 680 28164 18964 10846 28157 26890 28235 28172 28140 393 28139 1325 28246 28180 28290 1489 606 28137 387 68 7039 26387 28135 1024 3940 6137 492 17099 11510 28168 28322 47 28136 68 20 2029 28195 28136 9 84 3940 6137 28139 7316 28154 22421 77 84 24 58 28209 28179 28212 23 12 1325 1268 28137 6898 28142 28148 122 28354 3654 64 28135 28136 9 14639 68 10616 1319 28144 58 28541 28685 28147 10217 28172 28411 28135 12439 28144 1070 28142 28140 61 1453 28146 194 152 68 20 2029 28195 28136 9 10217 28172 28411 28151 2704 28137 387 26024 28140 10616 1319 28160 373 28147 13 772 28137 387 26024 28140 267 28160 373 28152 230 28137 1378 17700 165 28147 13 2508 579 28139 5296 28135 28 28144 676 28135 8338 64 28135 28136 9 255 7295 1387 773 28137 148 1963 28139 4571 28137 68 127 579 28160 1955 51 28137 7295 28137 28199 3440 28191 2733 28144 60 28755 14548 47 539 235 28148 740 28147 28 28136 9 579 28230 28149 9682 28203 28160 1985 2733 28144 1492 28142 28147 28 28136 9 68 20 8966 28195 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000010\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 10\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 법무부 장관 ##을 제 ##쳐 ##놓 ##고 민정 ##수 ##석 ##이 개정안 ##을 설명 ##하 ##는 게 이해 ##가 안 된다고 지적 ##한 경희 ##대 석좌 ##교 ##수 이름 ##은 ? [SEP] \" 내각 ##과 장관 ##들이 소외 ##되 ##고 대통령 ##비 ##서 ##실 ##의 권한 ##이 너무 크 ##다 \" , \" 행보 ##가 비서 본연 ##의 역할 ##을 벗어난 ##다 \" 는 의견 ##이 제기 ##되 ##었 ##다 . 대표 ##적 ##인 예 ##가 10 ##차 개헌 ##안 발표 ##이 ##다 . 원로 헌법 ##학자 ##인 허영 경희 ##대 석좌 ##교 ##수 ##는 정부 ##의 헌법 ##개 ##정 ##안 준비 과정 ##에 대해 \" 청와대 비서실 ##이 아닌 국무 ##회의 중심 ##으로 이뤄졌 ##어 ##야 했 ##다 \" 고 지적 ##했 ##다 . ' 국무 ##회의 ##의 심의 ##를 거쳐야 한다 ' ( 제 ##8 ##9 ##조 ) 는 헌법 규정 ##에 충실 ##하 ##지 않 ##았 ##다는 것 ##이 ##다 . 그러면서 \" 법무부 장관 ##을 제 ##쳐 ##놓 ##고 민정 ##수 ##석 ##이 개정안 ##을 설명 ##하 ##는 게 이해 ##가 안 된다 \" 고 지적 ##했 ##다 . 민정 ##수 ##석 ##은 국회의원 ##에 대해 책임지 ##는 법무부 장관 ##도 아니 ##고 , 국민 ##에 대해 책임지 ##는 사람 ##도 아니 ##기 때문 ##에 정당 ##성이 없 ##고 , 단지 대통령 ##의 신임 ##이 있 ##을 뿐 ##이 ##라는 것 ##이 ##다 . 또한 국무총리 선출 방식 ##에 대한 기자 ##의 질문 ##에 \" 문 대통령 ##도 취임 전 ##에 국무총리 ##에 ##게 실질 ##적 권한 ##을 주 ##겠 ##다고 했 ##지만 그러 ##지 못하 ##고 있 ##다 . 대통령 ##비 ##서 ##실장 ##만 ##도 못한 권한 ##을 행사 ##하 ##고 있 ##다 . \" 고 답변 ##했 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 33:0 34:0 35:0 36:1 37:1 38:2 39:2 40:2 41:3 42:3 43:3 44:3 45:3 46:4 47:4 48:5 49:6 50:6 51:6 52:6 53:7 54:7 55:7 56:8 57:9 58:9 59:10 60:10 61:11 62:11 63:11 64:11 65:12 66:12 67:13 68:13 69:13 70:13 71:13 72:14 73:14 74:14 75:15 76:15 77:16 78:16 79:17 80:17 81:18 82:18 83:18 84:18 85:19 86:20 87:20 88:20 89:21 90:22 91:22 92:23 93:23 94:23 95:23 96:24 97:24 98:25 99:25 100:25 101:25 102:26 103:27 104:27 105:28 106:29 107:29 108:30 109:30 110:31 111:32 112:32 113:33 114:33 115:34 116:34 117:34 118:35 119:35 120:35 121:35 122:36 123:36 124:36 125:36 126:37 127:37 128:37 129:37 130:38 131:38 132:39 133:40 134:40 135:40 136:40 137:40 138:40 139:40 140:40 141:40 142:41 143:42 144:42 145:43 146:43 147:43 148:44 149:44 150:44 151:45 152:45 153:45 154:45 155:46 156:47 157:47 158:48 159:48 160:49 161:49 162:49 163:49 164:50 165:50 166:50 167:50 168:51 169:51 170:52 171:52 172:52 173:53 174:54 175:54 176:55 177:56 178:56 179:56 180:57 181:57 182:57 183:57 184:58 185:58 186:58 187:58 188:59 189:59 190:60 191:61 192:61 193:62 194:63 195:63 196:64 197:64 198:64 199:65 200:65 201:66 202:67 203:67 204:68 205:68 206:69 207:69 208:70 209:70 210:71 211:71 212:72 213:72 214:72 215:73 216:74 217:74 218:75 219:75 220:76 221:76 222:77 223:77 224:77 225:78 226:78 227:78 228:78 229:79 230:80 231:81 232:82 233:82 234:83 235:84 236:84 237:85 238:85 239:86 240:86 241:87 242:87 243:88 244:89 245:89 246:90 247:90 248:90 249:91 250:91 251:92 252:92 253:93 254:93 255:93 256:94 257:94 258:95 259:95 260:96 261:96 262:97 263:97 264:97 265:98 266:98 267:98 268:98 269:98 270:98 271:99 272:100 273:100 274:101 275:101 276:101 277:102 278:102 279:102 280:102 281:102 282:103 283:103 284:103 285:103\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 10616 1319 28144 58 28541 28685 28147 10217 28172 28411 28135 12439 28144 1070 28142 28140 61 1453 28146 194 3591 2029 28150 10846 28157 26890 28235 28172 323 28151 1132 3 68 2086 28183 1319 7694 12283 28177 28147 579 28230 28149 28308 28139 2733 28135 2115 270 28136 68 13 68 14740 28146 5424 27219 28139 803 28144 13168 28136 68 12 1904 28135 1804 28177 28182 28136 9 392 28191 28164 188 28146 149 28283 10141 28290 512 28135 28136 9 6110 1325 680 28164 18964 10846 28157 26890 28235 28172 28140 393 28139 1325 28246 28180 28290 1489 606 28137 387 68 7039 26387 28135 1024 3940 6137 492 17099 11510 28168 28322 47 28136 68 20 2029 28195 28136 9 84 3940 6137 28139 7316 28154 22421 77 84 24 58 28209 28179 28212 23 12 1325 1268 28137 6898 28142 28148 122 28354 3654 64 28135 28136 9 14639 68 10616 1319 28144 58 28541 28685 28147 10217 28172 28411 28135 12439 28144 1070 28142 28140 61 1453 28146 194 152 68 20 2029 28195 28136 9 10217 28172 28411 28151 2704 28137 387 26024 28140 10616 1319 28160 373 28147 13 772 28137 387 26024 28140 267 28160 373 28152 230 28137 1378 17700 165 28147 13 2508 579 28139 5296 28135 28 28144 676 28135 8338 64 28135 28136 9 255 7295 1387 773 28137 148 1963 28139 4571 28137 68 127 579 28160 1955 51 28137 7295 28137 28199 3440 28191 2733 28144 60 28755 14548 47 539 235 28148 740 28147 28 28136 9 579 28230 28149 9682 28203 28160 1985 2733 28144 1492 28142 28147 28 28136 9 68 20 8966 28195 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000011\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 11\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 미국 군대 내 두 ##번 ##째 ##로 높 ##은 직위 ##는 무엇 ##인 ##가 ? [SEP] 알렉산더 메이 ##그 ##스 헤이그 2 ##세 ( 영어 : alex ##ander me ##ig ##s ha ##ig , jr . , 1924 ##년 12 ##월 2 ##일 ~ 2010 ##년 2 ##월 20 ##일 ) 는 미국 ##의 국무 장관 ##을 지낸 미국 ##의 군인 , 관료 및 정치인 ##이 ##다 . 로널드 레이건 대통령 밑 ##에 ##서 국무 ##장 ##관 ##을 지냈 ##으 ##며 , 리처드 닉슨 ##과 제 ##럴드 포드 대통령 밑 ##에 ##서 백악관 비서실장 ##을 지냈 ##다 . 또한 그 ##는 미국 군대 ##에 ##서 2 ##번 ##째 ##로 높 ##은 직위 ##인 미국 육군 부 ##참모 총장 ##과 나토 및 미국 군대 ##의 유럽연합 ##군 최고 ##사령 ##관 ##이 ##었 ##다 . 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관 ##의 참모 ##로 직접 참전 ##하 ##였 ##으 ##며 , 로널드 레이건 정부 출범 ##당 ##시 초대 국무 ##장 ##관 ##직 ##을 맡 ##아 1980 ##년 ##대 대한민국 ##과 미국 ##의 관계 ##를 조율 ##해 왔 ##다 . 저서 ##로 회고록 《 경고 : 현실 ##주의 , 레이건 ##과 외교 정책 》 ( 1984 ##년 발간 ) 이 있 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 17:0 18:1 19:1 20:1 21:2 22:3 23:3 24:3 25:3 26:3 27:4 28:4 29:5 30:5 31:5 32:6 33:6 34:6 35:7 36:7 37:7 38:8 39:8 40:9 41:9 42:10 43:10 44:11 45:12 46:12 47:13 48:13 49:14 50:14 51:14 52:14 53:15 54:15 55:16 56:17 57:17 58:18 59:19 60:19 61:20 62:20 63:21 64:22 65:23 66:23 67:23 68:23 69:24 70:25 71:26 72:27 73:27 74:27 75:28 76:28 77:28 78:28 79:29 80:29 81:29 82:29 83:30 84:31 85:31 86:32 87:32 88:33 89:34 90:35 91:35 92:35 93:36 94:37 95:37 96:38 97:38 98:38 99:39 100:40 101:40 102:41 103:42 104:42 105:42 106:43 107:43 108:43 109:43 110:44 111:44 112:45 113:45 114:46 115:47 116:48 117:48 118:49 119:49 120:50 121:51 122:52 123:53 124:53 125:54 126:54 127:55 128:55 129:55 130:55 131:55 132:55 133:55 134:56 135:57 136:58 137:59 138:60 139:61 140:62 141:62 142:63 143:63 144:64 145:65 146:65 147:65 148:65 149:65 150:65 151:66 152:67 153:68 154:69 155:69 156:69 157:70 158:71 159:71 160:71 161:71 162:71 163:72 164:72 165:73 166:73 167:73 168:74 169:74 170:75 171:75 172:76 173:76 174:77 175:77 176:78 177:78 178:78 179:79 180:79 181:80 182:81 183:81 184:81 185:81 186:81 187:81 188:82 189:82 190:83 191:84 192:84 193:84 194:84 195:84 196:85 197:85 198:85 199:86 200:86 201:86\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 229 1064 119 176 28365 28507 28141 391 28151 6734 28140 3081 28164 28146 1132 3 5821 1622 28174 28166 17670 33 28222 24 1258 306 17350 18725 3253 1098 28227 8582 1098 13 3919 9 13 4445 28165 218 28210 33 28171 239 611 28165 33 28210 56 28171 23 12 229 28139 3940 1319 28144 3508 229 28139 2238 13 2948 275 2639 28135 28136 9 20194 16206 579 1891 28137 28149 3940 28190 28251 28144 1411 28153 28215 13 5071 13184 28183 58 10399 7830 579 1891 28137 28149 15184 22438 28144 1411 28136 9 255 36 28140 229 1064 28137 28149 33 28365 28507 28141 391 28151 6734 28164 229 1299 55 18198 4346 28183 19344 275 229 1064 28139 20515 28263 722 13598 28251 28135 28182 28136 9 305 427 979 12875 13487 14989 2399 28139 4257 28141 869 3288 28142 28201 28153 28215 13 20194 16206 393 3902 28265 28158 1919 3940 28190 28251 28335 28144 530 28169 1399 28165 28157 357 28183 229 28139 482 28154 16445 28181 1027 28136 9 2755 28141 16504 179 4988 306 2108 311 13 16206 28183 1792 893 180 24 2427 28165 4799 23 7 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000012\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 12\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 로널드 레이건 정부 출범 당시 알렉산더 헤이그 ##는 어떤 직책 ##을 맡 ##았 ##는 ##가 ? [SEP] 알렉산더 메이 ##그 ##스 헤이그 2 ##세 ( 영어 : alex ##ander me ##ig ##s ha ##ig , jr . , 1924 ##년 12 ##월 2 ##일 ~ 2010 ##년 2 ##월 20 ##일 ) 는 미국 ##의 국무 장관 ##을 지낸 미국 ##의 군인 , 관료 및 정치인 ##이 ##다 . 로널드 레이건 대통령 밑 ##에 ##서 국무 ##장 ##관 ##을 지냈 ##으 ##며 , 리처드 닉슨 ##과 제 ##럴드 포드 대통령 밑 ##에 ##서 백악관 비서실장 ##을 지냈 ##다 . 또한 그 ##는 미국 군대 ##에 ##서 2 ##번 ##째 ##로 높 ##은 직위 ##인 미국 육군 부 ##참모 총장 ##과 나토 및 미국 군대 ##의 유럽연합 ##군 최고 ##사령 ##관 ##이 ##었 ##다 . 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관 ##의 참모 ##로 직접 참전 ##하 ##였 ##으 ##며 , 로널드 레이건 정부 출범 ##당 ##시 초대 국무 ##장 ##관 ##직 ##을 맡 ##아 1980 ##년 ##대 대한민국 ##과 미국 ##의 관계 ##를 조율 ##해 왔 ##다 . 저서 ##로 회고록 《 경고 : 현실 ##주의 , 레이건 ##과 외교 정책 》 ( 1984 ##년 발간 ) 이 있 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 18:0 19:1 20:1 21:1 22:2 23:3 24:3 25:3 26:3 27:3 28:4 29:4 30:5 31:5 32:5 33:6 34:6 35:6 36:7 37:7 38:7 39:8 40:8 41:9 42:9 43:10 44:10 45:11 46:12 47:12 48:13 49:13 50:14 51:14 52:14 53:14 54:15 55:15 56:16 57:17 58:17 59:18 60:19 61:19 62:20 63:20 64:21 65:22 66:23 67:23 68:23 69:23 70:24 71:25 72:26 73:27 74:27 75:27 76:28 77:28 78:28 79:28 80:29 81:29 82:29 83:29 84:30 85:31 86:31 87:32 88:32 89:33 90:34 91:35 92:35 93:35 94:36 95:37 96:37 97:38 98:38 99:38 100:39 101:40 102:40 103:41 104:42 105:42 106:42 107:43 108:43 109:43 110:43 111:44 112:44 113:45 114:45 115:46 116:47 117:48 118:48 119:49 120:49 121:50 122:51 123:52 124:53 125:53 126:54 127:54 128:55 129:55 130:55 131:55 132:55 133:55 134:55 135:56 136:57 137:58 138:59 139:60 140:61 141:62 142:62 143:63 144:63 145:64 146:65 147:65 148:65 149:65 150:65 151:65 152:66 153:67 154:68 155:69 156:69 157:69 158:70 159:71 160:71 161:71 162:71 163:71 164:72 165:72 166:73 167:73 168:73 169:74 170:74 171:75 172:75 173:76 174:76 175:77 176:77 177:78 178:78 179:78 180:79 181:79 182:80 183:81 184:81 185:81 186:81 187:81 188:81 189:82 190:82 191:83 192:84 193:84 194:84 195:84 196:84 197:85 198:85 199:85 200:86 201:86 202:86\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 20194 16206 393 3902 293 5821 17670 28140 995 7987 28144 530 28354 28140 28146 1132 3 5821 1622 28174 28166 17670 33 28222 24 1258 306 17350 18725 3253 1098 28227 8582 1098 13 3919 9 13 4445 28165 218 28210 33 28171 239 611 28165 33 28210 56 28171 23 12 229 28139 3940 1319 28144 3508 229 28139 2238 13 2948 275 2639 28135 28136 9 20194 16206 579 1891 28137 28149 3940 28190 28251 28144 1411 28153 28215 13 5071 13184 28183 58 10399 7830 579 1891 28137 28149 15184 22438 28144 1411 28136 9 255 36 28140 229 1064 28137 28149 33 28365 28507 28141 391 28151 6734 28164 229 1299 55 18198 4346 28183 19344 275 229 1064 28139 20515 28263 722 13598 28251 28135 28182 28136 9 305 427 979 12875 13487 14989 2399 28139 4257 28141 869 3288 28142 28201 28153 28215 13 20194 16206 393 3902 28265 28158 1919 3940 28190 28251 28335 28144 530 28169 1399 28165 28157 357 28183 229 28139 482 28154 16445 28181 1027 28136 9 2755 28141 16504 179 4988 306 2108 311 13 16206 28183 1792 893 180 24 2427 28165 4799 23 7 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000013\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 13\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 알렉산더 헤이그 ##는 어느 대통령 ##의 밑 ##에 ##서 국무 ##장 ##관 ##을 지냈 ##는 ##가 ? [SEP] 알렉산더 메이 ##그 ##스 헤이그 2 ##세 ( 영어 : alex ##ander me ##ig ##s ha ##ig , jr . , 1924 ##년 12 ##월 2 ##일 ~ 2010 ##년 2 ##월 20 ##일 ) 는 미국 ##의 국무 장관 ##을 지낸 미국 ##의 군인 , 관료 및 정치인 ##이 ##다 . 로널드 레이건 대통령 밑 ##에 ##서 국무 ##장 ##관 ##을 지냈 ##으 ##며 , 리처드 닉슨 ##과 제 ##럴드 포드 대통령 밑 ##에 ##서 백악관 비서실장 ##을 지냈 ##다 . 또한 그 ##는 미국 군대 ##에 ##서 2 ##번 ##째 ##로 높 ##은 직위 ##인 미국 육군 부 ##참모 총장 ##과 나토 및 미국 군대 ##의 유럽연합 ##군 최고 ##사령 ##관 ##이 ##었 ##다 . 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관 ##의 참모 ##로 직접 참전 ##하 ##였 ##으 ##며 , 로널드 레이건 정부 출범 ##당 ##시 초대 국무 ##장 ##관 ##직 ##을 맡 ##아 1980 ##년 ##대 대한민국 ##과 미국 ##의 관계 ##를 조율 ##해 왔 ##다 . 저서 ##로 회고록 《 경고 : 현실 ##주의 , 레이건 ##과 외교 정책 》 ( 1984 ##년 발간 ) 이 있 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 19:0 20:1 21:1 22:1 23:2 24:3 25:3 26:3 27:3 28:3 29:4 30:4 31:5 32:5 33:5 34:6 35:6 36:6 37:7 38:7 39:7 40:8 41:8 42:9 43:9 44:10 45:10 46:11 47:12 48:12 49:13 50:13 51:14 52:14 53:14 54:14 55:15 56:15 57:16 58:17 59:17 60:18 61:19 62:19 63:20 64:20 65:21 66:22 67:23 68:23 69:23 70:23 71:24 72:25 73:26 74:27 75:27 76:27 77:28 78:28 79:28 80:28 81:29 82:29 83:29 84:29 85:30 86:31 87:31 88:32 89:32 90:33 91:34 92:35 93:35 94:35 95:36 96:37 97:37 98:38 99:38 100:38 101:39 102:40 103:40 104:41 105:42 106:42 107:42 108:43 109:43 110:43 111:43 112:44 113:44 114:45 115:45 116:46 117:47 118:48 119:48 120:49 121:49 122:50 123:51 124:52 125:53 126:53 127:54 128:54 129:55 130:55 131:55 132:55 133:55 134:55 135:55 136:56 137:57 138:58 139:59 140:60 141:61 142:62 143:62 144:63 145:63 146:64 147:65 148:65 149:65 150:65 151:65 152:65 153:66 154:67 155:68 156:69 157:69 158:69 159:70 160:71 161:71 162:71 163:71 164:71 165:72 166:72 167:73 168:73 169:73 170:74 171:74 172:75 173:75 174:76 175:76 176:77 177:77 178:78 179:78 180:78 181:79 182:79 183:80 184:81 185:81 186:81 187:81 188:81 189:81 190:82 191:82 192:83 193:84 194:84 195:84 196:84 197:84 198:85 199:85 200:85 201:86 202:86 203:86\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 5821 17670 28140 1210 579 28139 1891 28137 28149 3940 28190 28251 28144 1411 28140 28146 1132 3 5821 1622 28174 28166 17670 33 28222 24 1258 306 17350 18725 3253 1098 28227 8582 1098 13 3919 9 13 4445 28165 218 28210 33 28171 239 611 28165 33 28210 56 28171 23 12 229 28139 3940 1319 28144 3508 229 28139 2238 13 2948 275 2639 28135 28136 9 20194 16206 579 1891 28137 28149 3940 28190 28251 28144 1411 28153 28215 13 5071 13184 28183 58 10399 7830 579 1891 28137 28149 15184 22438 28144 1411 28136 9 255 36 28140 229 1064 28137 28149 33 28365 28507 28141 391 28151 6734 28164 229 1299 55 18198 4346 28183 19344 275 229 1064 28139 20515 28263 722 13598 28251 28135 28182 28136 9 305 427 979 12875 13487 14989 2399 28139 4257 28141 869 3288 28142 28201 28153 28215 13 20194 16206 393 3902 28265 28158 1919 3940 28190 28251 28335 28144 530 28169 1399 28165 28157 357 28183 229 28139 482 28154 16445 28181 1027 28136 9 2755 28141 16504 179 4988 306 2108 311 13 16206 28183 1792 893 180 24 2427 28165 4799 23 7 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000014\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 14\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 로널드 레이건 대통령 밑 ##에 ##서 일 ##한 국무 장관 ##은 누구 ##인 ##가 ? [SEP] 알렉산더 메이 ##그 ##스 헤이그 2 ##세 ( 영어 : alex ##ander me ##ig ##s ha ##ig , jr . , 1924 ##년 12 ##월 2 ##일 ~ 2010 ##년 2 ##월 20 ##일 ) 는 미국 ##의 국무 장관 ##을 지낸 미국 ##의 군인 , 관료 및 정치인 ##이 ##다 . 로널드 레이건 대통령 밑 ##에 ##서 국무 ##장 ##관 ##을 지냈 ##으 ##며 , 리처드 닉슨 ##과 제 ##럴드 포드 대통령 밑 ##에 ##서 백악관 비서실장 ##을 지냈 ##다 . 또한 그 ##는 미국 군대 ##에 ##서 2 ##번 ##째 ##로 높 ##은 직위 ##인 미국 육군 부 ##참모 총장 ##과 나토 및 미국 군대 ##의 유럽연합 ##군 최고 ##사령 ##관 ##이 ##었 ##다 . 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관 ##의 참모 ##로 직접 참전 ##하 ##였 ##으 ##며 , 로널드 레이건 정부 출범 ##당 ##시 초대 국무 ##장 ##관 ##직 ##을 맡 ##아 1980 ##년 ##대 대한민국 ##과 미국 ##의 관계 ##를 조율 ##해 왔 ##다 . 저서 ##로 회고록 《 경고 : 현실 ##주의 , 레이건 ##과 외교 정책 》 ( 1984 ##년 발간 ) 이 있 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 17:0 18:1 19:1 20:1 21:2 22:3 23:3 24:3 25:3 26:3 27:4 28:4 29:5 30:5 31:5 32:6 33:6 34:6 35:7 36:7 37:7 38:8 39:8 40:9 41:9 42:10 43:10 44:11 45:12 46:12 47:13 48:13 49:14 50:14 51:14 52:14 53:15 54:15 55:16 56:17 57:17 58:18 59:19 60:19 61:20 62:20 63:21 64:22 65:23 66:23 67:23 68:23 69:24 70:25 71:26 72:27 73:27 74:27 75:28 76:28 77:28 78:28 79:29 80:29 81:29 82:29 83:30 84:31 85:31 86:32 87:32 88:33 89:34 90:35 91:35 92:35 93:36 94:37 95:37 96:38 97:38 98:38 99:39 100:40 101:40 102:41 103:42 104:42 105:42 106:43 107:43 108:43 109:43 110:44 111:44 112:45 113:45 114:46 115:47 116:48 117:48 118:49 119:49 120:50 121:51 122:52 123:53 124:53 125:54 126:54 127:55 128:55 129:55 130:55 131:55 132:55 133:55 134:56 135:57 136:58 137:59 138:60 139:61 140:62 141:62 142:63 143:63 144:64 145:65 146:65 147:65 148:65 149:65 150:65 151:66 152:67 153:68 154:69 155:69 156:69 157:70 158:71 159:71 160:71 161:71 162:71 163:72 164:72 165:73 166:73 167:73 168:74 169:74 170:75 171:75 172:76 173:76 174:77 175:77 176:78 177:78 178:78 179:79 180:79 181:80 182:81 183:81 184:81 185:81 186:81 187:81 188:82 189:82 190:83 191:84 192:84 193:84 194:84 195:84 196:85 197:85 198:85 199:86 200:86 201:86\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 20194 16206 579 1891 28137 28149 39 28150 3940 1319 28151 3328 28164 28146 1132 3 5821 1622 28174 28166 17670 33 28222 24 1258 306 17350 18725 3253 1098 28227 8582 1098 13 3919 9 13 4445 28165 218 28210 33 28171 239 611 28165 33 28210 56 28171 23 12 229 28139 3940 1319 28144 3508 229 28139 2238 13 2948 275 2639 28135 28136 9 20194 16206 579 1891 28137 28149 3940 28190 28251 28144 1411 28153 28215 13 5071 13184 28183 58 10399 7830 579 1891 28137 28149 15184 22438 28144 1411 28136 9 255 36 28140 229 1064 28137 28149 33 28365 28507 28141 391 28151 6734 28164 229 1299 55 18198 4346 28183 19344 275 229 1064 28139 20515 28263 722 13598 28251 28135 28182 28136 9 305 427 979 12875 13487 14989 2399 28139 4257 28141 869 3288 28142 28201 28153 28215 13 20194 16206 393 3902 28265 28158 1919 3940 28190 28251 28335 28144 530 28169 1399 28165 28157 357 28183 229 28139 482 28154 16445 28181 1027 28136 9 2755 28141 16504 179 4988 306 2108 311 13 16206 28183 1792 893 180 24 2427 28165 4799 23 7 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000015\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 15\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 미국 군대 ##에 ##서 두 ##번 ##째 ##로 높 ##은 직위 ##는 ? [SEP] 알렉산더 메이 ##그 ##스 헤이그 2 ##세 ( 영어 : alex ##ander me ##ig ##s ha ##ig , jr . , 1924 ##년 12 ##월 2 ##일 ~ 2010 ##년 2 ##월 20 ##일 ) 는 미국 ##의 국무 장관 ##을 지낸 미국 ##의 군인 , 관료 및 정치인 ##이 ##다 . 로널드 레이건 대통령 밑 ##에 ##서 국무 ##장 ##관 ##을 지냈 ##으 ##며 , 리처드 닉슨 ##과 제 ##럴드 포드 대통령 밑 ##에 ##서 백악관 비서실장 ##을 지냈 ##다 . 또한 그 ##는 미국 군대 ##에 ##서 2 ##번 ##째 ##로 높 ##은 직위 ##인 미국 육군 부 ##참모 총장 ##과 나토 및 미국 군대 ##의 유럽연합 ##군 최고 ##사령 ##관 ##이 ##었 ##다 . 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관 ##의 참모 ##로 직접 참전 ##하 ##였 ##으 ##며 , 로널드 레이건 정부 출범 ##당 ##시 초대 국무 ##장 ##관 ##직 ##을 맡 ##아 1980 ##년 ##대 대한민국 ##과 미국 ##의 관계 ##를 조율 ##해 왔 ##다 . 저서 ##로 회고록 《 경고 : 현실 ##주의 , 레이건 ##과 외교 정책 》 ( 1984 ##년 발간 ) 이 있 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 15:0 16:1 17:1 18:1 19:2 20:3 21:3 22:3 23:3 24:3 25:4 26:4 27:5 28:5 29:5 30:6 31:6 32:6 33:7 34:7 35:7 36:8 37:8 38:9 39:9 40:10 41:10 42:11 43:12 44:12 45:13 46:13 47:14 48:14 49:14 50:14 51:15 52:15 53:16 54:17 55:17 56:18 57:19 58:19 59:20 60:20 61:21 62:22 63:23 64:23 65:23 66:23 67:24 68:25 69:26 70:27 71:27 72:27 73:28 74:28 75:28 76:28 77:29 78:29 79:29 80:29 81:30 82:31 83:31 84:32 85:32 86:33 87:34 88:35 89:35 90:35 91:36 92:37 93:37 94:38 95:38 96:38 97:39 98:40 99:40 100:41 101:42 102:42 103:42 104:43 105:43 106:43 107:43 108:44 109:44 110:45 111:45 112:46 113:47 114:48 115:48 116:49 117:49 118:50 119:51 120:52 121:53 122:53 123:54 124:54 125:55 126:55 127:55 128:55 129:55 130:55 131:55 132:56 133:57 134:58 135:59 136:60 137:61 138:62 139:62 140:63 141:63 142:64 143:65 144:65 145:65 146:65 147:65 148:65 149:66 150:67 151:68 152:69 153:69 154:69 155:70 156:71 157:71 158:71 159:71 160:71 161:72 162:72 163:73 164:73 165:73 166:74 167:74 168:75 169:75 170:76 171:76 172:77 173:77 174:78 175:78 176:78 177:79 178:79 179:80 180:81 181:81 182:81 183:81 184:81 185:81 186:82 187:82 188:83 189:84 190:84 191:84 192:84 193:84 194:85 195:85 196:85 197:86 198:86 199:86\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 229 1064 28137 28149 176 28365 28507 28141 391 28151 6734 28140 1132 3 5821 1622 28174 28166 17670 33 28222 24 1258 306 17350 18725 3253 1098 28227 8582 1098 13 3919 9 13 4445 28165 218 28210 33 28171 239 611 28165 33 28210 56 28171 23 12 229 28139 3940 1319 28144 3508 229 28139 2238 13 2948 275 2639 28135 28136 9 20194 16206 579 1891 28137 28149 3940 28190 28251 28144 1411 28153 28215 13 5071 13184 28183 58 10399 7830 579 1891 28137 28149 15184 22438 28144 1411 28136 9 255 36 28140 229 1064 28137 28149 33 28365 28507 28141 391 28151 6734 28164 229 1299 55 18198 4346 28183 19344 275 229 1064 28139 20515 28263 722 13598 28251 28135 28182 28136 9 305 427 979 12875 13487 14989 2399 28139 4257 28141 869 3288 28142 28201 28153 28215 13 20194 16206 393 3902 28265 28158 1919 3940 28190 28251 28335 28144 530 28169 1399 28165 28157 357 28183 229 28139 482 28154 16445 28181 1027 28136 9 2755 28141 16504 179 4988 306 2108 311 13 16206 28183 1792 893 180 24 2427 28165 4799 23 7 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000016\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 16\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 알렉산더 메이 ##그 ##스 헤이그 ##의 생년 ##월 ##일 ##은 ? [SEP] 알렉산더 메이 ##그 ##스 헤이그 2 ##세 ( 영어 : alex ##ander me ##ig ##s ha ##ig , jr . , 1924 ##년 12 ##월 2 ##일 ~ 2010 ##년 2 ##월 20 ##일 ) 는 미국 ##의 국무 장관 ##을 지낸 미국 ##의 군인 , 관료 및 정치인 ##이 ##다 . 로널드 레이건 대통령 밑 ##에 ##서 국무 ##장 ##관 ##을 지냈 ##으 ##며 , 리처드 닉슨 ##과 제 ##럴드 포드 대통령 밑 ##에 ##서 백악관 비서실장 ##을 지냈 ##다 . 또한 그 ##는 미국 군대 ##에 ##서 2 ##번 ##째 ##로 높 ##은 직위 ##인 미국 육군 부 ##참모 총장 ##과 나토 및 미국 군대 ##의 유럽연합 ##군 최고 ##사령 ##관 ##이 ##었 ##다 . 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관 ##의 참모 ##로 직접 참전 ##하 ##였 ##으 ##며 , 로널드 레이건 정부 출범 ##당 ##시 초대 국무 ##장 ##관 ##직 ##을 맡 ##아 1980 ##년 ##대 대한민국 ##과 미국 ##의 관계 ##를 조율 ##해 왔 ##다 . 저서 ##로 회고록 《 경고 : 현실 ##주의 , 레이건 ##과 외교 정책 》 ( 1984 ##년 발간 ) 이 있 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 13:0 14:1 15:1 16:1 17:2 18:3 19:3 20:3 21:3 22:3 23:4 24:4 25:5 26:5 27:5 28:6 29:6 30:6 31:7 32:7 33:7 34:8 35:8 36:9 37:9 38:10 39:10 40:11 41:12 42:12 43:13 44:13 45:14 46:14 47:14 48:14 49:15 50:15 51:16 52:17 53:17 54:18 55:19 56:19 57:20 58:20 59:21 60:22 61:23 62:23 63:23 64:23 65:24 66:25 67:26 68:27 69:27 70:27 71:28 72:28 73:28 74:28 75:29 76:29 77:29 78:29 79:30 80:31 81:31 82:32 83:32 84:33 85:34 86:35 87:35 88:35 89:36 90:37 91:37 92:38 93:38 94:38 95:39 96:40 97:40 98:41 99:42 100:42 101:42 102:43 103:43 104:43 105:43 106:44 107:44 108:45 109:45 110:46 111:47 112:48 113:48 114:49 115:49 116:50 117:51 118:52 119:53 120:53 121:54 122:54 123:55 124:55 125:55 126:55 127:55 128:55 129:55 130:56 131:57 132:58 133:59 134:60 135:61 136:62 137:62 138:63 139:63 140:64 141:65 142:65 143:65 144:65 145:65 146:65 147:66 148:67 149:68 150:69 151:69 152:69 153:70 154:71 155:71 156:71 157:71 158:71 159:72 160:72 161:73 162:73 163:73 164:74 165:74 166:75 167:75 168:76 169:76 170:77 171:77 172:78 173:78 174:78 175:79 176:79 177:80 178:81 179:81 180:81 181:81 182:81 183:81 184:82 185:82 186:83 187:84 188:84 189:84 190:84 191:84 192:85 193:85 194:85 195:86 196:86 197:86\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 5821 1622 28174 28166 17670 28139 20326 28210 28171 28151 1132 3 5821 1622 28174 28166 17670 33 28222 24 1258 306 17350 18725 3253 1098 28227 8582 1098 13 3919 9 13 4445 28165 218 28210 33 28171 239 611 28165 33 28210 56 28171 23 12 229 28139 3940 1319 28144 3508 229 28139 2238 13 2948 275 2639 28135 28136 9 20194 16206 579 1891 28137 28149 3940 28190 28251 28144 1411 28153 28215 13 5071 13184 28183 58 10399 7830 579 1891 28137 28149 15184 22438 28144 1411 28136 9 255 36 28140 229 1064 28137 28149 33 28365 28507 28141 391 28151 6734 28164 229 1299 55 18198 4346 28183 19344 275 229 1064 28139 20515 28263 722 13598 28251 28135 28182 28136 9 305 427 979 12875 13487 14989 2399 28139 4257 28141 869 3288 28142 28201 28153 28215 13 20194 16206 393 3902 28265 28158 1919 3940 28190 28251 28335 28144 530 28169 1399 28165 28157 357 28183 229 28139 482 28154 16445 28181 1027 28136 9 2755 28141 16504 179 4988 306 2108 311 13 16206 28183 1792 893 180 24 2427 28165 4799 23 7 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   unique_id: 1000000017\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   example_index: 17\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   tokens: [CLS] 알렉산더 헤이그 ##가 로널드 레이건 대통령 밑 ##에 ##서 맡 ##은 직책 ##은 무엇 ##이 ##었 ##나 ? [SEP] 알렉산더 메이 ##그 ##스 헤이그 2 ##세 ( 영어 : alex ##ander me ##ig ##s ha ##ig , jr . , 1924 ##년 12 ##월 2 ##일 ~ 2010 ##년 2 ##월 20 ##일 ) 는 미국 ##의 국무 장관 ##을 지낸 미국 ##의 군인 , 관료 및 정치인 ##이 ##다 . 로널드 레이건 대통령 밑 ##에 ##서 국무 ##장 ##관 ##을 지냈 ##으 ##며 , 리처드 닉슨 ##과 제 ##럴드 포드 대통령 밑 ##에 ##서 백악관 비서실장 ##을 지냈 ##다 . 또한 그 ##는 미국 군대 ##에 ##서 2 ##번 ##째 ##로 높 ##은 직위 ##인 미국 육군 부 ##참모 총장 ##과 나토 및 미국 군대 ##의 유럽연합 ##군 최고 ##사령 ##관 ##이 ##었 ##다 . 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관 ##의 참모 ##로 직접 참전 ##하 ##였 ##으 ##며 , 로널드 레이건 정부 출범 ##당 ##시 초대 국무 ##장 ##관 ##직 ##을 맡 ##아 1980 ##년 ##대 대한민국 ##과 미국 ##의 관계 ##를 조율 ##해 왔 ##다 . 저서 ##로 회고록 《 경고 : 현실 ##주의 , 레이건 ##과 외교 정책 》 ( 1984 ##년 발간 ) 이 있 ##다 . [SEP]\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_to_orig_map: 20:0 21:1 22:1 23:1 24:2 25:3 26:3 27:3 28:3 29:3 30:4 31:4 32:5 33:5 34:5 35:6 36:6 37:6 38:7 39:7 40:7 41:8 42:8 43:9 44:9 45:10 46:10 47:11 48:12 49:12 50:13 51:13 52:14 53:14 54:14 55:14 56:15 57:15 58:16 59:17 60:17 61:18 62:19 63:19 64:20 65:20 66:21 67:22 68:23 69:23 70:23 71:23 72:24 73:25 74:26 75:27 76:27 77:27 78:28 79:28 80:28 81:28 82:29 83:29 84:29 85:29 86:30 87:31 88:31 89:32 90:32 91:33 92:34 93:35 94:35 95:35 96:36 97:37 98:37 99:38 100:38 101:38 102:39 103:40 104:40 105:41 106:42 107:42 108:42 109:43 110:43 111:43 112:43 113:44 114:44 115:45 116:45 117:46 118:47 119:48 120:48 121:49 122:49 123:50 124:51 125:52 126:53 127:53 128:54 129:54 130:55 131:55 132:55 133:55 134:55 135:55 136:55 137:56 138:57 139:58 140:59 141:60 142:61 143:62 144:62 145:63 146:63 147:64 148:65 149:65 150:65 151:65 152:65 153:65 154:66 155:67 156:68 157:69 158:69 159:69 160:70 161:71 162:71 163:71 164:71 165:71 166:72 167:72 168:73 169:73 170:73 171:74 172:74 173:75 174:75 175:76 176:76 177:77 178:77 179:78 180:78 181:78 182:79 183:79 184:80 185:81 186:81 187:81 188:81 189:81 190:81 191:82 192:82 193:83 194:84 195:84 196:84 197:84 198:84 199:85 200:85 201:85 202:86 203:86 204:86\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   token_is_max_context: 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True\n",
            "05/15/2020 02:39:43 - INFO - __main__ -   input_ids: 2 5821 17670 28146 20194 16206 579 1891 28137 28149 530 28151 7987 28151 3081 28135 28182 28175 1132 3 5821 1622 28174 28166 17670 33 28222 24 1258 306 17350 18725 3253 1098 28227 8582 1098 13 3919 9 13 4445 28165 218 28210 33 28171 239 611 28165 33 28210 56 28171 23 12 229 28139 3940 1319 28144 3508 229 28139 2238 13 2948 275 2639 28135 28136 9 20194 16206 579 1891 28137 28149 3940 28190 28251 28144 1411 28153 28215 13 5071 13184 28183 58 10399 7830 579 1891 28137 28149 15184 22438 28144 1411 28136 9 255 36 28140 229 1064 28137 28149 33 28365 28507 28141 391 28151 6734 28164 229 1299 55 18198 4346 28183 19344 275 229 1064 28139 20515 28263 722 13598 28251 28135 28182 28136 9 305 427 979 12875 13487 14989 2399 28139 4257 28141 869 3288 28142 28201 28153 28215 13 20194 16206 393 3902 28265 28158 1919 3940 28190 28251 28335 28144 530 28169 1399 28165 28157 357 28183 229 28139 482 28154 16445 28181 1027 28136 9 2755 28141 16504 179 4988 306 2108 311 13 16206 28183 1792 893 180 24 2427 28165 4799 23 7 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   unique_id: 1000000018\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   example_index: 18\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   tokens: [CLS] 알렉산더 헤이그 ##가 1984 ##년 발간 ##한 회고록 ##의 제목 ##은 무엇 ##인 ##가 ? [SEP] 알렉산더 메이 ##그 ##스 헤이그 2 ##세 ( 영어 : alex ##ander me ##ig ##s ha ##ig , jr . , 1924 ##년 12 ##월 2 ##일 ~ 2010 ##년 2 ##월 20 ##일 ) 는 미국 ##의 국무 장관 ##을 지낸 미국 ##의 군인 , 관료 및 정치인 ##이 ##다 . 로널드 레이건 대통령 밑 ##에 ##서 국무 ##장 ##관 ##을 지냈 ##으 ##며 , 리처드 닉슨 ##과 제 ##럴드 포드 대통령 밑 ##에 ##서 백악관 비서실장 ##을 지냈 ##다 . 또한 그 ##는 미국 군대 ##에 ##서 2 ##번 ##째 ##로 높 ##은 직위 ##인 미국 육군 부 ##참모 총장 ##과 나토 및 미국 군대 ##의 유럽연합 ##군 최고 ##사령 ##관 ##이 ##었 ##다 . 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관 ##의 참모 ##로 직접 참전 ##하 ##였 ##으 ##며 , 로널드 레이건 정부 출범 ##당 ##시 초대 국무 ##장 ##관 ##직 ##을 맡 ##아 1980 ##년 ##대 대한민국 ##과 미국 ##의 관계 ##를 조율 ##해 왔 ##다 . 저서 ##로 회고록 《 경고 : 현실 ##주의 , 레이건 ##과 외교 정책 》 ( 1984 ##년 발간 ) 이 있 ##다 . [SEP]\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   token_to_orig_map: 17:0 18:1 19:1 20:1 21:2 22:3 23:3 24:3 25:3 26:3 27:4 28:4 29:5 30:5 31:5 32:6 33:6 34:6 35:7 36:7 37:7 38:8 39:8 40:9 41:9 42:10 43:10 44:11 45:12 46:12 47:13 48:13 49:14 50:14 51:14 52:14 53:15 54:15 55:16 56:17 57:17 58:18 59:19 60:19 61:20 62:20 63:21 64:22 65:23 66:23 67:23 68:23 69:24 70:25 71:26 72:27 73:27 74:27 75:28 76:28 77:28 78:28 79:29 80:29 81:29 82:29 83:30 84:31 85:31 86:32 87:32 88:33 89:34 90:35 91:35 92:35 93:36 94:37 95:37 96:38 97:38 98:38 99:39 100:40 101:40 102:41 103:42 104:42 105:42 106:43 107:43 108:43 109:43 110:44 111:44 112:45 113:45 114:46 115:47 116:48 117:48 118:49 119:49 120:50 121:51 122:52 123:53 124:53 125:54 126:54 127:55 128:55 129:55 130:55 131:55 132:55 133:55 134:56 135:57 136:58 137:59 138:60 139:61 140:62 141:62 142:63 143:63 144:64 145:65 146:65 147:65 148:65 149:65 150:65 151:66 152:67 153:68 154:69 155:69 156:69 157:70 158:71 159:71 160:71 161:71 162:71 163:72 164:72 165:73 166:73 167:73 168:74 169:74 170:75 171:75 172:76 173:76 174:77 175:77 176:78 177:78 178:78 179:79 180:79 181:80 182:81 183:81 184:81 185:81 186:81 187:81 188:82 189:82 190:83 191:84 192:84 193:84 194:84 195:84 196:85 197:85 198:85 199:86 200:86 201:86\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   input_ids: 2 5821 17670 28146 2427 28165 4799 28150 16504 28139 2383 28151 3081 28164 28146 1132 3 5821 1622 28174 28166 17670 33 28222 24 1258 306 17350 18725 3253 1098 28227 8582 1098 13 3919 9 13 4445 28165 218 28210 33 28171 239 611 28165 33 28210 56 28171 23 12 229 28139 3940 1319 28144 3508 229 28139 2238 13 2948 275 2639 28135 28136 9 20194 16206 579 1891 28137 28149 3940 28190 28251 28144 1411 28153 28215 13 5071 13184 28183 58 10399 7830 579 1891 28137 28149 15184 22438 28144 1411 28136 9 255 36 28140 229 1064 28137 28149 33 28365 28507 28141 391 28151 6734 28164 229 1299 55 18198 4346 28183 19344 275 229 1064 28139 20515 28263 722 13598 28251 28135 28182 28136 9 305 427 979 12875 13487 14989 2399 28139 4257 28141 869 3288 28142 28201 28153 28215 13 20194 16206 393 3902 28265 28158 1919 3940 28190 28251 28335 28144 530 28169 1399 28165 28157 357 28183 229 28139 482 28154 16445 28181 1027 28136 9 2755 28141 16504 179 4988 306 2108 311 13 16206 28183 1792 893 180 24 2427 28165 4799 23 7 28 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   *** Example ***\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   unique_id: 1000000019\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   example_index: 19\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   doc_span_index: 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   tokens: [CLS] 알렉산더 헤이그 ##와 1950 ##년 5 ##월 결혼 ##한 상대 ##의 이름 ##은 무엇 ##인 ##가 ? [SEP] 노 ##터 ##데 ##임 대학교 ##에 ##서 2 ##년 ##간 합리 ##적 ##으로 심각 ##한 공부 ##를 한 후 헤이그 ##는 1944 ##년 미국 육군사관학교 ##로 임명 ##을 획득하여 자신 ##의 어린 시절 ##을 군사 경력 ##의 야망 ##으로 알아 ##챘 ##다 . 그 경력 ##은 헤이그 ##의 학문 ##적 경연 ##이 암시 ##하 ##려고 한 ##것 ##보 ##다 더욱 극 ##적 ##이 ##었 ##으 ##며 그 ##는 1947 ##년 310 ##의 동기 ##병 ##에 ##서 217 ##번 ##째 사관 ##으로 ##서 졸업 ##하 ##였 ##다 . 22 ##세 ##의 소위 ##로 헤이그 ##는 처음 ##에 캔자스 주 포트 ##라 ##일리 ##에 ##서 정통 제 ##병 연합 ##부 ##대로 , 그러 ##고 ##나 ##서 켄터키 주 포트 ##녹 ##스 ##에 있 ##는 기갑 훈련소 ##로 갔 ##다 . 그 ##후 ##에 그 ##는 제 ##1 기병 사단 ##으로 선임 ##되 ##고 그러 ##고 ##나 ##서 일본 ##에 ##서 점령군 ##의 임무 ##와 기력 ##이 없 ##는 훈련 ##을 하 ##였 ##다 . 그 ##는 1950 ##년 5 ##월 한 ##번 자신 ##의 사령관 알론 ##조 폭스 장군 ##의 딸 퍼 ##트리 ##샤 앤 ##토이 ##넷 폭스 ##와 결혼하여 슬하 3 ##명 ##의 자식 ##을 두 ##었 ##다 . [SEP]\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   token_to_orig_map: 19:0 20:0 21:0 22:0 23:1 24:1 25:1 26:2 27:2 28:2 29:3 30:3 31:3 32:4 33:4 34:5 35:5 36:6 37:7 38:8 39:8 40:9 41:9 42:10 43:11 44:11 45:12 46:12 47:13 48:14 49:14 50:15 51:16 52:16 53:17 54:18 55:18 56:19 57:19 58:20 59:20 60:20 61:20 62:21 63:22 64:22 65:23 66:23 67:24 68:24 69:25 70:25 71:26 72:26 73:26 74:27 75:27 76:27 77:27 78:28 79:29 80:29 81:29 82:29 83:29 84:29 85:30 86:30 87:31 88:31 89:32 90:32 91:33 92:33 93:33 94:33 95:34 96:34 97:34 98:35 99:35 100:35 101:36 102:36 103:36 104:36 105:36 106:37 107:37 108:37 109:38 110:38 111:39 112:39 113:40 114:40 115:41 116:42 117:43 118:43 119:43 120:43 121:43 122:44 123:45 124:45 125:46 126:46 127:46 128:46 129:47 130:47 131:47 132:47 133:48 134:49 135:50 136:50 137:50 138:50 139:51 140:51 141:52 142:53 143:53 144:54 145:54 146:54 147:55 148:55 149:55 150:56 151:56 152:57 153:57 154:58 155:59 156:59 157:60 158:60 159:60 160:61 161:61 162:61 163:61 164:62 165:62 166:62 167:63 168:63 169:64 170:64 171:65 172:65 173:66 174:66 175:67 176:67 177:68 178:68 179:68 180:68 181:69 182:69 183:70 184:70 185:71 186:71 187:72 188:72 189:73 190:73 191:74 192:75 193:75 194:76 195:77 196:77 197:78 198:79 199:79 200:79 201:80 202:80 203:80 204:81 205:81 206:82 207:83 208:84 209:84 210:84 211:85 212:85 213:86 214:86 215:86 216:86\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   token_is_max_context: 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   input_ids: 2 5821 17670 28198 1964 28165 106 28210 907 28150 662 28139 323 28151 3081 28164 28146 1132 3 162 28256 28270 28313 827 28137 28149 33 28165 28277 5081 28191 17099 2949 28150 1941 28154 22 103 17670 28140 3191 28165 229 14469 28141 863 28144 24801 285 28139 1283 979 28144 791 2865 28139 13513 17099 2902 31563 28136 9 36 2865 28151 17670 28139 2098 28191 8909 28135 8482 28142 25582 22 28238 28207 28136 1256 573 28191 28135 28182 28153 28215 36 28140 3460 28165 18966 28139 3817 28412 28137 28149 20027 28365 28507 5888 17099 28149 941 28142 28201 28136 9 727 28222 28139 4883 28141 17670 28140 456 28137 10164 60 4326 28173 4760 28137 28149 4880 58 28412 874 28176 1004 13 235 28147 28175 28149 15381 60 4326 28757 28166 28137 28 28140 5042 20866 28141 1516 28136 9 36 28241 28137 36 28140 58 28145 4940 1363 17099 4058 28177 28147 235 28147 28175 28149 208 28137 28149 28000 28139 2372 28198 19726 28135 165 28140 1525 28144 15 28201 28136 9 36 28140 1964 28165 106 28210 22 28365 285 28139 2399 20226 28212 6817 1585 28139 967 923 1508 28713 1755 28030 28775 6817 28198 9585 12300 73 28243 28139 4150 28144 176 28182 28136 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/15/2020 02:39:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3Eu_f_G7PZz",
        "colab_type": "code",
        "outputId": "d6b2ba88-dc4d-44cd-ed6f-5fa37cde21e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
        "all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
        "dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)\n",
        "sampler = SequentialSampler(dataset)\n",
        "dataloader = DataLoader(dataset, sampler=sampler, batch_size=predict_batch_size)\n",
        "\n",
        "logger.info(\"***** Evaluating *****\")\n",
        "logger.info(\"  Num features = %d\", len(dataset))\n",
        "logger.info(\"  Batch size = %d\", predict_batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 02:40:01 - INFO - __main__ -   ***** Evaluating *****\n",
            "05/15/2020 02:40:01 - INFO - __main__ -     Num features = 6579\n",
            "05/15/2020 02:40:01 - INFO - __main__ -     Batch size = 16\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4wvloxL7PYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "all_results = []\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBDJr9orH8mm",
        "colab_type": "text"
      },
      "source": [
        "## KorQuAD1.0 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH-55JVu7PV3",
        "colab_type": "code",
        "outputId": "ac0d00a8-dc87-4ca7-cf4a-6064c7c42b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "8e167b14cf0143769dd3bba96eebec75",
            "c9aa6ddbcf3f41bca8c61c3f9e662760",
            "cd12db3ff52940b985734a4ee0a42755",
            "29c73eed32a54c778d58ad5b27b6ee46",
            "d008966833f241c4b34d2c56a917ec2c",
            "2991301f96e4492fb48bff7fd6b9f87d",
            "5ac42f967d354596a98a1a07b3664501",
            "64b8344aca2141a7a14f4a2008cd5116"
          ]
        }
      },
      "source": [
        "logger.info(\"Start evaluating!\")\n",
        "for input_ids, input_mask, segment_ids, example_indices in tqdm(dataloader, desc=\"Evaluating\", leave=False, ncols=1000):\n",
        "    input_ids = input_ids.to(device)\n",
        "    input_mask = input_mask.to(device)\n",
        "    segment_ids = segment_ids.to(device)\n",
        "    with torch.no_grad():\n",
        "        batch_start_logits, batch_end_logits = model(input_ids, segment_ids, input_mask)\n",
        "    for i, example_index in enumerate(example_indices):\n",
        "        start_logits = batch_start_logits[i].detach().cpu().tolist()\n",
        "        end_logits = batch_end_logits[i].detach().cpu().tolist()\n",
        "        eval_feature = eval_features[example_index.item()]\n",
        "        unique_id = int(eval_feature.unique_id)\n",
        "        all_results.append(RawResult(unique_id=unique_id,\n",
        "                                     start_logits=start_logits,\n",
        "                                     end_logits=end_logits))\n",
        "output_prediction_file = os.path.join(output_dir, \"predictions.json\")\n",
        "output_nbest_file = os.path.join(output_dir, \"nbest_predictions.json\")\n",
        "write_predictions(eval_examples, eval_features, all_results,\n",
        "                    n_best_size, max_answer_length,\n",
        "                    False, output_prediction_file, output_nbest_file,\n",
        "                    None, False, False, 0.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 02:40:01 - INFO - __main__ -   Start evaluating!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e167b14cf0143769dd3bba96eebec75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Evaluating', layout=Layout(flex='2'), max=412.0, style=Pr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 02:40:31 - INFO - __main__ -   Writing predictions to: /content/drive/My Drive/bert_small/predictions.json\n",
            "05/15/2020 02:40:31 - INFO - __main__ -   Writing nbest to: /content/drive/My Drive/bert_small/nbest_predictions.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKaWdFrxH6Rl",
        "colab_type": "text"
      },
      "source": [
        "## 결과확인!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgYyRCg47PTr",
        "colab_type": "code",
        "outputId": "bf4c3d3a-6731-4f6e-951e-9a6395906d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "expected_version = 'KorQuAD_v1.0'\n",
        "with open(predict) as dataset_file:\n",
        "    dataset_json = json.load(dataset_file)\n",
        "    read_version = \"_\".join(dataset_json['version'].split(\"_\")[:-1])\n",
        "    if (read_version != expected_version):\n",
        "        logger.info('Evaluation expects ' + expected_version +\n",
        "                    ', but got dataset with ' + read_version,\n",
        "                    file=sys.stderr)\n",
        "    dataset = dataset_json['data']\n",
        "with open(os.path.join(output_dir, \"predictions.json\")) as prediction_file:\n",
        "    predictions = json.load(prediction_file)\n",
        "logger.info(json.dumps(evaluate(dataset, predictions)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/15/2020 02:40:45 - INFO - __main__ -   {\"exact_match\": 78.6802909594735, \"f1\": 88.19766039994913}\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}